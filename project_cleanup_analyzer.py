#!/usr/bin/env python3
# -*- coding:utf-8 -*-
"""
é¡¹ç›®æ¸…ç†åˆ†æå™¨
è¯†åˆ«å¹¶æ¸…ç†æ— ç”¨æ–‡ä»¶ï¼Œä¿æŒé¡¹ç›®æ•´æ´
"""

import os
import glob
from pathlib import Path
import json


class ProjectCleanupAnalyzer:
    """é¡¹ç›®æ¸…ç†åˆ†æå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        self.project_root = Path(".")
        self.cleanup_report = {
            "duplicate_files": [],
            "obsolete_files": [],
            "temporary_files": [],
            "keep_files": [],
            "cleanup_actions": []
        }
        
        print("ğŸ§¹ é¡¹ç›®æ·±åº¦æ¸…ç†åˆ†æå™¨")
        print("=" * 80)
    
    def analyze_duplicate_files(self):
        """åˆ†æé‡å¤æ–‡ä»¶"""
        print("\nğŸ” åˆ†æé‡å¤æ–‡ä»¶")
        print("-" * 60)
        
        # è¯†åˆ«é‡å¤çš„æ¨ç†æ–‡ä»¶
        inference_files = [
            "final_aligned_inference_test.py",
            "final_smart_inference_test.py", 
            "pytorch_exact_inferer.py",
            "pytorch_style_inference_visualizer.py",
            "simple_correct_inference.py",
            "strictly_aligned_inference.py",
            "comprehensive_inference_test.py",
            "fixed_gold_yolo_inference.py",
            "final_gold_yolo_inference.py"
        ]
        
        # è¯†åˆ«é‡å¤çš„æƒé‡è½¬æ¢æ–‡ä»¶
        weight_converter_files = [
            "complete_weight_converter.py",
            "exact_weight_converter_and_tester.py",
            "pytorch_exact_weight_converter.py",
            "perfect_weight_converter_v2.py",
            "true_weight_converter.py",
            "final_weight_converter.py",
            "final_weight_optimizer.py"
        ]
        
        # è¯†åˆ«é‡å¤çš„æ¶æ„åˆ†ææ–‡ä»¶
        architecture_files = [
            "deep_architecture_analyzer.py",
            "deep_architecture_diagnosis.py",
            "comprehensive_architecture_analyzer.py",
            "parameter_alignment_analyzer.py",
            "weight_structure_analyzer.py",
            "pytorch_weight_analyzer.py"
        ]
        
        # è¯†åˆ«é‡å¤çš„æ¨¡å‹æ–‡ä»¶
        model_files = [
            "pytorch_aligned_model.py",
            "true_pytorch_matched_model.py",
            "architecture_aligned_backbone.py"
        ]
        
        duplicates = {
            "inference_files": inference_files,
            "weight_converter_files": weight_converter_files,
            "architecture_files": architecture_files,
            "model_files": model_files
        }
        
        for category, files in duplicates.items():
            existing_files = [f for f in files if os.path.exists(f)]
            if len(existing_files) > 1:
                self.cleanup_report["duplicate_files"].append({
                    "category": category,
                    "files": existing_files,
                    "keep": existing_files[-1],  # ä¿ç•™æœ€æ–°çš„
                    "remove": existing_files[:-1]
                })
                
                print(f"   ğŸ“ {category}:")
                print(f"      ä¿ç•™: {existing_files[-1]}")
                print(f"      åˆ é™¤: {existing_files[:-1]}")
    
    def analyze_obsolete_files(self):
        """åˆ†æè¿‡æ—¶æ–‡ä»¶"""
        print(f"\nğŸ—‘ï¸ åˆ†æè¿‡æ—¶æ–‡ä»¶")
        print("-" * 60)
        
        # è¿‡æ—¶çš„å®éªŒæ–‡ä»¶
        obsolete_patterns = [
            "*diagnosis*.py",
            "*emergency*.py", 
            "*precise*.py",
            "*ultimate*.py",
            "complete_architecture_rebuilder.py",
            "complete_neck_implementation.py",
            "complete_parameter_alignment.py",
            "detection_accuracy_validator.py",
            "detection_performance_analyzer.py",
            "final_detection_accuracy_test.py",
            "final_project_summary.py",
            "final_weight_conversion_and_inference.py",
            "pytorch_jittor_comparison.py",
            "visualization_results_viewer.py"
        ]
        
        obsolete_files = []
        for pattern in obsolete_patterns:
            obsolete_files.extend(glob.glob(pattern))
        
        self.cleanup_report["obsolete_files"] = obsolete_files
        
        print(f"   å‘ç°è¿‡æ—¶æ–‡ä»¶: {len(obsolete_files)}ä¸ª")
        for file in obsolete_files:
            print(f"      {file}")
    
    def analyze_temporary_files(self):
        """åˆ†æä¸´æ—¶æ–‡ä»¶"""
        print(f"\nğŸ—‚ï¸ åˆ†æä¸´æ—¶æ–‡ä»¶")
        print("-" * 60)
        
        # ä¸´æ—¶æ–‡ä»¶æ¨¡å¼
        temp_patterns = [
            "*.json",  # åˆ†æç»“æœæ–‡ä»¶
            "__pycache__/*",
            "*.pyc",
            "*.log"
        ]
        
        temp_files = []
        for pattern in temp_patterns:
            temp_files.extend(glob.glob(pattern, recursive=True))
        
        # è¿‡æ»¤æ‰é‡è¦çš„é…ç½®æ–‡ä»¶
        important_json = [
            "configs/gold_yolo-n.py",
            "data/voc_gold_yolo_jittor.yaml"
        ]
        
        temp_files = [f for f in temp_files if f not in important_json]
        
        self.cleanup_report["temporary_files"] = temp_files
        
        print(f"   å‘ç°ä¸´æ—¶æ–‡ä»¶: {len(temp_files)}ä¸ª")
        for file in temp_files[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"      {file}")
        if len(temp_files) > 10:
            print(f"      ... è¿˜æœ‰{len(temp_files)-10}ä¸ª")
    
    def identify_keep_files(self):
        """è¯†åˆ«éœ€è¦ä¿ç•™çš„æ ¸å¿ƒæ–‡ä»¶"""
        print(f"\nâœ… è¯†åˆ«æ ¸å¿ƒä¿ç•™æ–‡ä»¶")
        print("-" * 60)
        
        # æ ¸å¿ƒæ–‡ä»¶
        core_files = [
            # æœ€ç»ˆæˆåŠŸçš„æ¨¡å‹å’Œæ¨ç†
            "final_smart_inference_test.py",
            "pytorch_aligned_model.py", 
            "smart_weight_matcher.py",
            "final_objectness_fixer.py",
            "architecture_aligned_backbone.py",
            
            # æ ¸å¿ƒæ¨¡å—
            "gold_yolo/",
            "yolov6/",
            "models/",
            "configs/",
            "data/",
            "scripts/",
            "tools/",
            
            # é‡è¦æƒé‡
            "weights/pytorch_original_weights.npz",
            "weights/smart_matched_weights.npz",
            "weights/final_objectness_fixed_weights.npz",
            
            # æ–‡æ¡£
            "README.md",
            "USAGE_GUIDE.md",
            "requirements.txt",
            "setup.py",
            
            # æœ€ç»ˆæˆåŠŸçš„è¾“å‡º
            "outputs/final_smart_inference/",
            "outputs/architecture_analysis/"
        ]
        
        self.cleanup_report["keep_files"] = core_files
        
        print(f"   æ ¸å¿ƒä¿ç•™æ–‡ä»¶/ç›®å½•: {len(core_files)}ä¸ª")
        for file in core_files:
            print(f"      âœ… {file}")
    
    def generate_cleanup_actions(self):
        """ç”Ÿæˆæ¸…ç†æ“ä½œ"""
        print(f"\nğŸ¯ ç”Ÿæˆæ¸…ç†æ“ä½œ")
        print("-" * 60)
        
        actions = []
        
        # åˆ é™¤é‡å¤æ–‡ä»¶
        for dup_group in self.cleanup_report["duplicate_files"]:
            for file in dup_group["remove"]:
                actions.append(f"rm {file}")
        
        # åˆ é™¤è¿‡æ—¶æ–‡ä»¶
        for file in self.cleanup_report["obsolete_files"]:
            actions.append(f"rm {file}")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        actions.extend([
            "rm -rf __pycache__",
            "find . -name '*.pyc' -delete",
            "rm -f *.json",  # åˆ é™¤åˆ†æç»“æœæ–‡ä»¶
        ])
        
        # æ¸…ç†å¤šä½™çš„æƒé‡æ–‡ä»¶
        weight_files_to_remove = [
            "weights/complete_matched_weights.npz",
            "weights/complete_rebuilt_weights.npz", 
            "weights/emergency_fixed_weights.npz",
            "weights/exact_matched_weights.npz",
            "weights/final_exact_weights.npz",
            "weights/final_optimized_weights.npz",
            "weights/precisely_fixed_weights.npz",
            "weights/pytorch_exact_weights.npz",
            "weights/pytorch_weights.npz",
            "weights/strictly_aligned_weights.npz",
            "weights/ultimate_fixed_weights.npz"
        ]
        
        for weight_file in weight_files_to_remove:
            actions.append(f"rm -f {weight_file}")
        
        # æ¸…ç†å¤šä½™çš„è¾“å‡ºç›®å½•
        output_dirs_to_remove = [
            "outputs/detection_validation",
            "outputs/detection_visualizations",
            "outputs/final_aligned_inference",
            "outputs/final_objectness_fix", 
            "outputs/final_optimization",
            "outputs/final_visualization_showcase",
            "outputs/inference_results",
            "outputs/pytorch_exact_inference",
            "outputs/pytorch_style_inference",
            "outputs/simple_correct_inference",
            "outputs/visualizations"
        ]
        
        for output_dir in output_dirs_to_remove:
            actions.append(f"rm -rf {output_dir}")
        
        self.cleanup_report["cleanup_actions"] = actions
        
        print(f"   ç”Ÿæˆæ¸…ç†æ“ä½œ: {len(actions)}ä¸ª")
        print(f"   é¢„è®¡é‡Šæ”¾ç©ºé—´: å¤§é‡ä¸´æ—¶æ–‡ä»¶å’Œé‡å¤æ–‡ä»¶")
    
    def create_cleanup_script(self):
        """åˆ›å»ºæ¸…ç†è„šæœ¬"""
        print(f"\nğŸ“ åˆ›å»ºæ¸…ç†è„šæœ¬")
        print("-" * 60)
        
        script_content = """#!/bin/bash
# Gold-YOLO Jittoré¡¹ç›®æ¸…ç†è„šæœ¬
# è‡ªåŠ¨ç”Ÿæˆï¼Œæ¸…ç†é‡å¤å’Œæ— ç”¨æ–‡ä»¶

echo "ğŸ§¹ å¼€å§‹æ¸…ç†Gold-YOLO Jittoré¡¹ç›®..."

# å¤‡ä»½é‡è¦æ–‡ä»¶
echo "ğŸ“¦ å¤‡ä»½é‡è¦æ–‡ä»¶..."
mkdir -p backup
cp weights/pytorch_original_weights.npz backup/
cp weights/smart_matched_weights.npz backup/
cp weights/final_objectness_fixed_weights.npz backup/

# æ¸…ç†é‡å¤æ–‡ä»¶
echo "ğŸ—‘ï¸ æ¸…ç†é‡å¤æ–‡ä»¶..."
"""
        
        for action in self.cleanup_report["cleanup_actions"]:
            script_content += f"{action}\n"
        
        script_content += """
# é‡æ–°ç»„ç»‡ç›®å½•ç»“æ„
echo "ğŸ“ é‡æ–°ç»„ç»‡ç›®å½•ç»“æ„..."
mkdir -p core_files
mv final_smart_inference_test.py core_files/
mv pytorch_aligned_model.py core_files/
mv smart_weight_matcher.py core_files/
mv final_objectness_fixer.py core_files/
mv architecture_aligned_backbone.py core_files/

echo "âœ… æ¸…ç†å®Œæˆ!"
echo "ğŸ“Š æ¸…ç†ç»Ÿè®¡:"
echo "   - åˆ é™¤é‡å¤æ–‡ä»¶: å¤šä¸ª"
echo "   - åˆ é™¤è¿‡æ—¶æ–‡ä»¶: å¤šä¸ª" 
echo "   - æ¸…ç†ä¸´æ—¶æ–‡ä»¶: å¤šä¸ª"
echo "   - ä¿ç•™æ ¸å¿ƒæ–‡ä»¶: é‡è¦æ–‡ä»¶å·²ä¿ç•™"
echo ""
echo "ğŸ¯ é¡¹ç›®ç°åœ¨æ›´åŠ æ•´æ´!"
"""
        
        with open("cleanup_project.sh", "w") as f:
            f.write(script_content)
        
        os.chmod("cleanup_project.sh", 0o755)
        
        print(f"   âœ… æ¸…ç†è„šæœ¬å·²åˆ›å»º: cleanup_project.sh")
        print(f"   è¿è¡Œæ–¹å¼: bash cleanup_project.sh")
    
    def save_cleanup_report(self):
        """ä¿å­˜æ¸…ç†æŠ¥å‘Š"""
        with open("cleanup_report.json", "w") as f:
            json.dump(self.cleanup_report, f, indent=2)
        
        print(f"\nğŸ’¾ æ¸…ç†æŠ¥å‘Šå·²ä¿å­˜: cleanup_report.json")
    
    def run_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print("ğŸ§¹ è¿è¡Œé¡¹ç›®æ·±åº¦æ¸…ç†åˆ†æ")
        print("=" * 80)
        
        self.analyze_duplicate_files()
        self.analyze_obsolete_files() 
        self.analyze_temporary_files()
        self.identify_keep_files()
        self.generate_cleanup_actions()
        self.create_cleanup_script()
        self.save_cleanup_report()
        
        print(f"\nğŸ‰ é¡¹ç›®æ¸…ç†åˆ†æå®Œæˆ!")
        print("=" * 80)
        
        # ç»Ÿè®¡
        total_duplicates = sum(len(group["remove"]) for group in self.cleanup_report["duplicate_files"])
        total_obsolete = len(self.cleanup_report["obsolete_files"])
        total_temp = len(self.cleanup_report["temporary_files"])
        
        print(f"ğŸ“Š æ¸…ç†ç»Ÿè®¡:")
        print(f"   é‡å¤æ–‡ä»¶: {total_duplicates}ä¸ª")
        print(f"   è¿‡æ—¶æ–‡ä»¶: {total_obsolete}ä¸ª")
        print(f"   ä¸´æ—¶æ–‡ä»¶: {total_temp}ä¸ª")
        print(f"   æ¸…ç†æ“ä½œ: {len(self.cleanup_report['cleanup_actions'])}ä¸ª")
        
        print(f"\nğŸš€ å»ºè®®æ“ä½œ:")
        print(f"   1. æŸ¥çœ‹æ¸…ç†æŠ¥å‘Š: cleanup_report.json")
        print(f"   2. æ‰§è¡Œæ¸…ç†è„šæœ¬: bash cleanup_project.sh")
        print(f"   3. éªŒè¯æ ¸å¿ƒåŠŸèƒ½: python final_smart_inference_test.py")


def main():
    """ä¸»å‡½æ•°"""
    analyzer = ProjectCleanupAnalyzer()
    analyzer.run_analysis()


if __name__ == '__main__':
    main()
