#!/usr/bin/env python3
# -*- coding:utf-8 -*-

import os
import cv2
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt

def generate_inference_report():
    """ç”Ÿæˆè¯¦ç»†çš„æ¨ç†åˆ†ææŠ¥å‘Š"""
    print('ğŸ“‹ Gold-YOLO-næ¨ç†åˆ†ææŠ¥å‘Š')
    print('=' * 80)
    
    # åŸºæœ¬ä¿¡æ¯
    print('ğŸ¯ æ¨¡å‹ä¿¡æ¯:')
    print('   æ¨¡å‹æ¶æ„: Gold-YOLO-n')
    print('   è®­ç»ƒæ•°æ®é›†: VOC2012å­é›† (964å¼ å›¾ç‰‡)')
    print('   è®­ç»ƒè½®æ•°: 49/50è½®')
    print('   è®­ç»ƒæ—¶é—´: 23åˆ†é’Ÿ')
    print('   GPU: RTX4060 8GB')
    print('   æ‰¹æ¬¡å¤§å°: 8')
    
    print('\\nğŸ“Š æ¨ç†é…ç½®:')
    print('   ç½®ä¿¡åº¦é˜ˆå€¼: 0.3')
    print('   IoUé˜ˆå€¼: 0.45')
    print('   è¾“å…¥å°ºå¯¸: 640x640')
    print('   æµ‹è¯•å›¾ç‰‡æ•°é‡: 10å¼ ')
    
    # åˆ†ææ¨ç†ç»“æœ
    test_images_dir = Path('data/test_images')
    test_labels_dir = Path('data/test_labels')
    inference_dir = Path('runs/inference/gold_yolo_n_test/test_images')
    
    def parse_yolo_label(label_path, img_width, img_height):
        boxes = []
        if not os.path.exists(label_path):
            return boxes
        
        with open(label_path, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 5:
                    class_id = int(parts[0])
                    x_center = float(parts[1]) * img_width
                    y_center = float(parts[2]) * img_height
                    width = float(parts[3]) * img_width
                    height = float(parts[4]) * img_height
                    confidence = float(parts[5]) if len(parts) > 5 else 1.0
                    
                    boxes.append({
                        'class_id': class_id,
                        'confidence': confidence
                    })
        return boxes
    
    # ç»Ÿè®¡ç»“æœ
    total_gt = 0
    total_pred = 0
    images_with_detections = 0
    images_with_gt = 0
    
    class_gt_count = {}
    class_pred_count = {}
    
    print('\\nğŸ“ˆ è¯¦ç»†æ£€æµ‹ç»“æœ:')
    print('   å›¾ç‰‡åç§°        çœŸå®ç›®æ ‡  é¢„æµ‹ç›®æ ‡  æ£€æµ‹ç‡')
    print('   ' + '-' * 50)
    
    for img_file in sorted(test_images_dir.glob('*.jpg')):
        img_name = img_file.stem
        
        # åŠ è½½å›¾ç‰‡è·å–å°ºå¯¸
        img = cv2.imread(str(img_file))
        img_height, img_width = img.shape[:2]
        
        # ç»Ÿè®¡çœŸå®å’Œé¢„æµ‹çš„ç›®æ ‡
        gt_label_file = test_labels_dir / f'{img_name}.txt'
        pred_label_file = inference_dir / f'{img_name}.txt'
        
        gt_boxes = parse_yolo_label(gt_label_file, img_width, img_height)
        pred_boxes = parse_yolo_label(pred_label_file, img_width, img_height)
        
        gt_count = len(gt_boxes)
        pred_count = len(pred_boxes)
        
        detection_rate = pred_count / gt_count if gt_count > 0 else 0
        
        print(f'   {img_name:<15} {gt_count:>8} {pred_count:>8} {detection_rate:>8.1%}')
        
        total_gt += gt_count
        total_pred += pred_count
        
        if pred_count > 0:
            images_with_detections += 1
        if gt_count > 0:
            images_with_gt += 1
        
        # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
        for box in gt_boxes:
            class_id = box['class_id']
            class_gt_count[class_id] = class_gt_count.get(class_id, 0) + 1
        
        for box in pred_boxes:
            class_id = box['class_id']
            class_pred_count[class_id] = class_pred_count.get(class_id, 0) + 1
    
    print('   ' + '-' * 50)
    print(f'   æ€»è®¡            {total_gt:>8} {total_pred:>8} {total_pred/total_gt if total_gt > 0 else 0:>8.1%}')
    
    print('\\nğŸ“Š æ€»ä½“ç»Ÿè®¡:')
    print(f'   æ€»çœŸå®ç›®æ ‡æ•°: {total_gt}')
    print(f'   æ€»é¢„æµ‹ç›®æ ‡æ•°: {total_pred}')
    print(f'   æœ‰ç›®æ ‡çš„å›¾ç‰‡: {images_with_gt}/10')
    print(f'   æœ‰æ£€æµ‹çš„å›¾ç‰‡: {images_with_detections}/10')
    print(f'   æ€»ä½“æ£€æµ‹ç‡: {total_pred/total_gt if total_gt > 0 else 0:.1%}')
    
    # ç±»åˆ«åˆ†æ
    classes = [
        'aeroplane', 'bicycle', 'bird', 'boat', 'bottle',
        'bus', 'car', 'cat', 'chair', 'cow',
        'diningtable', 'dog', 'horse', 'motorbike', 'person',
        'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'
    ]
    
    print('\\nğŸ·ï¸ ç±»åˆ«æ£€æµ‹åˆ†æ:')
    print('   ç±»åˆ«åç§°        çœŸå®æ•°é‡  é¢„æµ‹æ•°é‡  æ£€æµ‹ç‡')
    print('   ' + '-' * 50)
    
    for class_id in sorted(set(list(class_gt_count.keys()) + list(class_pred_count.keys()))):
        class_name = classes[class_id]
        gt_count = class_gt_count.get(class_id, 0)
        pred_count = class_pred_count.get(class_id, 0)
        detection_rate = pred_count / gt_count if gt_count > 0 else 0
        
        print(f'   {class_name:<15} {gt_count:>8} {pred_count:>8} {detection_rate:>8.1%}')
    
    print('\\nğŸ” é—®é¢˜åˆ†æ:')
    print('   1. æ£€æµ‹ç‡è¾ƒä½ (21.4%): æ¨¡å‹å¯èƒ½éœ€è¦æ›´å¤šè®­ç»ƒè½®æ•°')
    print('   2. å¤§éƒ¨åˆ†å›¾ç‰‡æ— æ£€æµ‹: ç½®ä¿¡åº¦é˜ˆå€¼å¯èƒ½è¿‡é«˜')
    print('   3. è®­ç»ƒæ•°æ®é‡è¾ƒå°: 964å¼ å›¾ç‰‡å¯èƒ½ä¸è¶³ä»¥å……åˆ†è®­ç»ƒ')
    print('   4. è®­ç»ƒæ—¶é—´è¾ƒçŸ­: 23åˆ†é’Ÿå¯èƒ½è®­ç»ƒä¸å……åˆ†')
    
    print('\\nğŸ’¡ æ”¹è¿›å»ºè®®:')
    print('   1. å¢åŠ è®­ç»ƒè½®æ•°åˆ°100-200è½®')
    print('   2. é™ä½ç½®ä¿¡åº¦é˜ˆå€¼åˆ°0.1-0.2')
    print('   3. ä½¿ç”¨æ›´å¤§çš„æ•°æ®é›†è¿›è¡Œè®­ç»ƒ')
    print('   4. è°ƒæ•´å­¦ä¹ ç‡å’Œä¼˜åŒ–å™¨å‚æ•°')
    print('   5. ä½¿ç”¨æ•°æ®å¢å¼ºæŠ€æœ¯')
    
    print('\\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:')
    print('   - æ¨ç†ç»“æœå›¾ç‰‡: runs/inference/gold_yolo_n_test/test_images/')
    print('   - å¯è§†åŒ–å¯¹æ¯”å›¾: runs/inference/gold_yolo_n_test/visualizations/')
    print('   - ç»Ÿè®¡å›¾è¡¨: runs/inference/gold_yolo_n_test/visualizations/detection_statistics.png')
    
    print('\\nâœ… æ¨ç†åˆ†ææŠ¥å‘Šå®Œæˆ')

if __name__ == '__main__':
    generate_inference_report()
