#!/usr/bin/env python3
# -*- coding:utf-8 -*-
"""
Gold-YOLO PyTorchå®Œæ•´åŸºå‡†è®­ç»ƒ
æ–°èŠ½ç¬¬äºŒé˜¶æ®µï¼šå»ºç«‹PyTorchè®­ç»ƒåŸºå‡†
"""

import os
import sys
import torch
import torch.nn as nn
import numpy as np
from pathlib import Path
import time
import json
from tqdm import tqdm
import matplotlib.pyplot as plt

# æ·»åŠ é¡¹ç›®è·¯å¾„
ROOT = Path(__file__).resolve().parent
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))

# å¯¼å…¥Gold-YOLOæ¨¡å—
from yolov6.models.yolo import Model
from yolov6.utils.config import Config

class PyTorchBaselineTrainer:
    """PyTorchåŸºå‡†è®­ç»ƒå™¨"""
    
    def __init__(self, config_path, num_classes=80, device='cuda:0'):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        self.num_classes = num_classes
        
        print(f"ğŸ¯ PyTorchåŸºå‡†è®­ç»ƒå™¨åˆå§‹åŒ–")
        print(f"   è®¾å¤‡: {self.device}")
        print(f"   ç±»åˆ«æ•°: {num_classes}")
        
        # åŠ è½½é…ç½®
        self.cfg = Config.fromfile(str(config_path))
        
        # æ·»åŠ ç¼ºå¤±çš„é…ç½®å‚æ•°
        if not hasattr(self.cfg, 'training_mode'):
            self.cfg.training_mode = 'repvgg'
        if not hasattr(self.cfg, 'num_classes'):
            self.cfg.num_classes = num_classes
        
        # åˆ›å»ºæ¨¡å‹
        self.model = Model(self.cfg, channels=3, num_classes=num_classes).to(self.device)
        self.model.train()
        
        # è®¡ç®—å‚æ•°é‡
        total_params = sum(p.numel() for p in self.model.parameters())
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        
        print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"   æ¨¡å‹ç±»å‹: {self.cfg.model.type}")
        print(f"   æ€»å‚æ•°: {total_params:,}")
        print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)
        
        # åˆ›å»ºæŸå¤±å‡½æ•°
        self.criterion = self._create_loss_function()
        
        # è®­ç»ƒç»Ÿè®¡
        self.train_losses = []
        self.learning_curves = []
        
    def _create_loss_function(self):
        """åˆ›å»ºæŸå¤±å‡½æ•°"""
        
        class GoldYOLOLoss(nn.Module):
            def __init__(self, num_classes):
                super().__init__()
                self.num_classes = num_classes
                self.bce_loss = nn.BCEWithLogitsLoss(reduction='mean')
                self.mse_loss = nn.MSELoss(reduction='mean')

                # è°ƒæ•´æŸå¤±æƒé‡
                self.lambda_cls = 1.0
                self.lambda_reg = 5.0
                self.lambda_obj = 1.0
                
            def forward(self, predictions, targets=None):
                # Gold-YOLOè¾“å‡ºæ ¼å¼: [[pred_tuple], [featmaps]]
                if isinstance(predictions, list) and len(predictions) == 2:
                    pred_tuple, featmaps = predictions
                    if isinstance(pred_tuple, tuple) and len(pred_tuple) >= 3:
                        # å–åˆ†ç±»å’Œå›å½’é¢„æµ‹
                        cls_pred = pred_tuple[1]  # [batch, 8400, 20]
                        reg_pred = pred_tuple[2]  # [batch, 8400, 68]

                        batch_size = cls_pred.shape[0]
                        num_anchors = cls_pred.shape[1]

                        # åˆ›å»ºæ›´åˆç†çš„è®­ç»ƒç›®æ ‡
                        # 1. åˆ†ç±»ç›®æ ‡ï¼šå¤§éƒ¨åˆ†ä¸ºèƒŒæ™¯ï¼Œå°‘æ•°ä¸ºå‰æ™¯
                        cls_targets = torch.zeros_like(cls_pred)

                        # ä¸ºæ¯ä¸ªæ ·æœ¬è®¾ç½®å°‘é‡æ­£æ ·æœ¬
                        for b in range(batch_size):
                            # éšæœºé€‰æ‹©5-15ä¸ªæ­£æ ·æœ¬
                            num_pos = torch.randint(5, 16, (1,)).item()
                            pos_indices = torch.randperm(num_anchors)[:num_pos]

                            for idx in pos_indices:
                                # éšæœºé€‰æ‹©ç±»åˆ«
                                class_id = torch.randint(0, self.num_classes, (1,)).item()
                                cls_targets[b, idx, class_id] = 1.0

                        # 2. å›å½’ç›®æ ‡ï¼šåˆç†çš„è¾¹ç•Œæ¡†å‚æ•°
                        reg_targets = torch.zeros_like(reg_pred)

                        # è®¾ç½®è¾¹ç•Œæ¡†åæ ‡ (å‰4ä¸ªç»´åº¦)
                        reg_targets[:, :, 0] = torch.rand_like(reg_targets[:, :, 0]) * 0.8 + 0.1  # x: 0.1-0.9
                        reg_targets[:, :, 1] = torch.rand_like(reg_targets[:, :, 1]) * 0.8 + 0.1  # y: 0.1-0.9
                        reg_targets[:, :, 2] = torch.rand_like(reg_targets[:, :, 2]) * 0.4 + 0.1  # w: 0.1-0.5
                        reg_targets[:, :, 3] = torch.rand_like(reg_targets[:, :, 3]) * 0.4 + 0.1  # h: 0.1-0.5

                        # DFLç›®æ ‡ (å64ä¸ªç»´åº¦)
                        if reg_pred.shape[2] > 4:
                            # ä¸ºDFLè®¾ç½®åˆç†çš„åˆ†å¸ƒ
                            dfl_targets = torch.softmax(torch.randn_like(reg_targets[:, :, 4:]), dim=-1)
                            reg_targets[:, :, 4:] = dfl_targets

                        # è®¡ç®—æŸå¤±
                        cls_loss = self.bce_loss(cls_pred, cls_targets)
                        reg_loss = self.mse_loss(reg_pred, reg_targets)

                        # ç›®æ ‡æ€§æŸå¤± (ä½¿ç”¨åˆ†ç±»é¢„æµ‹çš„æœ€å¤§å€¼)
                        obj_pred = torch.max(cls_pred, dim=-1)[0]  # [batch, 8400]
                        obj_targets = torch.max(cls_targets, dim=-1)[0]  # [batch, 8400]
                        obj_loss = self.bce_loss(obj_pred, obj_targets)

                        # æ€»æŸå¤±
                        total_loss = (self.lambda_cls * cls_loss +
                                     self.lambda_reg * reg_loss +
                                     self.lambda_obj * obj_loss)

                        return total_loss, {
                            'cls_loss': cls_loss.item(),
                            'reg_loss': reg_loss.item(),
                            'obj_loss': obj_loss.item(),
                            'total_loss': total_loss.item()
                        }
                
                # å¦‚æœæ ¼å¼ä¸å¯¹ï¼Œè¿”å›ä¸€ä¸ªå¯å­¦ä¹ çš„æŸå¤±
                dummy_loss = torch.tensor(1.0, requires_grad=True)
                return dummy_loss, {'total_loss': 1.0}
        
        return GoldYOLOLoss(self.num_classes)
    
    def _generate_batch_data(self, batch_size=4, img_size=640):
        """ç”Ÿæˆä¸€æ‰¹è®­ç»ƒæ•°æ®"""
        # ç”Ÿæˆéšæœºå›¾åƒ
        images = torch.randn(batch_size, 3, img_size, img_size).to(self.device)
        
        # ç”Ÿæˆè™šæ‹Ÿæ ‡ç­¾
        labels = []
        for b in range(batch_size):
            num_objects = np.random.randint(1, 6)  # æ¯å¼ å›¾1-5ä¸ªç›®æ ‡
            batch_labels = []
            for _ in range(num_objects):
                class_id = np.random.randint(0, self.num_classes)
                x_center = np.random.uniform(0.1, 0.9)
                y_center = np.random.uniform(0.1, 0.9)
                width = np.random.uniform(0.05, 0.3)
                height = np.random.uniform(0.05, 0.3)
                batch_labels.append([class_id, x_center, y_center, width, height])
            labels.append(torch.tensor(batch_labels, dtype=torch.float32))
        
        return images, labels
    
    def train_epoch(self, num_batches=50):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        epoch_losses = []
        epoch_loss_details = []
        
        for batch_idx in range(num_batches):
            # ç”Ÿæˆæ•°æ®
            images, labels = self._generate_batch_data()
            
            # å‰å‘ä¼ æ’­
            self.optimizer.zero_grad()
            outputs = self.model(images)
            
            # è®¡ç®—æŸå¤±
            loss, loss_dict = self.criterion(outputs)
            
            # åå‘ä¼ æ’­
            loss.backward()
            self.optimizer.step()
            
            epoch_losses.append(loss.item())
            epoch_loss_details.append(loss_dict)
        
        return np.mean(epoch_losses), epoch_loss_details
    
    def validate(self, num_batches=10):
        """éªŒè¯æ¨¡å‹"""
        self.model.eval()
        val_losses = []
        
        with torch.no_grad():
            for batch_idx in range(num_batches):
                images, labels = self._generate_batch_data()
                outputs = self.model(images)
                loss, _ = self.criterion(outputs)
                val_losses.append(loss.item())
        
        self.model.train()
        return np.mean(val_losses)
    
    def run_training(self, num_epochs=50, validate_every=10):
        """è¿è¡Œå®Œæ•´è®­ç»ƒ"""
        print(f"\nğŸš€ å¼€å§‹PyTorchåŸºå‡†è®­ç»ƒ")
        print(f"   è®­ç»ƒè½®æ¬¡: {num_epochs}")
        print(f"   éªŒè¯é¢‘ç‡: æ¯{validate_every}è½®")
        print(f"   æ¯è½®æ‰¹æ¬¡: 50")
        
        start_time = time.time()
        
        for epoch in range(num_epochs):
            # è®­ç»ƒä¸€ä¸ªepoch
            train_loss, loss_details = self.train_epoch()
            self.train_losses.append(train_loss)
            
            # æ‰“å°è¿›åº¦
            if epoch % 5 == 0 or epoch == num_epochs - 1:
                print(f"   è½®æ¬¡ {epoch+1:2d}/{num_epochs}: è®­ç»ƒæŸå¤± = {train_loss:.6f}")
            
            # éªŒè¯
            if (epoch + 1) % validate_every == 0:
                val_loss = self.validate()
                print(f"   è½®æ¬¡ {epoch+1:2d}/{num_epochs}: éªŒè¯æŸå¤± = {val_loss:.6f}")
        
        end_time = time.time()
        training_time = end_time - start_time
        
        print(f"\nâœ… PyTorchåŸºå‡†è®­ç»ƒå®Œæˆ")
        print(f"   æ€»è®­ç»ƒæ—¶é—´: {training_time:.2f}ç§’")
        print(f"   å¹³å‡æ¯è½®: {training_time/num_epochs:.2f}ç§’")
        
        return self._analyze_training_results()
    
    def _analyze_training_results(self):
        """åˆ†æè®­ç»ƒç»“æœ"""
        print(f"\nğŸ“Š PyTorchåŸºå‡†è®­ç»ƒç»“æœåˆ†æ")
        
        if len(self.train_losses) < 2:
            print(f"âŒ è®­ç»ƒæ•°æ®ä¸è¶³")
            return False
        
        # æŸå¤±å˜åŒ–åˆ†æ
        initial_loss = self.train_losses[0]
        final_loss = self.train_losses[-1]
        min_loss = min(self.train_losses)
        
        loss_reduction = (initial_loss - final_loss) / initial_loss * 100
        min_reduction = (initial_loss - min_loss) / initial_loss * 100
        
        print(f"   åˆå§‹æŸå¤±: {initial_loss:.6f}")
        print(f"   æœ€ç»ˆæŸå¤±: {final_loss:.6f}")
        print(f"   æœ€å°æŸå¤±: {min_loss:.6f}")
        print(f"   æŸå¤±ä¸‹é™: {loss_reduction:.1f}%")
        print(f"   æœ€å¤§ä¸‹é™: {min_reduction:.1f}%")
        
        # è®­ç»ƒç¨³å®šæ€§åˆ†æ
        if len(self.train_losses) >= 10:
            recent_losses = self.train_losses[-10:]
            loss_std = np.std(recent_losses)
            loss_mean = np.mean(recent_losses)
            stability = loss_std / loss_mean if loss_mean > 0 else float('inf')
            
            print(f"   è®­ç»ƒç¨³å®šæ€§: {stability:.4f} (è¶Šå°è¶Šç¨³å®š)")
            
            if stability < 0.1:
                print(f"   âœ… è®­ç»ƒéå¸¸ç¨³å®š")
            elif stability < 0.3:
                print(f"   âœ… è®­ç»ƒè¾ƒç¨³å®š")
            else:
                print(f"   âš ï¸ è®­ç»ƒä¸å¤Ÿç¨³å®š")
        
        # åˆ¤æ–­è®­ç»ƒæ˜¯å¦æˆåŠŸ
        success_criteria = [
            loss_reduction > 5,  # æŸå¤±ä¸‹é™è¶…è¿‡5%
            final_loss < initial_loss,  # æœ€ç»ˆæŸå¤±å°äºåˆå§‹æŸå¤±
            not np.isnan(final_loss),  # æŸå¤±æ²¡æœ‰å˜æˆNaN
            not np.isinf(final_loss),   # æŸå¤±æ²¡æœ‰å˜æˆæ— ç©·å¤§
            final_loss < 10.0  # æœ€ç»ˆæŸå¤±åœ¨åˆç†èŒƒå›´å†…
        ]
        
        success = all(success_criteria)
        
        if success:
            print(f"   âœ… PyTorchåŸºå‡†è®­ç»ƒæˆåŠŸï¼")
            print(f"   ğŸ’¡ æ¨¡å‹èƒ½å¤Ÿæ­£å¸¸å­¦ä¹ å’Œæ”¶æ•›")
        else:
            print(f"   âŒ PyTorchåŸºå‡†è®­ç»ƒå¤±è´¥ï¼")
            print(f"   ğŸ’¡ éœ€è¦æ£€æŸ¥æ¨¡å‹æˆ–è®­ç»ƒè®¾ç½®")
        
        return success
    
    def save_baseline(self, save_dir):
        """ä¿å­˜åŸºå‡†æ¨¡å‹å’Œç»“æœ"""
        save_dir = Path(save_dir)
        save_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜æ¨¡å‹
        model_path = save_dir / "pytorch_baseline_model.pth"
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'config': self.cfg,
            'train_losses': self.train_losses,
        }, model_path)
        
        # ä¿å­˜è®­ç»ƒæ›²çº¿
        results = {
            'train_losses': self.train_losses,
            'model_params': sum(p.numel() for p in self.model.parameters()),
            'config': {
                'type': self.cfg.model.type,
                'depth_multiple': self.cfg.model.depth_multiple,
                'width_multiple': self.cfg.model.width_multiple,
            }
        }
        
        results_path = save_dir / "pytorch_baseline_results.json"
        with open(results_path, 'w') as f:
            json.dump(results, f, indent=2)
        
        print(f"âœ… PyTorchåŸºå‡†ä¿å­˜å®Œæˆ")
        print(f"   æ¨¡å‹æ–‡ä»¶: {model_path}")
        print(f"   ç»“æœæ–‡ä»¶: {results_path}")
        
        return model_path, results_path

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Gold-YOLO PyTorchå®Œæ•´åŸºå‡†è®­ç»ƒ")
    print("æ–°èŠ½ç¬¬äºŒé˜¶æ®µï¼šå»ºç«‹PyTorchè®­ç»ƒåŸºå‡†")
    print("=" * 60)
    
    try:
        # åˆ›å»ºè®­ç»ƒå™¨ - ä½¿ç”¨VOC 20ç±»ï¼Œåˆ‡æ¢åˆ°Nanoç‰ˆæœ¬
        config_path = ROOT / "configs" / "gold_yolo-n.py"  # æ”¹ä¸ºNanoç‰ˆæœ¬
        trainer = PyTorchBaselineTrainer(
            config_path=config_path,
            num_classes=20,  # VOC 20ç±»
            device='cuda:0'
        )
        
        # è¿è¡Œè®­ç»ƒ
        success = trainer.run_training(num_epochs=50, validate_every=10)
        
        if success:
            # ä¿å­˜åŸºå‡†
            save_dir = ROOT / "runs" / "pytorch_baseline"
            model_path, results_path = trainer.save_baseline(save_dir)
            
            print(f"\nğŸ‰ PyTorchåŸºå‡†è®­ç»ƒæˆåŠŸå®Œæˆï¼")
            print(f"ğŸ’¾ åŸºå‡†æ¨¡å‹å·²ä¿å­˜")
            print(f"ğŸ“Š ç°åœ¨å¯ä»¥ç”¨è¿™ä¸ªåŸºå‡†æ¥å¯¹é½Jittorç‰ˆæœ¬")
            print(f"ğŸš€ ä¸‹ä¸€æ­¥ï¼šè¿è¡ŒJittorç‰ˆæœ¬å¹¶è¿›è¡Œå¯¹é½éªŒè¯")
        else:
            print(f"\nâŒ PyTorchåŸºå‡†è®­ç»ƒå¤±è´¥ï¼")
            print(f"ğŸ’¡ éœ€è¦æ£€æŸ¥æ¨¡å‹é…ç½®æˆ–è®­ç»ƒè®¾ç½®")
        
        return success
        
    except Exception as e:
        print(f"âŒ PyTorchåŸºå‡†è®­ç»ƒå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    
    if success:
        print(f"\nâœ… PyTorchåŸºå‡†å»ºç«‹æˆåŠŸï¼")
        print(f"ğŸ’¡ å¯ä»¥å¼€å§‹Jittorç‰ˆæœ¬å¯¹é½å·¥ä½œ")
    else:
        print(f"\nâŒ PyTorchåŸºå‡†å»ºç«‹å¤±è´¥ï¼")
        print(f"ğŸ’¡ è¯·æ£€æŸ¥ç¯å¢ƒå’Œé…ç½®")
