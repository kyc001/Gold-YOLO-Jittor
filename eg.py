#!/usr/bin/env python3
"""
ç»ˆæSanity Check - å®Œå…¨ä¿®å¤ç‰ˆæœ¬
è§£å†³æ‰€æœ‰å·²çŸ¥é—®é¢˜ï¼ŒéªŒè¯RT-DETRè®­ç»ƒæµç¨‹
"""

import os
import sys
import json
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import matplotlib
# è®¾ç½®matplotlibæ”¯æŒä¸­æ–‡å­—ä½“ï¼Œé¿å…ä¸­æ–‡å­—ç¬¦è­¦å‘Š
matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei', 'Arial Unicode MS', 'sans-serif']
matplotlib.rcParams['axes.unicode_minus'] = False

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/home/kyc/project/RT-DETR')

import jittor as jt
import jittor.nn as nn

# è®¾ç½®Jittor
jt.flags.use_cuda = 1

# COCOç±»åˆ«åç§°æ˜ å°„
COCO_CLASSES = {
    1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane',
    6: 'bus', 7: 'train', 8: 'truck', 9: 'boat', 10: 'traffic light',
    11: 'fire hydrant', 13: 'stop sign', 14: 'parking meter', 15: 'bench',
    16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse', 20: 'sheep',
    21: 'cow', 22: 'elephant', 23: 'bear', 24: 'zebra', 25: 'giraffe',
    27: 'backpack', 28: 'umbrella', 31: 'handbag', 32: 'tie', 33: 'suitcase',
    34: 'frisbee', 35: 'skis', 36: 'snowboard', 37: 'sports ball', 38: 'kite',
    39: 'baseball bat', 40: 'baseball glove', 41: 'skateboard', 42: 'surfboard',
    43: 'tennis racket', 44: 'bottle', 46: 'wine glass', 47: 'cup',
    48: 'fork', 49: 'knife', 50: 'spoon', 51: 'bowl', 52: 'banana',
    53: 'apple', 54: 'sandwich', 55: 'orange', 56: 'broccoli', 57: 'carrot',
    58: 'hot dog', 59: 'pizza', 60: 'donut', 61: 'cake', 62: 'chair',
    63: 'couch', 64: 'potted plant', 65: 'bed', 67: 'dining table',
    70: 'toilet', 72: 'tv', 73: 'laptop', 74: 'mouse', 75: 'remote',
    76: 'keyboard', 77: 'cell phone', 78: 'microwave', 79: 'oven',
    80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book',
    85: 'clock', 86: 'vase', 87: 'scissors', 88: 'teddy bear',
    89: 'hair drier', 90: 'toothbrush'
}
jt.set_global_seed(42)
jt.flags.auto_mixed_precision_level = 0

def load_and_verify_data():
    """åŠ è½½å¹¶éªŒè¯æ•°æ® - ä¿®å¤ç‰ˆæœ¬ï¼Œæ­£ç¡®è¯»å–COCOæ ‡æ³¨"""
    print("ğŸ¯ RT-DETRç»ˆæSanity Check")
    print("=" * 80)

    image_path = "/home/kyc/project/RT-DETR/data/coco2017_50/train2017/000000055150.jpg"
    annotation_path = "/home/kyc/project/RT-DETR/data/coco2017_50/annotations/instances_train2017.json"

    if not os.path.exists(image_path) or not os.path.exists(annotation_path):
        print("âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        return None, None

    # åŠ è½½å›¾åƒ
    image = Image.open(image_path).convert('RGB')
    original_width, original_height = image.size
    print(f"åŸå§‹å›¾åƒå°ºå¯¸: {original_width}x{original_height}")

    image_resized = image.resize((640, 640), Image.LANCZOS)

    # è½¬æ¢ä¸ºå¼ é‡
    img_array = np.array(image_resized).astype(np.float32) / 255.0
    img_tensor = jt.array(img_array.transpose(2, 0, 1)).float32().unsqueeze(0)

    # åŠ è½½æ ‡æ³¨ - ä¿®å¤ç‰ˆæœ¬
    with open(annotation_path, 'r') as f:
        coco_data = json.load(f)

    image_id = 55150
    annotations = []
    labels = []

    print(f"æŸ¥æ‰¾å›¾åƒID {image_id} çš„æ ‡æ³¨...")

    for ann in coco_data['annotations']:
        if ann['image_id'] == image_id:
            x, y, w, h = ann['bbox']
            category_id = ann['category_id']

            print(f"æ‰¾åˆ°æ ‡æ³¨: ç±»åˆ«{category_id}, è¾¹ç•Œæ¡†[{x},{y},{w},{h}]")

            # å½’ä¸€åŒ–åæ ‡ - ä½¿ç”¨æ­£ç¡®çš„åŸå§‹å°ºå¯¸
            x1, y1 = x / original_width, y / original_height
            x2, y2 = (x + w) / original_width, (y + h) / original_height

            # ç¡®ä¿åæ ‡æœ‰æ•ˆ
            if x2 > x1 and y2 > y1 and x1 >= 0 and y1 >= 0 and x2 <= 1 and y2 <= 1:
                annotations.append([x1, y1, x2, y2])
                labels.append(category_id)
                print(f"   å½’ä¸€åŒ–å: [{x1:.3f},{y1:.3f},{x2:.3f},{y2:.3f}]")

    # åˆ›å»ºç›®æ ‡ - ä¿®å¤COCOç±»åˆ«æ˜ å°„é—®é¢˜
    if annotations:
        # COCOç±»åˆ«IDéœ€è¦è½¬æ¢ä¸º0-basedç´¢å¼•
        # COCOç±»åˆ«1(person) -> ç´¢å¼•0, COCOç±»åˆ«36(sports ball) -> ç´¢å¼•35
        mapped_labels = []
        for label in labels:
            if label == 1:  # person
                mapped_labels.append(0)  # æ˜ å°„åˆ°ç´¢å¼•0
            elif label == 3:  # car
                mapped_labels.append(2)  # æ˜ å°„åˆ°ç´¢å¼•2
            elif label == 27:  # backpack
                mapped_labels.append(26)  # æ˜ å°„åˆ°ç´¢å¼•26
            elif label == 33:  # suitcase
                mapped_labels.append(32)  # æ˜ å°„åˆ°ç´¢å¼•32
            elif label == 84:  # book
                mapped_labels.append(83)  # æ˜ å°„åˆ°ç´¢å¼•83
            else:
                mapped_labels.append(label - 1)  # å…¶ä»–ç±»åˆ«å‡1

        target = {
            'boxes': jt.array(annotations, dtype=jt.float32),
            'labels': jt.array(mapped_labels, dtype=jt.int64)  # ä½¿ç”¨æ˜ å°„åçš„ç±»åˆ«
        }
        print(f"âœ… åŸå§‹COCOç±»åˆ«: {labels}")
        print(f"âœ… æ˜ å°„åç±»åˆ«ç´¢å¼•: {mapped_labels}")
        print(f"âœ… ç±»åˆ«æ˜ å°„: 1(person)->0, 3(car)->2, 27(backpack)->26, 33(suitcase)->32, 84(book)->83")
    else:
        target = {
            'boxes': jt.zeros((0, 4), dtype=jt.float32),
            'labels': jt.zeros((0,), dtype=jt.int64)
        }

    print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ")
    print(f"   å›¾åƒ: {img_tensor.shape}")
    print(f"   ç›®æ ‡: {len(annotations)}ä¸ªè¾¹ç•Œæ¡†")
    print(f"   ç±»åˆ«: {labels}")

    return img_tensor, [target]

def create_and_test_model():
    """åˆ›å»ºå¹¶æµ‹è¯•æ¨¡å‹"""
    print("\n" + "=" * 60)
    print("===        æ¨¡å‹åˆ›å»ºå’Œæµ‹è¯•        ===")
    print("=" * 60)
    
    try:
        from jittor_rt_detr.src.nn.backbone.resnet import ResNet50
        from jittor_rt_detr.src.zoo.rtdetr.rtdetr_decoder import RTDETRTransformer
        from jittor_rt_detr.src.nn.criterion.rtdetr_criterion import build_criterion
        
        # åˆ›å»ºæ¨¡å‹
        backbone = ResNet50(pretrained=False)
        transformer = RTDETRTransformer(
            num_classes=80,
            hidden_dim=256,
            num_queries=300,
            feat_channels=[256, 512, 1024, 2048]
        )
        criterion = build_criterion(num_classes=80)
        
        print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        img_tensor, targets = load_and_verify_data()
        if img_tensor is None:
            return None, None, None, None, None
        
        print("\næµ‹è¯•å‰å‘ä¼ æ’­...")
        feats = backbone(img_tensor)
        outputs = transformer(feats)
        
        print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"   ç‰¹å¾å›¾æ•°é‡: {len(feats)}")
        print(f"   è¾“å‡ºé”®: {list(outputs.keys())}")
        print(f"   pred_logits: {outputs['pred_logits'].shape}")
        print(f"   pred_boxes: {outputs['pred_boxes'].shape}")
        
        # æµ‹è¯•æŸå¤±è®¡ç®—
        print("\næµ‹è¯•æŸå¤±è®¡ç®—...")
        loss_dict = criterion(outputs, targets)
        total_loss = sum(loss_dict.values())
        
        print(f"âœ… æŸå¤±è®¡ç®—æˆåŠŸ: {total_loss.item():.4f}")
        for k, v in loss_dict.items():
            print(f"   {k}: {v.item():.4f}")
        
        return backbone, transformer, criterion, img_tensor, targets
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, None, None, None, None

def nms_filter(boxes, scores, classes, iou_threshold=0.5, score_threshold=0.3):
    """ç®€å•çš„NMSè¿‡æ»¤ï¼Œå»é™¤é‡å¤æ£€æµ‹"""
    if len(boxes) == 0:
        return [], [], []

    # æŒ‰åˆ†æ•°æ’åº
    sorted_indices = np.argsort(scores)[::-1]

    keep_indices = []
    for i in sorted_indices:
        if scores[i] < score_threshold:
            continue

        # æ£€æŸ¥ä¸å·²ä¿ç•™çš„æ¡†æ˜¯å¦é‡å è¿‡å¤š
        keep_this = True
        for j in keep_indices:
            # è®¡ç®—IoU
            box1 = boxes[i]
            box2 = boxes[j]

            # è®¡ç®—äº¤é›†
            x1 = max(box1[0], box2[0])
            y1 = max(box1[1], box2[1])
            x2 = min(box1[2], box2[2])
            y2 = min(box1[3], box2[3])

            if x2 > x1 and y2 > y1:
                intersection = (x2 - x1) * (y2 - y1)
                area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
                area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
                union = area1 + area2 - intersection
                iou = intersection / union if union > 0 else 0

                if iou > iou_threshold:
                    keep_this = False
                    break

        if keep_this:
            keep_indices.append(i)

    return [boxes[i] for i in keep_indices], [scores[i] for i in keep_indices], [classes[i] for i in keep_indices]

def convert_to_coco_class(class_idx):
    """å°†æ¨¡å‹ç±»åˆ«ç´¢å¼•è½¬æ¢ä¸ºCOCOç±»åˆ«IDå’Œåç§°"""
    if class_idx == 0:
        coco_id = 1  # person
    elif class_idx == 2:
        coco_id = 3  # car
    elif class_idx == 26:
        coco_id = 27  # backpack
    elif class_idx == 32:
        coco_id = 33  # suitcase
    elif class_idx == 83:
        coco_id = 84  # book
    else:
        coco_id = class_idx + 1

    class_name = COCO_CLASSES.get(coco_id, f'class_{coco_id}')
    return coco_id, class_name

def visualize_detection_results(original_image_path, pred_scores, pred_classes, pred_boxes, gt_boxes, gt_classes, save_path=None):
    """å¯è§†åŒ–æ£€æµ‹ç»“æœ"""
    print("ğŸ¨ ç”Ÿæˆæ£€æµ‹ç»“æœå¯è§†åŒ–...")

    # åŠ è½½åŸå§‹å›¾åƒ
    original_image = Image.open(original_image_path).convert('RGB')
    original_width, original_height = original_image.size

    # åˆ›å»ºmatplotlibå›¾å½¢
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))

    # å·¦ä¾§ï¼šçœŸå®æ ‡æ³¨
    ax1.imshow(original_image)
    ax1.set_title('Ground Truth', fontsize=16, fontweight='bold')
    ax1.axis('off')

    # ç»˜åˆ¶çœŸå®è¾¹ç•Œæ¡†
    for i, (gt_box, gt_mapped_label) in enumerate(zip(gt_boxes, gt_classes)):
        # å°†å½’ä¸€åŒ–åæ ‡è½¬æ¢åˆ°åŸå§‹å›¾åƒå°ºå¯¸
        x1, y1, x2, y2 = gt_box
        x1 = x1 * original_width
        y1 = y1 * original_height
        x2 = x2 * original_width
        y2 = y2 * original_height

        # è½¬æ¢å›COCOç±»åˆ«ID
        if gt_mapped_label == 0:
            coco_id, class_name = 1, 'person'
        elif gt_mapped_label == 2:
            coco_id, class_name = 3, 'car'
        elif gt_mapped_label == 26:
            coco_id, class_name = 27, 'backpack'
        elif gt_mapped_label == 32:
            coco_id, class_name = 33, 'suitcase'
        elif gt_mapped_label == 83:
            coco_id, class_name = 84, 'book'
        else:
            coco_id, class_name = gt_mapped_label + 1, COCO_CLASSES.get(gt_mapped_label + 1, f'class_{gt_mapped_label + 1}')

        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        rect = patches.Rectangle(
            (x1, y1), x2 - x1, y2 - y1,
            linewidth=3, edgecolor='green', facecolor='none'
        )
        ax1.add_patch(rect)

        # æ·»åŠ æ ‡ç­¾
        ax1.text(
            x1, y1 - 10, f'GT: {class_name}',
            bbox=dict(boxstyle='round,pad=0.3', facecolor='green', alpha=0.8),
            fontsize=12, fontweight='bold', color='white'
        )

    # å³ä¾§ï¼šé¢„æµ‹ç»“æœ
    ax2.imshow(original_image)
    ax2.set_title('Predictions', fontsize=16, fontweight='bold')
    ax2.axis('off')

    # é¢œè‰²æ˜ å°„
    color_map = plt.cm.Set3(np.linspace(0, 1, 12))

    # åº”ç”¨NMSè¿‡æ»¤é‡å¤æ£€æµ‹
    print("ğŸ”„ åº”ç”¨NMSè¿‡æ»¤é‡å¤æ£€æµ‹...")

    # è½¬æ¢åˆ°åŸå§‹å›¾åƒåæ ‡ç³»
    boxes_original = []
    for box in pred_boxes:
        x1, y1, x2, y2 = box
        x1 = x1 * original_width
        y1 = y1 * original_height
        x2 = x2 * original_width
        y2 = y2 * original_height
        boxes_original.append([x1, y1, x2, y2])

    # åº”ç”¨NMS
    filtered_boxes, filtered_scores, filtered_classes = nms_filter(
        boxes_original, pred_scores, pred_classes,
        iou_threshold=0.5, score_threshold=0.3
    )

    print(f"   NMSå‰: {len(pred_scores)}ä¸ªæ£€æµ‹")
    print(f"   NMSå: {len(filtered_scores)}ä¸ªæ£€æµ‹")

    # ç»˜åˆ¶è¿‡æ»¤åçš„é¢„æµ‹è¾¹ç•Œæ¡†
    for i, (box, score, class_idx) in enumerate(zip(filtered_boxes, filtered_scores, filtered_classes)):
        x1, y1, x2, y2 = box

        # è·å–ç±»åˆ«ä¿¡æ¯
        coco_id, class_name = convert_to_coco_class(class_idx)

        # é€‰æ‹©é¢œè‰²
        color = color_map[i % len(color_map)]

        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        rect = patches.Rectangle(
            (x1, y1), x2 - x1, y2 - y1,
            linewidth=3, edgecolor=color, facecolor='none'
        )
        ax2.add_patch(rect)

        # æ·»åŠ æ ‡ç­¾
        label = f'{class_name}\n{score:.3f}'
        ax2.text(
            x1, y1 - 10, label,
            bbox=dict(boxstyle='round,pad=0.3', facecolor=color, alpha=0.8),
            fontsize=12, fontweight='bold', color='black'
        )

    plt.tight_layout()

    # ä¿å­˜ç»“æœ
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ… å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {save_path}")

    plt.show()
    return fig

def simplified_training_test(backbone, transformer, criterion, img_tensor, targets):
    """ç®€åŒ–çš„è®­ç»ƒæµ‹è¯• - ä¸“æ³¨äºéªŒè¯è®­ç»ƒæ˜¯å¦æœ‰æ•ˆ"""
    print("ğŸ” ç®€åŒ–è®­ç»ƒæµ‹è¯•:")

    # æ”¶é›†æ‰€æœ‰å‚æ•°
    all_params = list(backbone.parameters()) + list(transformer.parameters())
    optimizer = jt.optim.Adam(all_params, lr=1e-3)

    # è®°å½•åˆå§‹æŸå¤±
    feats = backbone(img_tensor)
    outputs = transformer(feats)
    loss_dict = criterion(outputs, targets)
    initial_loss = sum(loss_dict.values()).numpy().item()

    print(f"   åˆå§‹æŸå¤±: {initial_loss:.4f}")

    # è¿›è¡Œå‡ æ­¥è®­ç»ƒ
    for step in range(10):
        feats = backbone(img_tensor)
        outputs = transformer(feats)
        loss_dict = criterion(outputs, targets)
        total_loss = sum(loss_dict.values())

        # ä½¿ç”¨Jittorçš„stepæ–¹æ³•
        optimizer.step(total_loss)

        if step % 3 == 0:
            print(f"   æ­¥éª¤{step}: æŸå¤±={total_loss.numpy().item():.4f}")

    final_loss = total_loss.numpy().item()
    loss_change = abs(final_loss - initial_loss)

    print(f"   æœ€ç»ˆæŸå¤±: {final_loss:.4f}")
    print(f"   æŸå¤±å˜åŒ–: {loss_change:.4f}")

    # å¦‚æœæŸå¤±æœ‰å˜åŒ–ï¼Œè¯´æ˜è®­ç»ƒæœ‰æ•ˆ
    training_effective = loss_change > 0.001

    if training_effective:
        print("âœ… è®­ç»ƒæœ‰æ•ˆï¼šæŸå¤±å‘ç”Ÿäº†å˜åŒ–")
    else:
        print("âš ï¸ è®­ç»ƒå¯èƒ½æ— æ•ˆï¼šæŸå¤±å‡ ä¹æ²¡æœ‰å˜åŒ–")

    return training_effective

def intensive_training_test(backbone, transformer, criterion, img_tensor, targets):
    """100æ¬¡è¿‡æ‹Ÿåˆè®­ç»ƒæµ‹è¯• - ä¸¥æ ¼éªŒè¯"""
    print("\n" + "=" * 60)
    print("===        100æ¬¡è¿‡æ‹Ÿåˆè®­ç»ƒæµ‹è¯•        ===")
    print("=" * 60)

    try:
        # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼å¹¶ä¿®å¤BatchNormé—®é¢˜
        backbone.train()
        transformer.train()

        # ä¿®å¤BatchNormï¼šç¡®ä¿æ‰€æœ‰BatchNormå±‚éƒ½åœ¨è®­ç»ƒæ¨¡å¼
        def fix_batchnorm(module):
            for m in module.modules():
                if isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)):
                    m.train()
                    # ç¡®ä¿BatchNormå‚æ•°å¯è®­ç»ƒ
                    if hasattr(m, 'weight') and m.weight is not None:
                        m.weight.requires_grad = True
                    if hasattr(m, 'bias') and m.bias is not None:
                        m.bias.requires_grad = True

        fix_batchnorm(backbone)
        fix_batchnorm(transformer)

        # æ”¶é›†æ‰€æœ‰éœ€è¦æ¢¯åº¦çš„å‚æ•°
        all_params = []
        for module in [backbone, transformer]:
            for param in module.parameters():
                if param.requires_grad:
                    all_params.append(param)

        # åˆ›å»ºä¼˜åŒ–å™¨ - ä½¿ç”¨æ›´ä½çš„å­¦ä¹ ç‡è¿›è¡Œç¨³å®šè®­ç»ƒ
        optimizer = jt.optim.Adam(all_params, lr=1e-4, weight_decay=0)  # è¿›ä¸€æ­¥é™ä½å­¦ä¹ ç‡

        # æ£€æŸ¥å‚æ•°æ•°é‡
        total_params = sum(p.numel() for p in backbone.parameters()) + sum(p.numel() for p in transformer.parameters())
        trainable_params = len(all_params)
        print(f"æ€»å‚æ•°: {total_params:,}, å¯è®­ç»ƒå‚æ•°æ•°é‡: {trainable_params}")

        print(f"å¼€å§‹200æ¬¡è¿‡æ‹Ÿåˆè®­ç»ƒ (å­¦ä¹ ç‡: 1e-4)...")
        print(f"ç›®æ ‡: æ¨¡å‹å¿…é¡»èƒ½å¤Ÿå®Œç¾è®°ä½è¿™å¼ å›¾åƒçš„æ‰€æœ‰ç›®æ ‡")
        print(f"ä¿®å¤: æ›´ä½å­¦ä¹ ç‡ï¼Œ200è½®è®­ç»ƒï¼Œé¿å…è¿‡åº¦æ‹Ÿåˆåˆ°å•ä¸€é¢„æµ‹")

        # æ£€æŸ¥åˆå§‹æ¢¯åº¦ - ä¿®å¤ç‰ˆæœ¬
        feats = backbone(img_tensor)
        outputs = transformer(feats)
        loss_dict = criterion(outputs, targets)
        total_loss = sum(loss_dict.values())

        print(f"åˆå§‹æŸå¤±: {total_loss.numpy().item():.6f}")
        print(f"æŸå¤±ç»„æˆ: {[f'{k}:{v.numpy().item():.4f}' for k, v in loss_dict.items()]}")

        # ç®€åŒ–çš„è®­ç»ƒæœ‰æ•ˆæ€§æµ‹è¯•
        training_effective = simplified_training_test(backbone, transformer, criterion, img_tensor, targets)
        if not training_effective:
            print("âš ï¸ è®­ç»ƒå¯èƒ½æ— æ•ˆï¼Œä½†ç»§ç»­100æ¬¡è®­ç»ƒ")

        losses = []
        num_epochs = 50  # å¢åŠ åˆ°200æ¬¡ï¼Œæ›´å……åˆ†çš„è®­ç»ƒ

        for epoch in range(num_epochs):
            # ç¡®ä¿æ¨¡å‹åœ¨è®­ç»ƒæ¨¡å¼
            backbone.train()
            transformer.train()

            # Jittorçš„optimizer.step()ä¼šè‡ªåŠ¨æ¸…é›¶æ¢¯åº¦

            # å‰å‘ä¼ æ’­
            feats = backbone(img_tensor)
            outputs = transformer(feats)

            # æŸå¤±è®¡ç®—
            loss_dict = criterion(outputs, targets)
            total_loss = sum(loss_dict.values())
            losses.append(total_loss.numpy().item())

            # åå‘ä¼ æ’­å’Œå‚æ•°æ›´æ–° - ä½¿ç”¨Jittoræ­£ç¡®çš„API
            optimizer.step(total_loss)

            # æ‰“å°è¿›åº¦ - ä¿®å¤ç‰ˆæœ¬ï¼Œå¢åŠ ç±»åˆ«å¤šæ ·æ€§ç›‘æ§
            if epoch % 40 == 0 or epoch < 10 or epoch >= 190:
                print(f"Epoch {epoch:3d}: æŸå¤±={total_loss.numpy().item():.4f}")
                for k, v in loss_dict.items():
                    print(f"         {k}: {v.numpy().item():.4f}")

                # æ£€æŸ¥é¢„æµ‹ç±»åˆ«çš„å¤šæ ·æ€§
                if epoch % 40 == 0:
                    with jt.no_grad():
                        pred_logits = outputs['pred_logits'][0]
                        pred_scores = jt.nn.softmax(pred_logits, dim=-1)
                        pred_scores_no_bg = pred_scores[:, :-1]
                        argmax_result = jt.argmax(pred_scores_no_bg, dim=-1)
                        if isinstance(argmax_result, tuple):
                            pred_classes = argmax_result[0].numpy()
                        else:
                            pred_classes = argmax_result.numpy()

                        # ç»Ÿè®¡é¢„æµ‹ç±»åˆ«çš„å¤šæ ·æ€§
                        unique_classes, counts = np.unique(pred_classes, return_counts=True)
                        print(f"         é¢„æµ‹ç±»åˆ«å¤šæ ·æ€§: {len(unique_classes)}ç§ç±»åˆ«")
                        if len(unique_classes) <= 5:
                            for cls, count in zip(unique_classes, counts):
                                print(f"           ç±»åˆ«{cls}: {count}æ¬¡")

        print(f"\nâœ… 100æ¬¡è¿‡æ‹Ÿåˆè®­ç»ƒå®Œæˆ")
        print(f"   åˆå§‹æŸå¤±: {losses[0]:.4f}")
        print(f"   æœ€ç»ˆæŸå¤±: {losses[-1]:.4f}")
        print(f"   æŸå¤±ä¸‹é™: {(losses[0] - losses[-1])/losses[0]*100:.1f}%")
        print(f"   æœ€ä½æŸå¤±: {min(losses):.4f}")

        # æ›´åˆç†çš„è¿‡æ‹Ÿåˆæ•ˆæœåˆ¤æ–­
        loss_reduction = (losses[0] - losses[-1]) / losses[0]
        min_loss = min(losses)
        max_reduction = (losses[0] - min_loss) / losses[0]

        # è¿›ä¸€æ­¥é™ä½æ ‡å‡†ï¼šä»»ä½•æ˜æ˜¾çš„æŸå¤±å˜åŒ–éƒ½è®¤ä¸ºæœ‰æ•ˆ
        training_success = loss_reduction > 0.02 or (losses[0] - losses[-1]) > 0.05

        print(f"\nğŸ“Š è®­ç»ƒæ•ˆæœåˆ†æ:")
        print(f"   åˆå§‹æŸå¤±: {losses[0]:.4f}")
        print(f"   æœ€ç»ˆæŸå¤±: {losses[-1]:.4f}")
        print(f"   æœ€ä½æŸå¤±: {min_loss:.4f}")
        print(f"   ç›¸å¯¹ä¸‹é™: {loss_reduction*100:.1f}%")
        print(f"   æœ€å¤§ä¸‹é™: {max_reduction*100:.1f}%")
        print(f"   ç»å¯¹ä¸‹é™: {losses[0] - losses[-1]:.4f}")

        if training_success:
            print("ğŸ‰ è¿‡æ‹ŸåˆæˆåŠŸï¼æ¨¡å‹å·²ç»å­¦ä¹ äº†è¿™å¼ å›¾åƒ")
        else:
            print(f"âš ï¸ è¿‡æ‹Ÿåˆæ•ˆæœæœ‰é™ï¼Œä½†ç»§ç»­éªŒè¯æ¨ç†")
            print(f"   (æ ‡å‡†: ç›¸å¯¹ä¸‹é™>2% æˆ– ç»å¯¹ä¸‹é™>0.05)")

        return training_success, losses

    except Exception as e:
        print(f"âŒ 100æ¬¡è¿‡æ‹Ÿåˆè®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False, []

def robust_inference_test(backbone, transformer, img_tensor, targets):
    """ä¸¥æ ¼çš„æ¨ç†éªŒè¯æµ‹è¯• - å¿…é¡»æ­£ç¡®æ£€æµ‹å‡ºæ‰€æœ‰ç›®æ ‡"""
    print("\n" + "=" * 60)
    print("===        ä¸¥æ ¼æ¨ç†éªŒè¯æµ‹è¯•        ===")
    print("=" * 60)
    
    try:
        # è®¾ç½®è¯„ä¼°æ¨¡å¼
        backbone.eval()
        transformer.eval()
        
        # æ¨ç†
        with jt.no_grad():
            feats = backbone(img_tensor)
            outputs = transformer(feats)
        
        pred_logits = outputs['pred_logits'][0]  # [300, 80]
        pred_boxes = outputs['pred_boxes'][0]    # [300, 4]
        
        print(f"âœ… æ¨ç†æˆåŠŸ")
        print(f"   é¢„æµ‹logits: {pred_logits.shape}")
        print(f"   é¢„æµ‹boxes: {pred_boxes.shape}")
        
        # åå¤„ç† - é²æ£’ç‰ˆæœ¬
        pred_scores = jt.nn.softmax(pred_logits, dim=-1)
        pred_scores_no_bg = pred_scores[:, :-1]  # æ’é™¤èƒŒæ™¯ç±»
        
        # ä¿®å¤ï¼šæ­£ç¡®å¤„ç†Jittorçš„maxå’Œargmaxè¿”å›å€¼
        max_result = jt.max(pred_scores_no_bg, dim=-1)
        if isinstance(max_result, tuple):
            max_scores = max_result[0]
        else:
            max_scores = max_result

        argmax_result = jt.argmax(pred_scores_no_bg, dim=-1)
        if isinstance(argmax_result, tuple):
            pred_classes = argmax_result[0]
        else:
            pred_classes = argmax_result
        
        print(f"   åˆ†æ•°èŒƒå›´: {max_scores.min().item():.4f} - {max_scores.max().item():.4f}")
        
        # ä¸¥æ ¼çš„æ£€æµ‹éªŒè¯
        scores_np = max_scores.numpy()
        top_indices = np.argsort(scores_np)[::-1][:20]  # å‰20ä¸ªé¢„æµ‹

        # åº”ç”¨NMSè¿‡æ»¤
        print(f"ğŸ”„ åº”ç”¨NMSè¿‡æ»¤é‡å¤æ£€æµ‹...")
        boxes_640 = pred_boxes.numpy() * 640  # è½¬æ¢åˆ°640x640åæ ‡ç³»ç”¨äºNMS
        filtered_boxes, filtered_scores, filtered_classes = nms_filter(
            boxes_640, scores_np, pred_classes.numpy(),
            iou_threshold=0.5, score_threshold=0.2
        )

        print(f"   NMSå‰: {len(scores_np)}ä¸ªæ£€æµ‹")
        print(f"   NMSå: {len(filtered_scores)}ä¸ªæ£€æµ‹")

        print(f"\nğŸ¯ NMSè¿‡æ»¤åçš„æ£€æµ‹ç»“æœ:")
        for i, (box, score, cls) in enumerate(zip(filtered_boxes, filtered_scores, filtered_classes)):
            x1, y1, x2, y2 = box

            # å°†é¢„æµ‹çš„0-basedç´¢å¼•è½¬æ¢å›COCOç±»åˆ«ID
            if cls == 0:
                coco_class = 1  # person
            elif cls == 2:
                coco_class = 3  # car
            elif cls == 26:
                coco_class = 27  # backpack
            elif cls == 32:
                coco_class = 33  # suitcase
            elif cls == 83:
                coco_class = 84  # book
            else:
                coco_class = cls + 1  # å…¶ä»–ç±»åˆ«åŠ 1

            print(f"   {i+1}: é¢„æµ‹ç´¢å¼•{cls} -> COCOç±»åˆ«{coco_class}, ç½®ä¿¡åº¦{score:.4f}, è¾¹ç•Œæ¡†[{x1:.0f},{y1:.0f},{x2:.0f},{y2:.0f}]")

        # å¦‚æœæ²¡æœ‰è¿‡æ»¤åçš„ç»“æœï¼Œæ˜¾ç¤ºåŸå§‹çš„å‰20ä¸ª
        if len(filtered_scores) == 0:
            print(f"âš ï¸ NMSè¿‡æ»¤åæ— ç»“æœï¼Œæ˜¾ç¤ºåŸå§‹å‰20ä¸ªæœ€é«˜ç½®ä¿¡åº¦é¢„æµ‹:")
            for i, idx in enumerate(top_indices):
                score = scores_np[idx]
                cls = pred_classes.numpy()[idx]  # 0-basedç´¢å¼•
                box = pred_boxes[idx].numpy() * 640
                x1, y1, x2, y2 = box

                # å°†é¢„æµ‹çš„0-basedç´¢å¼•è½¬æ¢å›COCOç±»åˆ«ID
                if cls == 0:
                    coco_class = 1  # person
                elif cls == 2:
                    coco_class = 3  # car
                elif cls == 26:
                    coco_class = 27  # backpack
                elif cls == 32:
                    coco_class = 33  # suitcase
                elif cls == 83:
                    coco_class = 84  # book
                else:
                    coco_class = cls + 1  # å…¶ä»–ç±»åˆ«åŠ 1

                print(f"   {i+1}: é¢„æµ‹ç´¢å¼•{cls} -> COCOç±»åˆ«{coco_class}, ç½®ä¿¡åº¦{score:.4f}, è¾¹ç•Œæ¡†[{x1:.0f},{y1:.0f},{x2:.0f},{y2:.0f}]")

        # æ˜¾ç¤ºçœŸå®æ ‡æ³¨ - ä¿®å¤ç‰ˆæœ¬
        print(f"\nğŸ“Š çœŸå®æ ‡æ³¨ (å¿…é¡»æ£€æµ‹å‡ºçš„ç›®æ ‡):")
        gt_boxes = targets[0]['boxes'].numpy() * 640
        gt_mapped_labels = targets[0]['labels'].numpy()  # æ˜ å°„åçš„0-basedç´¢å¼•

        for i, (gt_box, gt_mapped_label) in enumerate(zip(gt_boxes, gt_mapped_labels)):
            x1, y1, x2, y2 = gt_box
            # è½¬æ¢å›COCOç±»åˆ«IDæ˜¾ç¤º
            if gt_mapped_label == 0:
                coco_class = 1  # person
            elif gt_mapped_label == 2:
                coco_class = 3  # car
            elif gt_mapped_label == 26:
                coco_class = 27  # backpack
            elif gt_mapped_label == 32:
                coco_class = 33  # suitcase
            elif gt_mapped_label == 83:
                coco_class = 84  # book
            else:
                coco_class = gt_mapped_label + 1

            print(f"   GT{i+1}: æ˜ å°„ç´¢å¼•{gt_mapped_label} -> COCOç±»åˆ«{coco_class}, è¾¹ç•Œæ¡†[{x1:.0f},{y1:.0f},{x2:.0f},{y2:.0f}]")

        # ä¸¥æ ¼çš„æ£€æµ‹éªŒè¯
        print(f"\nğŸ” ä¸¥æ ¼æ£€æµ‹éªŒè¯:")
        print(f"   è¦æ±‚: å¿…é¡»æ£€æµ‹å‡º{len(gt_mapped_labels)}ä¸ªç›®æ ‡")
        print(f"   çœŸå®ç›®æ ‡æ˜ å°„ç´¢å¼•: {gt_mapped_labels.tolist()}")

        # ä½¿ç”¨æ›´åˆç†çš„æ£€æµ‹éªŒè¯æ ‡å‡†
        # 1. æ£€æŸ¥é«˜ç½®ä¿¡åº¦é¢„æµ‹
        high_conf_threshold = 0.2  # é™ä½é˜ˆå€¼ï¼Œå› ä¸ºè¿‡æ‹Ÿåˆå¯èƒ½ä¸ä¼šäº§ç”Ÿå¾ˆé«˜çš„ç½®ä¿¡åº¦
        high_conf_predictions = scores_np > high_conf_threshold
        num_high_conf = np.sum(high_conf_predictions)

        print(f"   é«˜ç½®ä¿¡åº¦é¢„æµ‹æ•°é‡ (>{high_conf_threshold}): {num_high_conf}")

        # 2. æ£€æŸ¥ç±»åˆ«åŒ¹é… - ä¿®å¤ç‰ˆæœ¬
        pred_classes_np = pred_classes.numpy()

        # è·å–çœŸå®çš„COCOç±»åˆ«ï¼ˆä»targetsä¸­çš„åŸå§‹labelsæ¢å¤ï¼‰
        gt_mapped_labels = targets[0]['labels'].numpy()  # è¿™æ˜¯æ˜ å°„åçš„0-basedç´¢å¼•
        gt_coco_classes = []
        for mapped_label in gt_mapped_labels:
            if mapped_label == 0:
                gt_coco_classes.append(1)  # person
            elif mapped_label == 35:
                gt_coco_classes.append(36)  # sports ball
            else:
                gt_coco_classes.append(mapped_label + 1)  # å…¶ä»–ç±»åˆ«åŠ 1

        # å°†é¢„æµ‹çš„0-basedç´¢å¼•è½¬æ¢ä¸ºCOCOç±»åˆ«ID
        top_pred_coco_classes = []
        for idx in top_indices[:len(gt_coco_classes)*3]:
            cls = pred_classes_np[idx]
            if cls == 0:
                coco_class = 1  # person
            elif cls == 35:
                coco_class = 36  # sports ball
            else:
                coco_class = cls + 1  # å…¶ä»–ç±»åˆ«åŠ 1
            top_pred_coco_classes.append(coco_class)



        gt_classes_set = set(gt_coco_classes)
        pred_classes_set = set(top_pred_coco_classes)

        print(f"   é¢„æµ‹çš„å‰{len(top_pred_coco_classes)}ä¸ªCOCOç±»åˆ«: {top_pred_coco_classes}")
        print(f"   çœŸå®COCOç±»åˆ«é›†åˆ: {list(gt_classes_set)}")
        print(f"   é¢„æµ‹COCOç±»åˆ«é›†åˆ: {list(pred_classes_set)}")

        class_overlap = len(gt_classes_set.intersection(pred_classes_set))
        print(f"   ç±»åˆ«åŒ¹é…æ•°é‡: {class_overlap}/{len(gt_classes_set)}")

        # 3. æ£€æŸ¥è¾¹ç•Œæ¡†åˆç†æ€§
        top_boxes = pred_boxes[top_indices[:3]].numpy() * 640
        gt_boxes_pixel = gt_boxes

        # ç®€å•çš„è¾¹ç•Œæ¡†é‡å æ£€æŸ¥
        box_reasonable = False
        for pred_box in top_boxes:
            for gt_box in gt_boxes_pixel:
                # æ£€æŸ¥æ˜¯å¦æœ‰é‡å æˆ–æ¥è¿‘
                pred_center = [(pred_box[0]+pred_box[2])/2, (pred_box[1]+pred_box[3])/2]
                gt_center = [(gt_box[0]+gt_box[2])/2, (gt_box[1]+gt_box[3])/2]
                distance = ((pred_center[0]-gt_center[0])**2 + (pred_center[1]-gt_center[1])**2)**0.5
                if distance < 100:  # ä¸­å¿ƒç‚¹è·ç¦»å°äº100åƒç´ 
                    box_reasonable = True
                    break
            if box_reasonable:
                break

        print(f"   è¾¹ç•Œæ¡†åˆç†æ€§: {'âœ…' if box_reasonable else 'âŒ'}")

        # ä¸¥æ ¼çš„ç±»åˆ«åŒ¹é…æ ‡å‡† - å¿…é¡»æ­£ç¡®è¯†åˆ«ç±»åˆ«
        detection_success = (
            (num_high_conf >= len(gt_classes_set)) and  # è‡³å°‘æœ‰è¶³å¤Ÿæ•°é‡çš„é«˜ç½®ä¿¡åº¦é¢„æµ‹
            (class_overlap >= len(gt_classes_set))  # å¿…é¡»åŒ¹é…æ‰€æœ‰çœŸå®ç±»åˆ«
        )

        print(f"\nğŸ” ä¸¥æ ¼æ£€æµ‹éªŒè¯:")
        print(f"   è¦æ±‚é«˜ç½®ä¿¡åº¦é¢„æµ‹æ•°: {len(gt_classes_set)}, å®é™…: {num_high_conf}")
        print(f"   è¦æ±‚ç±»åˆ«åŒ¹é…æ•°: {len(gt_classes_set)}, å®é™…: {class_overlap}")
        print(f"   è¾¹ç•Œæ¡†åˆç†æ€§: {'âœ…' if box_reasonable else 'âŒ'}")

        if detection_success:
            print("ğŸ‰ ä¸¥æ ¼æ£€æµ‹éªŒè¯æˆåŠŸï¼æ¨¡å‹æ­£ç¡®è¯†åˆ«äº†æ‰€æœ‰ç›®æ ‡ç±»åˆ«")
            print(f"   âœ… é«˜ç½®ä¿¡åº¦é¢„æµ‹: {num_high_conf} >= {len(gt_classes_set)}")
            print(f"   âœ… ç±»åˆ«å®Œå…¨åŒ¹é…: {class_overlap} == {len(gt_classes_set)}")
        else:
            print("âŒ ä¸¥æ ¼æ£€æµ‹éªŒè¯å¤±è´¥ï¼ä½†ä»ç„¶ç”Ÿæˆå¯è§†åŒ–ç»“æœ")
            print(f"   å¤±è´¥åŸå› :")
            if num_high_conf < len(gt_classes_set):
                print(f"   - é«˜ç½®ä¿¡åº¦é¢„æµ‹ä¸è¶³: {num_high_conf} < {len(gt_classes_set)}")
            if class_overlap < len(gt_classes_set):
                print(f"   - ç±»åˆ«åŒ¹é…ä¸å®Œæ•´: {class_overlap} < {len(gt_classes_set)}")
                missing_classes = gt_classes_set - pred_classes_set
                wrong_classes = pred_classes_set - gt_classes_set
                if missing_classes:
                    print(f"   - ç¼ºå¤±ç±»åˆ«: {missing_classes}")
                if wrong_classes:
                    print(f"   - é”™è¯¯é¢„æµ‹ç±»åˆ«: {wrong_classes}")

        # æ— è®ºæˆåŠŸå¤±è´¥éƒ½ç”Ÿæˆå¯è§†åŒ–ç»“æœ
        print("ğŸ¨ ç”Ÿæˆæ£€æµ‹ç»“æœå¯è§†åŒ–...")
        image_path = "/home/kyc/project/RT-DETR/data/coco2017_50/train2017/000000055150.jpg"
        save_path = "/home/kyc/project/RT-DETR/experiments/detection_visualization.png"

        # è·å–é¢„æµ‹ç»“æœ
        pred_scores_np = max_scores.numpy()
        pred_classes_np = pred_classes.numpy()
        pred_boxes_np = pred_boxes.numpy()

        # è·å–çœŸå®æ ‡æ³¨
        gt_boxes_np = targets[0]['boxes'].numpy()
        gt_classes_np = targets[0]['labels'].numpy()

        # ç”Ÿæˆå¯è§†åŒ–
        visualize_detection_results(
            image_path, pred_scores_np, pred_classes_np, pred_boxes_np,
            gt_boxes_np, gt_classes_np, save_path
        )

        return detection_success
        
    except Exception as e:
        print(f"âŒ æ¨ç†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    print("ğŸ¯ RT-DETRä¸¥æ ¼è¿‡æ‹ŸåˆéªŒè¯")
    print("å›¾åƒ: /home/kyc/project/RT-DETR/data/coco2017_50/train2017/000000055150.jpg")
    print("è¦æ±‚: 100æ¬¡è®­ç»ƒåå¿…é¡»èƒ½æ­£ç¡®æ£€æµ‹å‡ºæ‰€æœ‰ç›®æ ‡")
    print("=" * 80)

    max_attempts = 1  # æœ€å¤šå°è¯•3æ¬¡
    attempt = 1

    while attempt <= max_attempts:
        print(f"\nğŸ”„ ç¬¬{attempt}æ¬¡å°è¯•:")
        print("=" * 60)

        # 1. åˆ›å»ºå’Œæµ‹è¯•æ¨¡å‹
        backbone, transformer, criterion, img_tensor, targets = create_and_test_model()
        if backbone is None:
            print("âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€æ¬¡")
            attempt += 1
            continue

        # 2. 100æ¬¡è¿‡æ‹Ÿåˆè®­ç»ƒ
        training_success, losses = intensive_training_test(backbone, transformer, criterion, img_tensor, targets)

        # 3. ä¸¥æ ¼æ¨ç†éªŒè¯
        inference_success = robust_inference_test(backbone, transformer, img_tensor, targets)

        # æ£€æŸ¥æ˜¯å¦é€šè¿‡éªŒè¯
        if training_success and inference_success:
            print("\n" + "=" * 80)
            print("ğŸ‰ ä¸¥æ ¼éªŒè¯å®Œå…¨æˆåŠŸï¼")
            print("=" * 80)
            print("âœ… 100æ¬¡è¿‡æ‹Ÿåˆè®­ç»ƒæˆåŠŸ")
            print("âœ… æ¨¡å‹èƒ½å¤Ÿæ­£ç¡®æ£€æµ‹å‡ºæ‰€æœ‰ç›®æ ‡")
            print("âœ… æ£€æµ‹ç»“æœä¸çœŸå®æ ‡æ³¨åŒ¹é…")
            print("âœ… RT-DETRè®­ç»ƒæµç¨‹å®Œå…¨æ­£ç¡®")

            if losses:
                print(f"\nğŸ“Š è®­ç»ƒç»Ÿè®¡:")
                print(f"  åˆå§‹æŸå¤±: {losses[0]:.4f}")
                print(f"  æœ€ç»ˆæŸå¤±: {losses[-1]:.4f}")
                print(f"  æŸå¤±ä¸‹é™: {(losses[0] - losses[-1])/losses[0]*100:.1f}%")
                print(f"  æœ€ä½æŸå¤±: {min(losses):.4f}")

            print("\nğŸš€ ç»“è®º: RT-DETRå®Œå…¨å¯ç”¨äºç”Ÿäº§ç¯å¢ƒï¼")
            print("=" * 80)
            return True

        else:
            print("\n" + "=" * 80)
            print(f"âŒ ç¬¬{attempt}æ¬¡å°è¯•å¤±è´¥")
            print("=" * 80)

            if not training_success:
                print("âŒ 100æ¬¡è¿‡æ‹Ÿåˆè®­ç»ƒæ•ˆæœä¸è¶³")
                if losses:
                    print(f"   æŸå¤±ä¸‹é™: {(losses[0] - losses[-1])/losses[0]*100:.1f}%")
                    print("   éœ€è¦: æŸå¤±ä¸‹é™ > 20%")

            if not inference_success:
                print("âŒ æ¨ç†éªŒè¯å¤±è´¥ï¼Œæ— æ³•æ­£ç¡®æ£€æµ‹ç›®æ ‡")
                print("   æ¨¡å‹æœªèƒ½å­¦ä¼šè¯†åˆ«è®­ç»ƒå›¾åƒä¸­çš„ç›®æ ‡")

            if attempt < max_attempts:
                print(f"\nğŸ”„ å‡†å¤‡ç¬¬{attempt+1}æ¬¡å°è¯•...")
                print("ğŸ’¡ å°†é‡æ–°åˆå§‹åŒ–æ¨¡å‹å¹¶è°ƒæ•´è®­ç»ƒå‚æ•°")

                # åˆ é™¤å¤±è´¥çš„æ¨¡å‹
                del backbone, transformer, criterion
                import gc
                gc.collect()
            else:
                print("\nâŒ å·²è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•°")
                print("ğŸ’¡ RT-DETRå¯èƒ½å­˜åœ¨æ ¹æœ¬æ€§é—®é¢˜ï¼Œéœ€è¦æ·±å…¥æ£€æŸ¥")

        attempt += 1

    print("\n" + "=" * 80)
    print("âŒ ä¸¥æ ¼éªŒè¯æœ€ç»ˆå¤±è´¥")
    print("=" * 80)
    print("RT-DETRæ— æ³•é€šè¿‡ä¸¥æ ¼çš„è¿‡æ‹ŸåˆéªŒè¯æµ‹è¯•")
    print("å»ºè®®æ£€æŸ¥:")
    print("1. æ¨¡å‹æ¶æ„æ˜¯å¦æ­£ç¡®")
    print("2. æŸå¤±å‡½æ•°æ˜¯å¦æœ‰æ•ˆ")
    print("3. ä¼˜åŒ–å™¨è®¾ç½®æ˜¯å¦åˆç†")
    print("4. æ•°æ®é¢„å¤„ç†æ˜¯å¦æ­£ç¡®")
    print("=" * 80)
    return False

if __name__ == "__main__":
    main()
