#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®å‡†å¤‡è„šæœ¬ - ä¸ºå¯¹é½å®éªŒå‡†å¤‡å°‘é‡æ•°æ®é›†
æ”¯æŒCOCOå’ŒVOCæ ¼å¼ï¼Œç¡®ä¿PyTorchå’ŒJittorä½¿ç”¨å®Œå…¨ç›¸åŒçš„æ•°æ®
"""

import os
import json
import shutil
import random
from pathlib import Path
import argparse
from typing import List, Dict, Any


class DatasetPreparer:
    """æ•°æ®é›†å‡†å¤‡å™¨"""
    
    def __init__(self, source_path: str, target_path: str, seed: int = 42):
        self.source_path = Path(source_path)
        self.target_path = Path(target_path)
        self.seed = seed
        random.seed(seed)
        
    def prepare_coco_subset(self, num_images: int = 1000, selected_classes: List[str] = None):
        """å‡†å¤‡COCOå­é›†ç”¨äºå¯¹é½å®éªŒ"""
        if selected_classes is None:
            selected_classes = [
                'person', 'bicycle', 'car', 'motorcycle', 'bus', 'truck',
                'cat', 'dog', 'bottle', 'chair'
            ]
        
        print(f"ğŸ¾ å‡†å¤‡COCOå­é›†: {num_images}å¼ å›¾ç‰‡, {len(selected_classes)}ä¸ªç±»åˆ«")
        
        # åˆ›å»ºç›®æ ‡ç›®å½•
        target_images = self.target_path / "images"
        target_labels = self.target_path / "labels"
        target_images.mkdir(parents=True, exist_ok=True)
        target_labels.mkdir(parents=True, exist_ok=True)
        
        # è¯»å–COCO annotations
        ann_file = self.source_path / "annotations" / "instances_train2017.json"
        with open(ann_file, 'r') as f:
            coco_data = json.load(f)
        
        # åˆ›å»ºç±»åˆ«æ˜ å°„
        class_mapping = {}
        new_categories = []
        for i, class_name in enumerate(selected_classes):
            for cat in coco_data['categories']:
                if cat['name'] == class_name:
                    class_mapping[cat['id']] = i
                    new_categories.append({
                        'id': i,
                        'name': class_name,
                        'supercategory': cat['supercategory']
                    })
                    break
        
        # ç­›é€‰å›¾ç‰‡å’Œæ ‡æ³¨
        valid_images = []
        valid_annotations = []
        
        for img in coco_data['images']:
            img_annotations = [ann for ann in coco_data['annotations'] 
                             if ann['image_id'] == img['id'] and ann['category_id'] in class_mapping]
            if img_annotations:
                valid_images.append(img)
                valid_annotations.extend(img_annotations)
        
        # éšæœºé€‰æ‹©æŒ‡å®šæ•°é‡çš„å›¾ç‰‡
        selected_images = random.sample(valid_images, min(num_images, len(valid_images)))
        selected_image_ids = {img['id'] for img in selected_images}
        
        # å¤åˆ¶å›¾ç‰‡å’Œç”ŸæˆYOLOæ ¼å¼æ ‡ç­¾
        copied_count = 0
        for img in selected_images:
            # å¤åˆ¶å›¾ç‰‡
            src_img = self.source_path / "images" / "train2017" / img['file_name']
            dst_img = target_images / img['file_name']
            if src_img.exists():
                shutil.copy2(src_img, dst_img)
                
                # ç”ŸæˆYOLOæ ¼å¼æ ‡ç­¾
                img_annotations = [ann for ann in valid_annotations 
                                 if ann['image_id'] == img['id']]
                
                label_file = target_labels / (img['file_name'].replace('.jpg', '.txt'))
                with open(label_file, 'w') as f:
                    for ann in img_annotations:
                        if ann['category_id'] in class_mapping:
                            # è½¬æ¢ä¸ºYOLOæ ¼å¼
                            x, y, w, h = ann['bbox']
                            img_w, img_h = img['width'], img['height']
                            
                            # å½’ä¸€åŒ–
                            x_center = (x + w/2) / img_w
                            y_center = (y + h/2) / img_h
                            norm_w = w / img_w
                            norm_h = h / img_h
                            
                            class_id = class_mapping[ann['category_id']]
                            f.write(f"{class_id} {x_center:.6f} {y_center:.6f} {norm_w:.6f} {norm_h:.6f}\n")
                
                copied_count += 1
        
        # ä¿å­˜æ•°æ®é›†ä¿¡æ¯
        dataset_info = {
            'name': 'coco_subset_alignment',
            'num_images': copied_count,
            'num_classes': len(selected_classes),
            'classes': selected_classes,
            'class_mapping': class_mapping,
            'seed': self.seed,
            'source': str(self.source_path)
        }
        
        with open(self.target_path / "dataset_info.json", 'w') as f:
            json.dump(dataset_info, f, indent=2)
        
        # ç”Ÿæˆæ•°æ®é›†é…ç½®æ–‡ä»¶
        self._generate_dataset_yaml(selected_classes)
        
        print(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆ: {copied_count}å¼ å›¾ç‰‡")
        return dataset_info
    
    def _generate_dataset_yaml(self, classes: List[str]):
        """ç”Ÿæˆæ•°æ®é›†YAMLé…ç½®æ–‡ä»¶"""
        yaml_content = f"""# Gold-YOLOå¯¹é½å®éªŒæ•°æ®é›†é…ç½®
path: {self.target_path.absolute()}
train: images
val: images  # ä½¿ç”¨ç›¸åŒæ•°æ®è¿›è¡ŒéªŒè¯ï¼ˆå¯¹é½å®éªŒï¼‰

# ç±»åˆ«æ•°é‡
nc: {len(classes)}

# ç±»åˆ«åç§°
names: {classes}
"""
        
        with open(self.target_path / "dataset.yaml", 'w') as f:
            f.write(yaml_content)
    
    def split_train_val(self, val_ratio: float = 0.2):
        """åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†"""
        images_dir = self.target_path / "images"
        labels_dir = self.target_path / "labels"
        
        # åˆ›å»ºtrain/valç›®å½•
        for split in ['train', 'val']:
            (self.target_path / "images" / split).mkdir(exist_ok=True)
            (self.target_path / "labels" / split).mkdir(exist_ok=True)
        
        # è·å–æ‰€æœ‰å›¾ç‰‡
        image_files = list(images_dir.glob("*.jpg"))
        random.shuffle(image_files)
        
        # åˆ’åˆ†æ•°æ®
        val_count = int(len(image_files) * val_ratio)
        val_files = image_files[:val_count]
        train_files = image_files[val_count:]
        
        # ç§»åŠ¨æ–‡ä»¶
        for img_file in train_files:
            label_file = labels_dir / (img_file.stem + '.txt')
            shutil.move(img_file, self.target_path / "images" / "train" / img_file.name)
            if label_file.exists():
                shutil.move(label_file, self.target_path / "labels" / "train" / label_file.name)
        
        for img_file in val_files:
            label_file = labels_dir / (img_file.stem + '.txt')
            shutil.move(img_file, self.target_path / "images" / "val" / img_file.name)
            if label_file.exists():
                shutil.move(label_file, self.target_path / "labels" / "val" / label_file.name)
        
        # åˆ é™¤åŸå§‹ç›®å½•
        if images_dir.exists() and not any(images_dir.iterdir()):
            images_dir.rmdir()
        if labels_dir.exists() and not any(labels_dir.iterdir()):
            labels_dir.rmdir()
        
        print(f"âœ… æ•°æ®åˆ’åˆ†å®Œæˆ: è®­ç»ƒé›†{len(train_files)}å¼ , éªŒè¯é›†{len(val_files)}å¼ ")


def main():
    parser = argparse.ArgumentParser(description='å‡†å¤‡å¯¹é½å®éªŒæ•°æ®é›†')
    parser.add_argument('--source', type=str, required=True, help='æºæ•°æ®é›†è·¯å¾„')
    parser.add_argument('--target', type=str, default='./data/alignment_dataset', help='ç›®æ ‡æ•°æ®é›†è·¯å¾„')
    parser.add_argument('--num_images', type=int, default=1000, help='å›¾ç‰‡æ•°é‡')
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­')
    parser.add_argument('--split', action='store_true', help='æ˜¯å¦åˆ’åˆ†è®­ç»ƒéªŒè¯é›†')
    
    args = parser.parse_args()
    
    # é€‰æ‹©çš„ç±»åˆ«ï¼ˆç¡®ä¿PyTorchå’ŒJittorä½¿ç”¨ç›¸åŒçš„ç±»åˆ«ï¼‰
    selected_classes = [
        'person', 'bicycle', 'car', 'motorcycle', 'bus', 'truck',
        'cat', 'dog', 'bottle', 'chair'
    ]
    
    preparer = DatasetPreparer(args.source, args.target, args.seed)
    dataset_info = preparer.prepare_coco_subset(args.num_images, selected_classes)
    
    if args.split:
        preparer.split_train_val()
    
    print(f"\nğŸ‰ æ•°æ®å‡†å¤‡å®Œæˆ!")
    print(f"ğŸ“ æ•°æ®è·¯å¾„: {args.target}")
    print(f"ğŸ“Š æ•°æ®ä¿¡æ¯: {dataset_info}")


if __name__ == "__main__":
    main()
