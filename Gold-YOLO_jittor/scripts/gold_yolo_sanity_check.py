#!/usr/bin/env python3
"""
Gold-YOLO Jittor ç»ˆææµç¨‹è‡ªæ£€è„šæœ¬
é€šè¿‡è¿‡æ‹Ÿåˆæµ‹è¯•éªŒè¯Gold-YOLO Jittorç‰ˆæœ¬çš„åŠŸèƒ½æ˜¯å¦æ­£ç¡®
"""

import os
import sys
import json
import random
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import matplotlib
import gc

# è®¾ç½®matplotlibæ”¯æŒä¸­æ–‡å­—ä½“
matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei', 'Arial Unicode MS', 'sans-serif']
matplotlib.rcParams['axes.unicode_minus'] = False

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/home/kyc/project/GOLD-YOLO/Gold-YOLO_jittor')

import jittor as jt
import jittor.nn as nn

# è®¾ç½®Jittor
jt.flags.use_cuda = 1
jt.set_global_seed(42)

# COCOç±»åˆ«åç§°æ˜ å°„
COCO_CLASSES = {
    1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane',
    6: 'bus', 7: 'train', 8: 'truck', 9: 'boat', 10: 'traffic light',
    11: 'fire hydrant', 13: 'stop sign', 14: 'parking meter', 15: 'bench',
    16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse', 20: 'sheep',
    21: 'cow', 22: 'elephant', 23: 'bear', 24: 'zebra', 25: 'giraffe',
    27: 'backpack', 28: 'umbrella', 31: 'handbag', 32: 'tie', 33: 'suitcase',
    34: 'frisbee', 35: 'skis', 36: 'snowboard', 37: 'sports ball', 38: 'kite',
    39: 'baseball bat', 40: 'baseball glove', 41: 'skateboard', 42: 'surfboard',
    43: 'tennis racket', 44: 'bottle', 46: 'wine glass', 47: 'cup',
    48: 'fork', 49: 'knife', 50: 'spoon', 51: 'bowl', 52: 'banana',
    53: 'apple', 54: 'sandwich', 55: 'orange', 56: 'broccoli', 57: 'carrot',
    58: 'hot dog', 59: 'pizza', 60: 'donut', 61: 'cake', 62: 'chair',
    63: 'couch', 64: 'potted plant', 65: 'bed', 67: 'dining table',
    70: 'toilet', 72: 'tv', 73: 'laptop', 74: 'mouse', 75: 'remote',
    76: 'keyboard', 77: 'cell phone', 78: 'microwave', 79: 'oven',
    80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book',
    85: 'clock', 86: 'vase', 87: 'scissors', 88: 'teddy bear',
    89: 'hair drier', 90: 'toothbrush'
}

def select_random_image():
    """ä»æ•°æ®é›†ä¸­éšæœºé€‰æ‹©ä¸€å¼ å›¾ç‰‡"""
    data_dir = "/home/kyc/project/GOLD-YOLO/data/coco2017_50/train2017"
    annotation_path = "/home/kyc/project/GOLD-YOLO/data/coco2017_50/annotations/instances_train2017.json"
    
    if not os.path.exists(data_dir) or not os.path.exists(annotation_path):
        print("âŒ æ•°æ®é›†ä¸å­˜åœ¨")
        return None, None, None
    
    # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    image_files = [f for f in os.listdir(data_dir) if f.endswith('.jpg')]
    if not image_files:
        print("âŒ æ•°æ®é›†ä¸­æ²¡æœ‰å›¾ç‰‡")
        return None, None, None
    
    # éšæœºé€‰æ‹©ä¸€å¼ å›¾ç‰‡
    selected_image = random.choice(image_files)
    image_path = os.path.join(data_dir, selected_image)
    image_id = int(selected_image.split('.')[0])
    
    print(f"ğŸ¯ éšæœºé€‰æ‹©å›¾ç‰‡: {selected_image} (ID: {image_id})")
    
    return image_path, image_id, annotation_path

def load_and_verify_data(image_path, image_id, annotation_path):
    """åŠ è½½å¹¶éªŒè¯æ•°æ®"""
    print("ğŸ” åŠ è½½æ•°æ®...")
    
    # åŠ è½½å›¾åƒ
    image = Image.open(image_path).convert('RGB')
    original_width, original_height = image.size
    print(f"åŸå§‹å›¾åƒå°ºå¯¸: {original_width}x{original_height}")
    
    # è°ƒæ•´å›¾åƒå¤§å°åˆ°640x640
    image_resized = image.resize((640, 640), Image.LANCZOS)
    
    # è½¬æ¢ä¸ºå¼ é‡
    img_array = np.array(image_resized).astype(np.float32) / 255.0
    img_tensor = jt.array(img_array.transpose(2, 0, 1)).float32().unsqueeze(0)
    
    # åŠ è½½æ ‡æ³¨
    with open(annotation_path, 'r') as f:
        coco_data = json.load(f)
    
    annotations = []
    labels = []
    
    print(f"æŸ¥æ‰¾å›¾åƒID {image_id} çš„æ ‡æ³¨...")
    
    for ann in coco_data['annotations']:
        if ann['image_id'] == image_id:
            x, y, w, h = ann['bbox']
            category_id = ann['category_id']
            
            print(f"æ‰¾åˆ°æ ‡æ³¨: ç±»åˆ«{category_id}, è¾¹ç•Œæ¡†[{x},{y},{w},{h}]")
            
            # å½’ä¸€åŒ–åæ ‡
            x1, y1 = x / original_width, y / original_height
            x2, y2 = (x + w) / original_width, (y + h) / original_height
            
            # ç¡®ä¿åæ ‡æœ‰æ•ˆ
            if x2 > x1 and y2 > y1 and x1 >= 0 and y1 >= 0 and x2 <= 1 and y2 <= 1:
                annotations.append([x1, y1, x2, y2])
                labels.append(category_id - 1)  # è½¬æ¢ä¸º0-basedç´¢å¼•
                print(f"   å½’ä¸€åŒ–å: [{x1:.3f},{y1:.3f},{x2:.3f},{y2:.3f}], ç±»åˆ«ç´¢å¼•: {category_id-1}")
    
    if not annotations:
        print("âš ï¸ è¯¥å›¾ç‰‡æ²¡æœ‰æœ‰æ•ˆæ ‡æ³¨ï¼Œé‡æ–°é€‰æ‹©å›¾ç‰‡")
        return None, None, None
    
    # åˆ›å»ºç›®æ ‡
    target = {
        'boxes': jt.array(annotations, dtype=jt.float32),
        'labels': jt.array(labels, dtype=jt.int64)
    }
    
    print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ")
    print(f"   å›¾åƒ: {img_tensor.shape}")
    print(f"   ç›®æ ‡: {len(annotations)}ä¸ªè¾¹ç•Œæ¡†")
    print(f"   ç±»åˆ«: {labels}")
    
    return img_tensor, target, image

def create_and_test_model():
    """åˆ›å»ºå¹¶æµ‹è¯•Gold-YOLOæ¨¡å‹"""
    print("\n" + "=" * 60)
    print("===        Gold-YOLOæ¨¡å‹åˆ›å»ºå’Œæµ‹è¯•        ===")
    print("=" * 60)
    
    try:
        from models.yolo import Model
        from models.loss import GoldYOLOLoss
        from configs.gold_yolo_s import get_config

        # åŠ è½½é…ç½®
        config = get_config()

        # åˆ›å»ºæ¨¡å‹
        model = Model(config=config, channels=3, num_classes=80)
        criterion = GoldYOLOLoss(num_classes=80)
        
        print(f"âœ… Gold-YOLOæ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        img_tensor, target, original_image = load_and_verify_data(*select_random_image())
        if img_tensor is None:
            return None, None, None, None, None
        
        print("\næµ‹è¯•å‰å‘ä¼ æ’­...")
        model.train()
        outputs = model(img_tensor)
        
        print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"   è¾“å‡ºç±»å‹: {type(outputs)}")
        if isinstance(outputs, list):
            print(f"   è¾“å‡ºåˆ—è¡¨é•¿åº¦: {len(outputs)}")
            if len(outputs) >= 2:
                detection_output, featmaps = outputs
                print(f"   æ£€æµ‹è¾“å‡ºç±»å‹: {type(detection_output)}")
                print(f"   ç‰¹å¾å›¾æ•°é‡: {len(featmaps)}")
        
        # æµ‹è¯•æŸå¤±è®¡ç®—
        print("\næµ‹è¯•æŸå¤±è®¡ç®—...")
        batch = {'cls': target['labels'].unsqueeze(0), 'bboxes': target['boxes'].unsqueeze(0)}
        loss, loss_items = criterion(outputs, batch)
        
        print(f"âœ… æŸå¤±è®¡ç®—æˆåŠŸ: {loss.item():.4f}")
        print(f"   æŸå¤±åˆ†é‡: {loss_items.numpy()}")

        # æµ‹è¯•è®­ç»ƒå‰çš„æ¨ç†èƒ½åŠ›
        print("\næµ‹è¯•è®­ç»ƒå‰æ¨ç†èƒ½åŠ›...")
        model.eval()
        with jt.no_grad():
            outputs = model(img_tensor)

        detections = strict_post_process(outputs, conf_thres=0.3, iou_thres=0.5, max_det=20)
        det = detections[0]

        print(f"âœ… è®­ç»ƒå‰æ¨ç†æˆåŠŸ")
        print(f"   æ£€æµ‹åˆ° {det.shape[0]} ä¸ªç›®æ ‡")

        if det.shape[0] > 0:
            print(f"   ç½®ä¿¡åº¦èŒƒå›´: [{det[:, 4].min().item():.3f}, {det[:, 4].max().item():.3f}]")
            print(f"   æ£€æµ‹ç±»åˆ«: {set(det[:, 5].numpy().astype(int))}")
            print("ğŸ‰ è®­ç»ƒå‰æ¨¡å‹å…·å¤‡æ£€æµ‹èƒ½åŠ›ï¼")
        else:
            print("âš ï¸ è®­ç»ƒå‰æ¨¡å‹æ— æ£€æµ‹èƒ½åŠ›")

        # åˆ‡æ¢å›è®­ç»ƒæ¨¡å¼
        model.train()

        return model, criterion, img_tensor, target, original_image
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, None, None, None, None

def intensive_overfitting_test(model, criterion, img_tensor, target):
    """å¼ºåŒ–è¿‡æ‹Ÿåˆè®­ç»ƒæµ‹è¯•"""
    print("\n" + "=" * 60)
    print("===        å¼ºåŒ–è¿‡æ‹Ÿåˆè®­ç»ƒæµ‹è¯•        ===")
    print("=" * 60)
    
    try:
        # è®¾ç½®è®­ç»ƒæ¨¡å¼
        model.train()
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = jt.optim.Adam(model.parameters(), lr=1e-3)
        
        # å‡†å¤‡batchæ•°æ®
        batch = {'cls': target['labels'].unsqueeze(0), 'bboxes': target['boxes'].unsqueeze(0)}
        
        print(f"å¼€å§‹100æ¬¡è¿‡æ‹Ÿåˆè®­ç»ƒ...")
        print(f"ç›®æ ‡: æ¨¡å‹å¿…é¡»èƒ½å¤Ÿå®Œç¾è®°ä½è¿™å¼ å›¾åƒçš„æ‰€æœ‰ç›®æ ‡")
        
        losses = []
        num_epochs = 100
        
        for epoch in range(num_epochs):
            # å‰å‘ä¼ æ’­
            outputs = model(img_tensor)
            
            # æŸå¤±è®¡ç®—
            loss, loss_items = criterion(outputs, batch)
            losses.append(loss.item())
            
            # åå‘ä¼ æ’­å’Œå‚æ•°æ›´æ–° - ä½¿ç”¨Jittorçš„æ­£ç¡®è¯­æ³•
            optimizer.step(loss)
            
            # æ‰“å°è¿›åº¦
            if epoch % 20 == 0 or epoch < 5 or epoch >= 95:
                print(f"Epoch {epoch:3d}: æŸå¤±={loss.item():.4f}")
        
        print(f"\nâœ… 100æ¬¡è¿‡æ‹Ÿåˆè®­ç»ƒå®Œæˆ")
        print(f"   åˆå§‹æŸå¤±: {losses[0]:.4f}")
        print(f"   æœ€ç»ˆæŸå¤±: {losses[-1]:.4f}")
        print(f"   æŸå¤±ä¸‹é™: {(losses[0] - losses[-1])/losses[0]*100:.1f}%")
        print(f"   æœ€ä½æŸå¤±: {min(losses):.4f}")
        
        # åˆ¤æ–­è¿‡æ‹Ÿåˆæ•ˆæœ
        loss_reduction = (losses[0] - losses[-1]) / losses[0]
        training_success = loss_reduction > 0.1  # æŸå¤±ä¸‹é™è¶…è¿‡10%
        
        if training_success:
            print("ğŸ‰ è¿‡æ‹ŸåˆæˆåŠŸï¼æ¨¡å‹å·²ç»å­¦ä¹ äº†è¿™å¼ å›¾åƒ")
        else:
            print(f"âš ï¸ è¿‡æ‹Ÿåˆæ•ˆæœæœ‰é™ï¼ŒæŸå¤±ä¸‹é™ä»…{loss_reduction*100:.1f}%")
        
        return training_success, losses
        
    except Exception as e:
        print(f"âŒ è¿‡æ‹Ÿåˆè®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False, []

def strict_post_process(prediction, conf_thres=0.5, iou_thres=0.5, max_det=50):
    """ä¸¥æ ¼çš„åå¤„ç†å‡½æ•° - ç¡®ä¿æ£€æµ‹ç»“æœåˆç†"""

    # è¾“å…¥æ ¼å¼: [batch, num_anchors, 5+num_classes]
    # è¾“å‡ºæ ¼å¼: [batch, num_detections, 6] (x1, y1, x2, y2, conf, cls)

    batch_size = prediction.shape[0]
    num_anchors = prediction.shape[1]
    num_classes = prediction.shape[2] - 5

    output = []

    for i in range(batch_size):
        pred = prediction[i]  # [num_anchors, 5+num_classes]

        # è½¬æ¢ä¸ºnumpyè¿›è¡Œå¤„ç†
        pred_np = pred.numpy()

        # æå–å„éƒ¨åˆ†
        boxes = pred_np[:, :4]  # [x1, y1, x2, y2]
        obj_conf = pred_np[:, 4]  # ç›®æ ‡ç½®ä¿¡åº¦
        cls_scores = pred_np[:, 5:]  # ç±»åˆ«åˆ†æ•°

        # è®¡ç®—æœ€ç»ˆç½®ä¿¡åº¦å’Œç±»åˆ«
        class_conf = np.max(cls_scores, axis=1)
        class_pred = np.argmax(cls_scores, axis=1)
        final_conf = obj_conf * class_conf

        # ä¸¥æ ¼çš„ç½®ä¿¡åº¦è¿‡æ»¤
        valid_mask = final_conf > conf_thres

        if not np.any(valid_mask):
            output.append(jt.zeros((0, 6)))
            continue

        # åº”ç”¨æ©ç 
        valid_boxes = boxes[valid_mask]
        valid_conf = final_conf[valid_mask]
        valid_cls = class_pred[valid_mask]

        # è¿‡æ»¤æ— æ•ˆè¾¹ç•Œæ¡†
        valid_indices = []
        for idx, box in enumerate(valid_boxes):
            x1, y1, x2, y2 = box
            # æ£€æŸ¥è¾¹ç•Œæ¡†æ˜¯å¦æœ‰æ•ˆ
            if x2 > x1 and y2 > y1 and x1 >= 0 and y1 >= 0:
                # æ£€æŸ¥è¾¹ç•Œæ¡†å¤§å°æ˜¯å¦åˆç†
                width = x2 - x1
                height = y2 - y1
                area = width * height
                if area > 1:  # æœ€å°é¢ç§¯é˜ˆå€¼ (é™ä½è¦æ±‚)
                    valid_indices.append(idx)

        if len(valid_indices) == 0:
            output.append(jt.zeros((0, 6)))
            continue

        # åº”ç”¨æœ‰æ•ˆæ€§è¿‡æ»¤
        valid_boxes = valid_boxes[valid_indices]
        valid_conf = valid_conf[valid_indices]
        valid_cls = valid_cls[valid_indices]

        # ç®€åŒ–çš„NMS - æŒ‰ç½®ä¿¡åº¦æ’åºå¹¶ç§»é™¤é‡å æ¡†
        sort_indices = np.argsort(valid_conf)[::-1]  # é™åº
        valid_boxes = valid_boxes[sort_indices]
        valid_conf = valid_conf[sort_indices]
        valid_cls = valid_cls[sort_indices]

        # ç®€å•çš„NMSå®ç°
        keep_indices = []
        for i in range(len(valid_boxes)):
            if i == 0:
                keep_indices.append(i)
                continue

            # è®¡ç®—ä¸å·²ä¿ç•™æ¡†çš„IoU
            current_box = valid_boxes[i]
            should_keep = True

            for kept_idx in keep_indices:
                kept_box = valid_boxes[kept_idx]
                iou = calculate_iou(current_box, kept_box)
                if iou > iou_thres:
                    should_keep = False
                    break

            if should_keep:
                keep_indices.append(i)

        # åº”ç”¨NMSç»“æœ
        if len(keep_indices) > 0:
            final_boxes = valid_boxes[keep_indices]
            final_conf = valid_conf[keep_indices]
            final_cls = valid_cls[keep_indices]

            # é™åˆ¶æ£€æµ‹æ•°é‡
            if len(final_conf) > max_det:
                final_boxes = final_boxes[:max_det]
                final_conf = final_conf[:max_det]
                final_cls = final_cls[:max_det]

            # ç»„åˆç»“æœ
            detections = np.column_stack([
                final_boxes,  # [x1, y1, x2, y2]
                final_conf.reshape(-1, 1),  # confidence
                final_cls.reshape(-1, 1)    # class
            ])
            output.append(jt.array(detections))
        else:
            output.append(jt.zeros((0, 6)))

    return output

def calculate_iou(box1, box2):
    """è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„IoU"""
    x1_1, y1_1, x2_1, y2_1 = box1
    x1_2, y1_2, x2_2, y2_2 = box2

    # è®¡ç®—äº¤é›†
    x1_inter = max(x1_1, x1_2)
    y1_inter = max(y1_1, y1_2)
    x2_inter = min(x2_1, x2_2)
    y2_inter = min(y2_1, y2_2)

    if x2_inter <= x1_inter or y2_inter <= y1_inter:
        return 0.0

    inter_area = (x2_inter - x1_inter) * (y2_inter - y1_inter)

    # è®¡ç®—å¹¶é›†
    area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
    area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
    union_area = area1 + area2 - inter_area

    if union_area <= 0:
        return 0.0

    return inter_area / union_area

def scale_coords(img1_shape, coords, img0_shape):
    """å°†åæ ‡ä»img1_shapeç¼©æ”¾åˆ°img0_shape"""
    gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])
    pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2

    coords[:, [0, 2]] -= pad[0]  # x padding
    coords[:, [1, 3]] -= pad[1]  # y padding
    coords[:, :4] /= gain

    # é™åˆ¶åæ ‡èŒƒå›´
    coords[:, 0] = jt.clamp(coords[:, 0], 0, img0_shape[1])  # x1
    coords[:, 1] = jt.clamp(coords[:, 1], 0, img0_shape[0])  # y1
    coords[:, 2] = jt.clamp(coords[:, 2], 0, img0_shape[1])  # x2
    coords[:, 3] = jt.clamp(coords[:, 3], 0, img0_shape[0])  # y2

    return coords

def inference_and_visualization_test(model, img_tensor, target, original_image):
    """æ¨ç†å’Œå¯è§†åŒ–æµ‹è¯• - å®Œæ•´ç‰ˆæœ¬"""
    print("\n" + "=" * 60)
    print("===        æ¨ç†å’Œå¯è§†åŒ–æµ‹è¯•        ===")
    print("=" * 60)

    try:
        # è®¾ç½®è¯„ä¼°æ¨¡å¼
        model.eval()

        # æ¨ç†
        with jt.no_grad():
            outputs = model(img_tensor)

        print(f"âœ… æ¨ç†æˆåŠŸ")
        print(f"   è¾“å‡ºç±»å‹: {type(outputs)}")
        print(f"   è¾“å‡ºå½¢çŠ¶: {outputs.shape}")

        # åå¤„ç†
        print("ğŸ”„ å¼€å§‹åå¤„ç†...")
        detections = strict_post_process(outputs, conf_thres=0.3, iou_thres=0.5, max_det=20)
        det = detections[0]  # ç¬¬ä¸€ä¸ªbatch

        print(f"   æ£€æµ‹åˆ° {det.shape[0]} ä¸ªç›®æ ‡")

        # åæ ‡ç¼©æ”¾
        if det.shape[0] > 0:
            # ä»640x640ç¼©æ”¾åˆ°åŸå§‹å›¾åƒå°ºå¯¸
            det[:, :4] = scale_coords((640, 640), det[:, :4], (original_image.height, original_image.width))

        # ç”Ÿæˆå¯è§†åŒ–
        save_path = "/home/kyc/project/GOLD-YOLO/Gold-YOLO_jittor/experiments/detection_visualization.png"
        os.makedirs(os.path.dirname(save_path), exist_ok=True)

        # åˆ›å»ºå¯è§†åŒ–
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))

        # å·¦ä¾§ï¼šåŸå›¾å’ŒçœŸå®æ ‡æ³¨
        ax1.imshow(original_image)
        ax1.set_title('Ground Truth', fontsize=16, fontweight='bold')
        ax1.axis('off')

        # ç»˜åˆ¶çœŸå®è¾¹ç•Œæ¡†
        gt_boxes = target['boxes'].numpy()
        gt_labels = target['labels'].numpy()

        for i, (box, label) in enumerate(zip(gt_boxes, gt_labels)):
            x1, y1, x2, y2 = box
            x1 *= original_image.width
            y1 *= original_image.height
            x2 *= original_image.width
            y2 *= original_image.height

            rect = patches.Rectangle(
                (x1, y1), x2 - x1, y2 - y1,
                linewidth=3, edgecolor='green', facecolor='none'
            )
            ax1.add_patch(rect)

            class_name = COCO_CLASSES.get(label + 1, f'class_{label + 1}')
            ax1.text(
                x1, y1 - 10, f'GT: {class_name}',
                bbox=dict(boxstyle='round,pad=0.3', facecolor='green', alpha=0.8),
                fontsize=12, fontweight='bold', color='white'
            )

        # å³ä¾§ï¼šé¢„æµ‹ç»“æœ
        ax2.imshow(original_image)
        ax2.set_title(f'Predictions ({det.shape[0]} detections)', fontsize=16, fontweight='bold')
        ax2.axis('off')

        # ç»˜åˆ¶é¢„æµ‹è¾¹ç•Œæ¡†
        if det.shape[0] > 0:
            det_np = det.numpy()
            for i, detection in enumerate(det_np):
                x1, y1, x2, y2, conf, cls = detection

                # åªæ˜¾ç¤ºé«˜ç½®ä¿¡åº¦çš„æ£€æµ‹
                if conf > 0.3:
                    rect = patches.Rectangle(
                        (x1, y1), x2 - x1, y2 - y1,
                        linewidth=3, edgecolor='red', facecolor='none'
                    )
                    ax2.add_patch(rect)

                    class_name = COCO_CLASSES.get(int(cls) + 1, f'class_{int(cls) + 1}')
                    ax2.text(
                        x1, y1 - 10, f'{class_name}: {conf:.2f}',
                        bbox=dict(boxstyle='round,pad=0.3', facecolor='red', alpha=0.8),
                        fontsize=12, fontweight='bold', color='white'
                    )
        else:
            ax2.text(
                original_image.width // 2, original_image.height // 2,
                'No detections found\n(confidence threshold: 0.3)',
                ha='center', va='center', fontsize=16,
                bbox=dict(boxstyle='round,pad=1', facecolor='orange', alpha=0.8)
            )

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ… å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {save_path}")

        # ä¸¥æ ¼çš„æ£€æµ‹æ•ˆæœè¯„ä¼°
        print("\nğŸ“Š ä¸¥æ ¼æ£€æµ‹æ•ˆæœè¯„ä¼°:")
        print(f"   çœŸå®ç›®æ ‡æ•°é‡: {len(gt_labels)}")
        print(f"   æ£€æµ‹ç›®æ ‡æ•°é‡: {det.shape[0]}")

        # è‡ªæ£€æˆåŠŸçš„ä¸¥æ ¼æ ‡å‡†
        success_criteria = {
            'quantity_match': False,
            'category_match': False,
            'position_match': False
        }

        if det.shape[0] > 0:
            high_conf_dets = det[det[:, 4] > 0.3]
            print(f"   é«˜ç½®ä¿¡åº¦æ£€æµ‹ (>0.3): {high_conf_dets.shape[0]}")

            if high_conf_dets.shape[0] > 0:
                print(f"   æœ€é«˜ç½®ä¿¡åº¦: {high_conf_dets[:, 4].max().item():.3f}")
                print(f"   å¹³å‡ç½®ä¿¡åº¦: {high_conf_dets[:, 4].mean().item():.3f}")

                # 1. æ£€æŸ¥æ•°é‡åŒ¹é… (å…è®¸Â±1çš„è¯¯å·®)
                quantity_diff = abs(high_conf_dets.shape[0] - len(gt_labels))
                if quantity_diff <= 1:
                    success_criteria['quantity_match'] = True
                    print(f"   âœ… æ•°é‡åŒ¹é…: æ£€æµ‹{high_conf_dets.shape[0]}ä¸ª vs çœŸå®{len(gt_labels)}ä¸ª")
                else:
                    print(f"   âŒ æ•°é‡ä¸åŒ¹é…: æ£€æµ‹{high_conf_dets.shape[0]}ä¸ª vs çœŸå®{len(gt_labels)}ä¸ª")

                # 2. æ£€æŸ¥ç±»åˆ«åŒ¹é…
                detected_classes = set(high_conf_dets[:, 5].numpy().astype(int))
                gt_classes = set(gt_labels)

                # è®¡ç®—ç±»åˆ«åŒ¹é…åº¦
                intersection = detected_classes.intersection(gt_classes)
                union = detected_classes.union(gt_classes)
                class_match_ratio = len(intersection) / len(union) if len(union) > 0 else 0

                if class_match_ratio >= 0.5:  # è‡³å°‘50%çš„ç±»åˆ«åŒ¹é…
                    success_criteria['category_match'] = True
                    print(f"   âœ… ç±»åˆ«åŒ¹é…: {class_match_ratio:.1%} (æ£€æµ‹åˆ°: {detected_classes}, çœŸå®: {gt_classes})")
                else:
                    print(f"   âŒ ç±»åˆ«ä¸åŒ¹é…: {class_match_ratio:.1%} (æ£€æµ‹åˆ°: {detected_classes}, çœŸå®: {gt_classes})")

                # 3. æ£€æŸ¥ä½ç½®åŒ¹é… (ç®€åŒ–ç‰ˆæœ¬)
                if len(gt_labels) > 0 and high_conf_dets.shape[0] > 0:
                    # è®¡ç®—æ£€æµ‹æ¡†ä¸çœŸå®æ¡†çš„æœ€å¤§IoU
                    max_ious = []
                    gt_boxes_scaled = target['boxes'].numpy()

                    for gt_box in gt_boxes_scaled:
                        gt_x1 = gt_box[0] * original_image.width
                        gt_y1 = gt_box[1] * original_image.height
                        gt_x2 = gt_box[2] * original_image.width
                        gt_y2 = gt_box[3] * original_image.height
                        gt_box_scaled = [gt_x1, gt_y1, gt_x2, gt_y2]

                        best_iou = 0
                        for det_box in high_conf_dets[:, :4].numpy():
                            iou = calculate_iou(det_box, gt_box_scaled)
                            best_iou = max(best_iou, iou)
                        max_ious.append(best_iou)

                    avg_iou = np.mean(max_ious) if max_ious else 0
                    if avg_iou >= 0.3:  # å¹³å‡IoU >= 0.3
                        success_criteria['position_match'] = True
                        print(f"   âœ… ä½ç½®åŒ¹é…: å¹³å‡IoU = {avg_iou:.3f}")
                    else:
                        print(f"   âŒ ä½ç½®ä¸åŒ¹é…: å¹³å‡IoU = {avg_iou:.3f}")
                else:
                    print(f"   âŒ æ— æ³•è®¡ç®—ä½ç½®åŒ¹é…")
        else:
            print(f"   âŒ æ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡")

        # ç»¼åˆè¯„ä¼°
        passed_criteria = sum(success_criteria.values())
        total_criteria = len(success_criteria)

        print(f"\nğŸ¯ è‡ªæ£€ç»“æœ: {passed_criteria}/{total_criteria} é¡¹é€šè¿‡")
        for criterion, passed in success_criteria.items():
            status = "âœ…" if passed else "âŒ"
            print(f"   {status} {criterion}")

        plt.close()  # å…³é—­å›¾å½¢ä»¥èŠ‚çœå†…å­˜

        # åªæœ‰æ‰€æœ‰æ ‡å‡†éƒ½é€šè¿‡æ‰ç®—æˆåŠŸ
        return passed_criteria == total_criteria

    except Exception as e:
        print(f"âŒ æ¨ç†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def cleanup_failed_model():
    """æ¸…ç†å¤±è´¥çš„æ¨¡å‹"""
    print("ğŸ§¹ æ¸…ç†å¤±è´¥çš„æ¨¡å‹...")
    gc.collect()
    jt.gc()

def main():
    """ä¸»å‡½æ•° - å®Œæ•´çš„è‡ªæ£€æµç¨‹"""
    print("ğŸ¯ Gold-YOLO Jittor ç»ˆææµç¨‹è‡ªæ£€")
    print("=" * 80)
    print("ç›®æ ‡: é€šè¿‡è¿‡æ‹Ÿåˆæµ‹è¯•éªŒè¯Gold-YOLOåŠŸèƒ½æ˜¯å¦æ­£ç¡®")
    print("è¦æ±‚: èƒ½å¤Ÿå‡†ç¡®è¯†åˆ«å›¾ç‰‡ä¸­çš„ç‰©ä½“ç±»åˆ«å’Œæ•°ç›®ï¼Œä¸”æ£€æµ‹æ¡†ä½ç½®åˆç†")
    print("=" * 80)

    max_attempts = 1  # æœ€å¤šå°è¯•3æ¬¡
    attempt = 1

    while attempt <= max_attempts:
        print(f"\nğŸ”„ ç¬¬{attempt}æ¬¡å°è¯•:")
        print("=" * 60)

        try:
            # 1. åˆ›å»ºå’Œæµ‹è¯•æ¨¡å‹
            model, criterion, img_tensor, target, original_image = create_and_test_model()
            if model is None:
                print("âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€æ¬¡")
                attempt += 1
                continue

            # 2. å¼ºåŒ–è¿‡æ‹Ÿåˆè®­ç»ƒ
            training_success, losses = intensive_overfitting_test(model, criterion, img_tensor, target)

            # 3. æ¨ç†å’Œå¯è§†åŒ–æµ‹è¯•
            inference_success = inference_and_visualization_test(model, img_tensor, target, original_image)

            # æ£€æŸ¥æ˜¯å¦é€šè¿‡éªŒè¯
            if training_success and inference_success:
                print("\n" + "=" * 80)
                print("ğŸ‰ Gold-YOLOè‡ªæ£€å®Œå…¨æˆåŠŸï¼")
                print("=" * 80)
                print("âœ… è¿‡æ‹Ÿåˆè®­ç»ƒæˆåŠŸ")
                print("âœ… æ¨ç†å’Œå¯è§†åŒ–æˆåŠŸ")
                print("âœ… Gold-YOLO Jittorç‰ˆæœ¬åŠŸèƒ½æ­£ç¡®")

                if losses:
                    print(f"\nğŸ“Š è®­ç»ƒç»Ÿè®¡:")
                    print(f"  åˆå§‹æŸå¤±: {losses[0]:.4f}")
                    print(f"  æœ€ç»ˆæŸå¤±: {losses[-1]:.4f}")
                    print(f"  æŸå¤±ä¸‹é™: {(losses[0] - losses[-1])/losses[0]*100:.1f}%")
                    print(f"  æœ€ä½æŸå¤±: {min(losses):.4f}")

                print("\nğŸš€ ç»“è®º: Gold-YOLO Jittorç‰ˆæœ¬å¯ç”¨äºç”Ÿäº§ç¯å¢ƒï¼")
                print("=" * 80)
                return True

            else:
                print("\n" + "=" * 80)
                print(f"âŒ ç¬¬{attempt}æ¬¡å°è¯•å¤±è´¥")
                print("=" * 80)

                if not training_success:
                    print("âŒ è¿‡æ‹Ÿåˆè®­ç»ƒæ•ˆæœä¸è¶³")
                    if losses:
                        print(f"   æŸå¤±ä¸‹é™: {(losses[0] - losses[-1])/losses[0]*100:.1f}%")
                        print("   éœ€è¦: æŸå¤±ä¸‹é™ > 10%")

                if not inference_success:
                    print("âŒ æ¨ç†éªŒè¯å¤±è´¥")

                if attempt < max_attempts:
                    print(f"\nğŸ”„ å‡†å¤‡ç¬¬{attempt+1}æ¬¡å°è¯•...")
                    print("ğŸ’¡ å°†é‡æ–°åˆå§‹åŒ–æ¨¡å‹å¹¶è°ƒæ•´å‚æ•°")

                    # æ¸…ç†å¤±è´¥çš„æ¨¡å‹
                    cleanup_failed_model()
                else:
                    print("\nâŒ å·²è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•°")
                    print("ğŸ’¡ Gold-YOLOå¯èƒ½å­˜åœ¨é—®é¢˜ï¼Œéœ€è¦æ·±å…¥æ£€æŸ¥")

        except Exception as e:
            print(f"âŒ ç¬¬{attempt}æ¬¡å°è¯•å‡ºç°å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            cleanup_failed_model()

        attempt += 1

    print("\n" + "=" * 80)
    print("âŒ Gold-YOLOè‡ªæ£€æœ€ç»ˆå¤±è´¥")
    print("=" * 80)
    print("Gold-YOLOæ— æ³•é€šè¿‡è¿‡æ‹ŸåˆéªŒè¯æµ‹è¯•")
    print("å»ºè®®æ£€æŸ¥:")
    print("1. æ¨¡å‹æ¶æ„æ˜¯å¦æ­£ç¡®")
    print("2. æŸå¤±å‡½æ•°æ˜¯å¦æœ‰æ•ˆ")
    print("3. æ¢¯åº¦ä¼ æ’­æ˜¯å¦æ­£å¸¸")
    print("4. æ•°æ®é¢„å¤„ç†æ˜¯å¦æ­£ç¡®")
    print("=" * 80)
    return False

if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡ç°æ€§
    random.seed(42)
    np.random.seed(42)
    jt.set_global_seed(42)

    success = main()

    if success:
        print("\nğŸŠ æ­å–œï¼Gold-YOLO Jittorç‰ˆæœ¬é€šè¿‡äº†æ‰€æœ‰æµ‹è¯•ï¼")
    else:
        print("\nğŸ˜ å¾ˆé—æ†¾ï¼ŒGold-YOLO Jittorç‰ˆæœ¬æœªèƒ½é€šè¿‡æµ‹è¯•ã€‚")
        print("è¯·æ ¹æ®ä¸Šè¿°å»ºè®®è¿›è¡Œä¿®å¤åé‡æ–°æµ‹è¯•ã€‚")
