#!/usr/bin/env python3
"""
æ·±å…¥åˆ†æPyTorchç‰ˆæœ¬çš„è¯¦ç»†ä¿¡æ¯
ç»†è‡´åˆ°æ¯ä¸€ä¸ªé€šé“å’Œæ¥å£
"""

import os
import sys
import torch
import torch.nn as nn
from pathlib import Path

# æ·»åŠ PyTorchç‰ˆæœ¬è·¯å¾„
pytorch_path = "/home/kyc/project/GOLD-YOLO/Gold-YOLO_pytorch"
sys.path.insert(0, pytorch_path)

def analyze_pytorch_model():
    """æ·±å…¥åˆ†æPyTorchç‰ˆæœ¬æ¨¡å‹"""
    print("ğŸ” æ·±å…¥åˆ†æPyTorchç‰ˆæœ¬GOLD-YOLO")
    print("=" * 80)
    
    try:
        # å¯¼å…¥PyTorchç‰ˆæœ¬
        from yolov6.models.yolo import build_model
        from yolov6.utils.config import Config
        
        # åŠ è½½é…ç½®
        config_path = os.path.join(pytorch_path, "configs/gold_yolo-n.py")
        cfg = Config.fromfile(config_path)
        
        print(f"ğŸ“ é…ç½®æ–‡ä»¶: {config_path}")
        print(f"ğŸ¯ æ¨¡å‹é…ç½®: {cfg.model}")
        
        # åˆ›å»ºæ¨¡å‹
        model = build_model(cfg, num_classes=20, device='cpu')
        model.eval()
        
        print(f"\nğŸ“Š PyTorchæ¨¡å‹åˆ†æ:")
        print(f"   æ¨¡å‹ç±»å‹: {type(model)}")
        
        # åˆ†ææ¨¡å‹ç»“æ„
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"   æ€»å‚æ•°: {total_params:,} ({total_params/1e6:.2f}M)")
        print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,} ({trainable_params/1e6:.2f}M)")
        
        # åˆ†æå„éƒ¨åˆ†å‚æ•°
        backbone_params = sum(p.numel() for p in model.backbone.parameters())
        neck_params = sum(p.numel() for p in model.neck.parameters()) if hasattr(model, 'neck') else 0
        head_params = sum(p.numel() for p in model.head.parameters()) if hasattr(model, 'head') else 0
        
        print(f"   Backboneå‚æ•°: {backbone_params:,} ({backbone_params/total_params*100:.1f}%)")
        print(f"   Neckå‚æ•°: {neck_params:,} ({neck_params/total_params*100:.1f}%)")
        print(f"   Headå‚æ•°: {head_params:,} ({head_params/total_params*100:.1f}%)")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        print(f"\nğŸ”„ æµ‹è¯•å‰å‘ä¼ æ’­:")
        test_input = torch.randn(1, 3, 500, 500)
        print(f"   è¾“å…¥å½¢çŠ¶: {test_input.shape}")
        
        with torch.no_grad():
            outputs = model(test_input)
        
        print(f"   è¾“å‡ºç±»å‹: {type(outputs)}")
        if isinstance(outputs, (list, tuple)):
            for i, output in enumerate(outputs):
                if hasattr(output, 'shape'):
                    print(f"     è¾“å‡º{i}: {output.shape}")
                else:
                    print(f"     è¾“å‡º{i}: {type(output)}")
        else:
            print(f"   è¾“å‡ºå½¢çŠ¶: {outputs.shape}")
        
        # åˆ†æbackboneè¯¦ç»†ç»“æ„
        print(f"\nğŸ—ï¸ Backboneè¯¦ç»†åˆ†æ:")
        print(f"   Backboneç±»å‹: {type(model.backbone)}")
        
        # é€å±‚åˆ†æbackbone
        for name, module in model.backbone.named_children():
            if hasattr(module, 'weight'):
                print(f"     {name}: {module.weight.shape}")
            elif hasattr(module, '__len__'):
                print(f"     {name}: {len(module)}å±‚")
                for i, sub_module in enumerate(module):
                    if hasattr(sub_module, 'weight'):
                        print(f"       {name}[{i}]: {sub_module.weight.shape}")
            else:
                print(f"     {name}: {type(module)}")
        
        # åˆ†æneckè¯¦ç»†ç»“æ„
        if hasattr(model, 'neck'):
            print(f"\nğŸ”— Neckè¯¦ç»†åˆ†æ:")
            print(f"   Neckç±»å‹: {type(model.neck)}")
            
            for name, module in model.neck.named_children():
                print(f"     {name}: {type(module)}")
        
        # åˆ†æheadè¯¦ç»†ç»“æ„
        if hasattr(model, 'head'):
            print(f"\nğŸ¯ Headè¯¦ç»†åˆ†æ:")
            print(f"   Headç±»å‹: {type(model.head)}")
            
            # æ£€æŸ¥headçš„å…³é”®å±æ€§
            if hasattr(model.head, 'use_dfl'):
                print(f"     use_dfl: {model.head.use_dfl}")
            if hasattr(model.head, 'reg_max'):
                print(f"     reg_max: {model.head.reg_max}")
            if hasattr(model.head, 'nc'):
                print(f"     num_classes: {model.head.nc}")
            if hasattr(model.head, 'nl'):
                print(f"     num_layers: {model.head.nl}")
            
            # åˆ†æheadçš„å„ä¸ªç»„ä»¶
            for name, module in model.head.named_children():
                if hasattr(module, '__len__'):
                    print(f"     {name}: {len(module)}ä¸ªç»„ä»¶")
                    for i, sub_module in enumerate(module):
                        if hasattr(sub_module, 'weight'):
                            print(f"       {name}[{i}]: {sub_module.weight.shape}")
                        else:
                            print(f"       {name}[{i}]: {type(sub_module)}")
                else:
                    print(f"     {name}: {type(module)}")
        
        # åˆ†æç‰¹å¾å›¾å°ºå¯¸
        print(f"\nğŸ“ ç‰¹å¾å›¾å°ºå¯¸åˆ†æ:")
        
        # Hookå‡½æ•°æ¥æ•è·ä¸­é—´ç‰¹å¾
        feature_shapes = {}
        
        def hook_fn(name):
            def hook(module, input, output):
                if isinstance(output, torch.Tensor):
                    feature_shapes[name] = output.shape
                elif isinstance(output, (list, tuple)):
                    for i, out in enumerate(output):
                        if isinstance(out, torch.Tensor):
                            feature_shapes[f"{name}_out{i}"] = out.shape
            return hook
        
        # æ³¨å†Œhook
        hooks = []
        if hasattr(model, 'backbone'):
            hook = model.backbone.register_forward_hook(hook_fn('backbone'))
            hooks.append(hook)
        if hasattr(model, 'neck'):
            hook = model.neck.register_forward_hook(hook_fn('neck'))
            hooks.append(hook)
        if hasattr(model, 'head'):
            hook = model.head.register_forward_hook(hook_fn('head'))
            hooks.append(hook)
        
        # é‡æ–°å‰å‘ä¼ æ’­
        with torch.no_grad():
            _ = model(test_input)
        
        # ç§»é™¤hook
        for hook in hooks:
            hook.remove()
        
        # æ˜¾ç¤ºç‰¹å¾å›¾å°ºå¯¸
        for name, shape in feature_shapes.items():
            print(f"     {name}: {shape}")
        
        # è®¡ç®—anchoræ•°é‡
        print(f"\nâš“ Anchoræ•°é‡åˆ†æ:")
        if hasattr(model, 'head') and hasattr(model.head, 'stride'):
            strides = model.head.stride
            print(f"   Strides: {strides}")
            
            input_size = 500
            total_anchors = 0
            for stride in strides:
                feature_size = input_size // stride
                anchors = feature_size * feature_size
                total_anchors += anchors
                print(f"     Stride {stride}: {feature_size}x{feature_size} = {anchors} anchors")
            
            print(f"   æ€»Anchoræ•°: {total_anchors}")
        
        return {
            'model': model,
            'total_params': total_params,
            'trainable_params': trainable_params,
            'backbone_params': backbone_params,
            'neck_params': neck_params,
            'head_params': head_params,
            'feature_shapes': feature_shapes,
            'outputs': outputs
        }
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def compare_with_jittor():
    """å¯¹æ¯”Jittorç‰ˆæœ¬"""
    print(f"\nğŸ”„ å¯¹æ¯”Jittorç‰ˆæœ¬:")
    print("=" * 80)
    
    # è¿™é‡Œå¯ä»¥åŠ è½½Jittorç‰ˆæœ¬è¿›è¡Œå¯¹æ¯”
    # æš‚æ—¶å…ˆè¾“å‡ºJittorç‰ˆæœ¬çš„å·²çŸ¥ä¿¡æ¯
    print(f"Jittorç‰ˆæœ¬ä¿¡æ¯:")
    print(f"   æ€»å‚æ•°: 5,711,613 (5.71M)")
    print(f"   è¾“å‡ºå½¢çŠ¶: feats(list), [1,5249,20], [1,5249,68]")
    print(f"   Anchoræ•°: 5249")
    print(f"   æ¢¯åº¦é—®é¢˜: 476/480å‚æ•°æ¢¯åº¦ä¸ºé›¶")

def main():
    print("ğŸ” PyTorchç‰ˆæœ¬æ·±å…¥åˆ†æ")
    print("=" * 80)
    
    # åˆ†æPyTorchç‰ˆæœ¬
    pytorch_info = analyze_pytorch_model()
    
    if pytorch_info:
        print(f"\nâœ… PyTorchç‰ˆæœ¬åˆ†æå®Œæˆ!")
        
        # å¯¹æ¯”Jittorç‰ˆæœ¬
        compare_with_jittor()
        
        # ä¿å­˜åˆ†æç»“æœ
        analysis_file = "PYTORCH_DETAILED_ANALYSIS.md"
        with open(analysis_file, 'w', encoding='utf-8') as f:
            f.write("# PyTorchç‰ˆæœ¬è¯¦ç»†åˆ†æç»“æœ\n\n")
            f.write(f"## æ¨¡å‹å‚æ•°ç»Ÿè®¡\n")
            f.write(f"- æ€»å‚æ•°: {pytorch_info['total_params']:,} ({pytorch_info['total_params']/1e6:.2f}M)\n")
            f.write(f"- å¯è®­ç»ƒå‚æ•°: {pytorch_info['trainable_params']:,}\n")
            f.write(f"- Backboneå‚æ•°: {pytorch_info['backbone_params']:,}\n")
            f.write(f"- Neckå‚æ•°: {pytorch_info['neck_params']:,}\n")
            f.write(f"- Headå‚æ•°: {pytorch_info['head_params']:,}\n\n")
            
            f.write(f"## ç‰¹å¾å›¾å°ºå¯¸\n")
            for name, shape in pytorch_info['feature_shapes'].items():
                f.write(f"- {name}: {shape}\n")
            
            f.write(f"\n## è¾“å‡ºä¿¡æ¯\n")
            f.write(f"- è¾“å‡ºç±»å‹: {type(pytorch_info['outputs'])}\n")
            if isinstance(pytorch_info['outputs'], (list, tuple)):
                for i, output in enumerate(pytorch_info['outputs']):
                    if hasattr(output, 'shape'):
                        f.write(f"- è¾“å‡º{i}: {output.shape}\n")
        
        print(f"   åˆ†æç»“æœå·²ä¿å­˜åˆ°: {analysis_file}")
    else:
        print(f"\nâŒ PyTorchç‰ˆæœ¬åˆ†æå¤±è´¥!")

if __name__ == "__main__":
    main()
