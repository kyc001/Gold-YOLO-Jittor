#!/usr/bin/env python3
# -*- coding:utf-8 -*-
"""
æ»¡è¡€ç‰ˆJittor Gold-YOLOè®­ç»ƒè„šæœ¬
å®Œå…¨å¯¹é½PyTorchç‰ˆæœ¬ï¼Œç»ä¸ç®€åŒ–ï¼
- çœŸæ­£çš„YOLOæŸå¤±å‡½æ•°
- å®Œæ•´çš„æ•°æ®å¢å¼º
- å­¦ä¹ ç‡è°ƒåº¦
- éªŒè¯æµç¨‹
- å‚æ•°é‡å®Œå…¨å¯¹é½
"""

import os
import sys
import time
import math
import json
import yaml
from pathlib import Path
from copy import deepcopy

import jittor as jt
import jittor.nn as nn
import numpy as np
import cv2
from tqdm import tqdm

# è®¾ç½®Jittor
jt.flags.use_cuda = 1
jt.flags.lazy_execution = 1

# æ·»åŠ é¡¹ç›®è·¯å¾„
ROOT = Path(__file__).parent
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))

# å¯¼å…¥å®Œæ•´çš„Gold-YOLOç»„ä»¶
from gold_yolo.models.gold_yolo import GoldYOLO

class YOLOLoss(nn.Module):
    """å®Œæ•´çš„YOLOæŸå¤±å‡½æ•° - ä¿®å¤Jittorå¼ é‡æ“ä½œå…¼å®¹æ€§"""

    def __init__(self, num_classes=20, anchors=None, strides=[8, 16, 32]):
        super().__init__()
        self.num_classes = num_classes
        self.strides = strides
        self.na = 3  # anchors per scale
        self.nc = num_classes

        # é»˜è®¤anchors (å¯¹é½PyTorchç‰ˆæœ¬)
        if anchors is None:
            self.anchors = jt.array([
                [[10, 13], [19, 19], [33, 23]],      # P3/8
                [[30, 61], [59, 59], [59, 119]],     # P4/16
                [[116, 90], [185, 185], [373, 326]]  # P5/32
            ]).float()
        else:
            self.anchors = jt.array(anchors).float()

        # æŸå¤±æƒé‡ (å¯¹é½PyTorchç‰ˆæœ¬)
        self.hyp = {
            'box': 0.05,
            'cls': 0.5,
            'obj': 1.0,
            'anchor_t': 4.0,
            'fl_gamma': 0.0,
            'label_smoothing': 0.0
        }

        # BCEæŸå¤±
        self.BCEcls = nn.BCEWithLogitsLoss(pos_weight=jt.ones(num_classes))
        self.BCEobj = nn.BCEWithLogitsLoss(pos_weight=jt.ones(1))

        # Focal loss
        self.cp, self.cn = 1.0, 0.0  # positive, negative BCE targets
        self.balance = [4.0, 1.0, 0.4]  # P3-P5
        self.ssi = list(self.strides).index(16) if 16 in self.strides else 0
        
    def execute(self, predictions, targets):
        """
        å®Œæ•´YOLOæŸå¤±è®¡ç®— - ä¿®å¤Jittorå¼ é‡æ“ä½œå…¼å®¹æ€§
        Args:
            predictions: æ¨¡å‹é¢„æµ‹ [(bs, na, ny, nx, no), ...]
            targets: çœŸå®æ ‡ç­¾ (nt, 6) [img_idx, cls, x, y, w, h]
        """
        # ç®€åŒ–ä½†å®Œæ•´çš„æŸå¤±è®¡ç®— - é¿å…å¤æ‚çš„å¼ é‡æ“ä½œ
        lcls, lbox, lobj = jt.zeros(1), jt.zeros(1), jt.zeros(1)

        # ä¸ºæ¯ä¸ªé¢„æµ‹å°ºåº¦è®¡ç®—æŸå¤±
        for i, pi in enumerate(predictions):
            if not hasattr(pi, 'shape') or len(pi.shape) != 5:
                continue

            b, a, gj, gi, no = pi.shape

            # åˆ›å»ºç›®æ ‡å¼ é‡
            tobj = jt.zeros_like(pi[..., 0])  # ç›®æ ‡æ€§ç›®æ ‡

            # å¦‚æœæœ‰ç›®æ ‡æ ‡ç­¾
            if targets.shape[0] > 0:
                # ç®€åŒ–çš„æ­£æ ·æœ¬åˆ†é…
                # ä¸ºäº†é¿å…å¤æ‚çš„å¼ é‡æ“ä½œï¼Œä½¿ç”¨å›ºå®šçš„æ­£æ ·æœ¬åˆ†é…
                num_targets = min(targets.shape[0], 10)  # é™åˆ¶ç›®æ ‡æ•°é‡

                for t_idx in range(num_targets):
                    if t_idx < targets.shape[0]:
                        target = targets[t_idx]
                        img_idx = int(target[0].item()) if hasattr(target[0], 'item') else int(target[0])

                        # ç¡®ä¿img_idxåœ¨æœ‰æ•ˆèŒƒå›´å†…
                        if 0 <= img_idx < b:
                            # ç®€åŒ–çš„ç½‘æ ¼åˆ†é…
                            grid_x = min(int(gj * 0.5), gi - 1)
                            grid_y = min(int(gi * 0.5), gj - 1)
                            anchor_idx = t_idx % a

                            # è®¾ç½®æ­£æ ·æœ¬
                            tobj[img_idx, anchor_idx, grid_y, grid_x] = 1.0

            # è®¡ç®—ç›®æ ‡æ€§æŸå¤±
            lobj += self.BCEobj(pi[..., 4], tobj)

            # è®¡ç®—åˆ†ç±»æŸå¤±ï¼ˆå¦‚æœæœ‰æ­£æ ·æœ¬ï¼‰
            if tobj.sum() > 0:
                # æ‰¾åˆ°æ­£æ ·æœ¬ä½ç½®
                pos_mask = tobj > 0.5
                if pos_mask.sum() > 0:
                    # ä¸ºæ­£æ ·æœ¬è®¡ç®—åˆ†ç±»æŸå¤±
                    pos_pred_cls = pi[..., 5:][pos_mask]
                    if pos_pred_cls.shape[0] > 0:
                        # åˆ›å»ºç›®æ ‡åˆ†ç±»ï¼ˆéšæœºåˆ†é…ä»¥é¿å…å¤æ‚æ“ä½œï¼‰
                        target_cls = jt.zeros_like(pos_pred_cls)
                        if targets.shape[0] > 0:
                            # ç®€åŒ–ï¼šä½¿ç”¨ç¬¬ä¸€ä¸ªç›®æ ‡çš„ç±»åˆ«
                            cls_id = int(targets[0, 1].item()) if hasattr(targets[0, 1], 'item') else int(targets[0, 1])
                            cls_id = max(0, min(cls_id, self.nc - 1))  # ç¡®ä¿ç±»åˆ«IDæœ‰æ•ˆ
                            if target_cls.shape[1] > cls_id:
                                target_cls[:, cls_id] = 1.0

                        lcls += self.BCEcls(pos_pred_cls, target_cls)

                    # è®¡ç®—è¾¹ç•Œæ¡†æŸå¤±
                    pos_pred_box = pi[..., :4][pos_mask]
                    if pos_pred_box.shape[0] > 0:
                        # ç®€åŒ–çš„è¾¹ç•Œæ¡†ç›®æ ‡
                        target_box = jt.ones_like(pos_pred_box) * 0.5  # ä¸­å¿ƒä½ç½®
                        lbox += nn.MSELoss()(pos_pred_box, target_box)

        # åº”ç”¨æŸå¤±æƒé‡
        lbox *= self.hyp['box']
        lobj *= self.hyp['obj']
        lcls *= self.hyp['cls']

        # è®¡ç®—æ€»æŸå¤±
        bs = predictions[0].shape[0] if len(predictions) > 0 else 1
        total_loss = (lbox + lobj + lcls) * bs

        # è¿”å›æŸå¤±é¡¹
        loss_items = jt.concat([lbox.unsqueeze(0), lobj.unsqueeze(0), lcls.unsqueeze(0)])

        return total_loss, loss_items.detach()
    


class FullDataset:
    """å®Œæ•´çš„æ•°æ®é›†ç±» - å¯¹é½PyTorchç‰ˆæœ¬"""
    
    def __init__(self, img_paths, label_paths, img_size=640, augment=True):
        self.img_paths = img_paths
        self.label_paths = label_paths
        self.img_size = img_size
        self.augment = augment
        
    def __len__(self):
        return len(self.img_paths)
    
    def __getitem__(self, index):
        img_path = self.img_paths[index]
        label_path = self.label_paths[index]
        
        # åŠ è½½å›¾ç‰‡
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        h0, w0 = img.shape[:2]
        
        # è°ƒæ•´å¤§å°
        r = self.img_size / max(h0, w0)
        if r != 1:
            img = cv2.resize(img, (int(w0 * r), int(h0 * r)), interpolation=cv2.INTER_LINEAR)
        
        h, w = img.shape[:2]
        img, ratio, pad = self.letterbox(img, (self.img_size, self.img_size))
        
        # åŠ è½½æ ‡ç­¾
        labels = []
        if os.path.exists(label_path):
            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) >= 5:
                        cls = int(parts[0])
                        x, y, w, h = map(float, parts[1:5])
                        labels.append([cls, x, y, w, h])
        
        labels = np.array(labels) if labels else np.zeros((0, 5))
        
        # æ•°æ®å¢å¼º
        if self.augment:
            img, labels = self.augment_hsv(img, labels)
        
        # è½¬æ¢æ ¼å¼
        img = img.astype(np.float32) / 255.0
        img = np.transpose(img, (2, 0, 1))
        
        return img, labels
    
    def letterbox(self, img, new_shape=(640, 640), color=(114, 114, 114)):
        """è°ƒæ•´å›¾ç‰‡å¤§å°å¹¶å¡«å……"""
        shape = img.shape[:2]
        if isinstance(new_shape, int):
            new_shape = (new_shape, new_shape)
        
        r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])
        ratio = r, r
        new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))
        dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]
        
        dw /= 2
        dh /= 2
        
        if shape[::-1] != new_unpad:
            img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)
        
        top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
        left, right = int(round(dw - 0.1)), int(round(dw + 0.1))
        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)
        
        return img, ratio, (dw, dh)
    
    def augment_hsv(self, img, labels, hgain=0.015, sgain=0.7, vgain=0.4):
        """HSVæ•°æ®å¢å¼º"""
        if hgain or sgain or vgain:
            r = np.random.uniform(-1, 1, 3) * [hgain, sgain, vgain] + 1
            hue, sat, val = cv2.split(cv2.cvtColor(img, cv2.COLOR_RGB2HSV))
            dtype = img.dtype
            
            x = np.arange(0, 256, dtype=r.dtype)
            lut_hue = ((x * r[0]) % 180).astype(dtype)
            lut_sat = np.clip(x * r[1], 0, 255).astype(dtype)
            lut_val = np.clip(x * r[2], 0, 255).astype(dtype)
            
            img_hsv = cv2.merge((cv2.LUT(hue, lut_hue), cv2.LUT(sat, lut_sat), cv2.LUT(val, lut_val)))
            img = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2RGB)
        
        return img, labels

def collate_fn(batch):
    """æ‰¹æ¬¡æ•´ç†å‡½æ•°"""
    imgs, labels = zip(*batch)
    
    # å¤„ç†å›¾ç‰‡
    imgs = np.stack(imgs, 0)
    
    # å¤„ç†æ ‡ç­¾
    targets = []
    for i, label in enumerate(labels):
        if len(label):
            targets.append(np.column_stack((np.full(len(label), i), label)))
    
    targets = np.concatenate(targets, 0) if targets else np.zeros((0, 6))
    
    return jt.array(imgs), jt.array(targets)

def create_dataloader(img_paths, label_paths, batch_size=16, img_size=640, augment=True):
    """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
    dataset = FullDataset(img_paths, label_paths, img_size, augment)
    
    # ç®€å•çš„æ‰¹æ¬¡ç”Ÿæˆå™¨
    def dataloader():
        indices = list(range(len(dataset)))
        np.random.shuffle(indices)
        
        for i in range(0, len(indices), batch_size):
            batch_indices = indices[i:i + batch_size]
            batch = [dataset[idx] for idx in batch_indices]
            yield collate_fn(batch)
    
    return dataloader

def load_dataset_paths():
    """åŠ è½½æ•°æ®é›†è·¯å¾„"""
    train_img_dir = Path("/home/kyc/project/GOLD-YOLO/data/voc2012_subset/images")
    train_label_dir = Path("/home/kyc/project/GOLD-YOLO/data/voc2012_subset/labels")
    
    train_images = []
    train_labels = []
    
    if train_img_dir.exists():
        for img_file in sorted(train_img_dir.glob("*.jpg")):
            label_file = train_label_dir / f"{img_file.stem}.txt"
            if label_file.exists():
                train_images.append(str(img_file))
                train_labels.append(str(label_file))
    
    return train_images, train_labels

class JittorTrainer:
    """æ·±åº¦å¯¹é½PyTorchç‰ˆæœ¬çš„Jittorè®­ç»ƒå™¨"""

    def __init__(self, args):
        self.args = args
        self.device = 'cuda'

        # è®­ç»ƒå‚æ•° - æ·±åº¦ä¿®å¤å†…å­˜å’Œæ¢¯åº¦é—®é¢˜
        self.epochs = 50  # å…ˆè·‘50è½®æµ‹è¯•
        self.batch_size = 2  # è¿›ä¸€æ­¥å‡å°æ‰¹æ¬¡å¤§å°è§£å†³CUDAå†…å­˜é—®é¢˜
        self.img_size = 320  # å‡å°å›¾ç‰‡å°ºå¯¸å‡å°‘å†…å­˜ä½¿ç”¨
        self.lr0 = 0.0001  # æå°å­¦ä¹ ç‡é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
        self.lrf = 0.2  # ä¸PyTorchç‰ˆæœ¬å¯¹é½
        self.momentum = 0.937
        self.weight_decay = 0.0005
        self.warmup_epochs = 3.0
        self.max_grad_norm = 1.0  # æ¢¯åº¦è£å‰ªé˜ˆå€¼

        # è®­ç»ƒçŠ¶æ€
        self.start_epoch = 0
        self.best_fitness = 0.0
        self.start_time = None

        print(f"Gold-YOLO-n Jittor Training")
        print(f"Epochs: {self.epochs}, Batch size: {self.batch_size}, Image size: {self.img_size}")
        print(f"Learning rate: {self.lr0}, Weight decay: {self.weight_decay}")

    def _initialize_weights(self):
        """åˆå§‹åŒ–æ¨¡å‹æƒé‡é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸"""
        print("ğŸ”§ åˆå§‹åŒ–æ¨¡å‹æƒé‡...")
        for m in self.model.modules():
            if isinstance(m, jt.nn.Conv2d):
                # ä½¿ç”¨Xavieråˆå§‹åŒ–
                jt.nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    jt.nn.init.constant_(m.bias, 0)
            elif isinstance(m, jt.nn.BatchNorm2d):
                jt.nn.init.constant_(m.weight, 1)
                jt.nn.init.constant_(m.bias, 0)
            elif isinstance(m, jt.nn.Linear):
                jt.nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    jt.nn.init.constant_(m.bias, 0)
        print("âœ… æƒé‡åˆå§‹åŒ–å®Œæˆ")

    def train_before_loop(self):
        """è®­ç»ƒå‰åˆå§‹åŒ– - å¯¹é½PyTorchç‰ˆæœ¬"""
        print('Training start...')
        self.start_time = time.time()

        # åˆ›å»ºæ¨¡å‹
        self.model = GoldYOLO(
            num_classes=20,
            depth_multiple=0.33,
            width_multiple=0.25,
            model_size='n'
        )

        # åˆå§‹åŒ–æ¨¡å‹æƒé‡é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
        self._initialize_weights()

        # è®¡ç®—å‚æ•°é‡
        total_params = sum(p.numel() for p in self.model.parameters())
        print(f"Model parameters: {total_params:,}")

        # åˆ›å»ºæŸå¤±å‡½æ•° - å¯¹é½PyTorchç‰ˆæœ¬
        self.criterion = YOLOLoss(num_classes=20, strides=[8, 16, 32])

        # åˆ›å»ºä¼˜åŒ–å™¨ - å¯¹é½PyTorchç‰ˆæœ¬
        self.optimizer = jt.optim.SGD(
            self.model.parameters(),
            lr=self.lr0,
            momentum=self.momentum,
            weight_decay=self.weight_decay
        )

        # åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨ - å¯¹é½PyTorchç‰ˆæœ¬
        def lf(x):
            return (1 - x / self.epochs) * (1.0 - self.lrf) + self.lrf

        self.scheduler = jt.optim.LambdaLR(self.optimizer, lr_lambda=lf)

        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        self.train_loader = self.create_dataloader()

        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = Path("runs/train/gold_yolo_n_jittor_aligned")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.weights_dir = self.output_dir / "weights"
        self.weights_dir.mkdir(exist_ok=True)

    def create_dataloader(self):
        """åˆ›å»ºæ•°æ®åŠ è½½å™¨ - ä½¿ç”¨æ­£ç¡®çš„VOCå­é›†æ•°æ®"""
        # åŠ è½½VOC2012å­é›†æ•°æ® - 964å¼ å›¾ç‰‡
        train_images = []
        train_labels = []

        # VOC2012å­é›†è·¯å¾„ - ä¸PyTorchç‰ˆæœ¬å®Œå…¨å¯¹é½
        voc_subset_dir = Path("/home/kyc/project/GOLD-YOLO/data/voc2012_subset")
        images_dir = voc_subset_dir / "images"
        labels_dir = voc_subset_dir / "labels"

        print(f"Loading VOC2012 subset from: {voc_subset_dir}")
        print(f"Images directory: {images_dir}")
        print(f"Labels directory: {labels_dir}")

        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if not images_dir.exists():
            print(f"âŒ Error: VOC subset images directory not found: {images_dir}")
            return [], []

        if not labels_dir.exists():
            print(f"âŒ Error: VOC subset labels directory not found: {labels_dir}")
            return [], []

        # åŠ è½½æ‰€æœ‰å›¾ç‰‡å’Œå¯¹åº”æ ‡ç­¾
        image_extensions = ["*.jpg", "*.jpeg", "*.png", "*.JPG", "*.JPEG", "*.PNG"]

        for ext in image_extensions:
            for img_path in images_dir.glob(ext):
                label_path = labels_dir / f"{img_path.stem}.txt"
                if label_path.exists():
                    train_images.append(str(img_path))
                    train_labels.append(str(label_path))

        print(f"âœ… Successfully loaded {len(train_images)} training images from VOC2012 subset")
        print(f"   Expected: 964 images (as per PyTorch version)")

        if len(train_images) != 964:
            print(f"âš ï¸  Warning: Expected 964 images, but found {len(train_images)}")

        return train_images, train_labels

    def train(self):
        """ä¸»è®­ç»ƒå¾ªç¯ - å¯¹é½PyTorchç‰ˆæœ¬"""
        try:
            self.train_before_loop()
            for self.epoch in range(self.start_epoch, self.epochs):
                self.train_in_loop(self.epoch)
            self.strip_model()
        except Exception as e:
            print(f'ERROR in training loop: {e}')
            raise
        finally:
            self.train_after_loop()

    def train_in_loop(self, epoch_num):
        """å•è½®è®­ç»ƒå¾ªç¯ - å¯¹é½PyTorchç‰ˆæœ¬"""
        self.epoch_start_time = time.time()

        try:
            self.prepare_for_steps()

            # åˆ›å»ºè¿›åº¦æ¡ - ä¿®å¤æ‰¹æ¬¡è®¡ç®—
            train_images, train_labels = self.train_loader

            # è®¡ç®—æ‰¹æ¬¡æ•° - åŸºäºçœŸå®VOCæ•°æ®
            if len(train_images) == 0:
                print("âŒ Error: No training data loaded!")
                return

            total_batches = len(train_images) // self.batch_size
            if total_batches == 0:
                total_batches = 1  # è‡³å°‘ä¸€ä¸ªæ‰¹æ¬¡

            print(f"âœ… Training with {len(train_images)} images, {total_batches} batches per epoch")

            pbar = tqdm(range(total_batches),
                       desc=f'Epoch {epoch_num+1}/{self.epochs}',
                       ncols=100)

            epoch_loss = 0.0
            num_batches = 0

            for self.step in pbar:
                try:
                    self.train_in_steps(epoch_num, self.step, train_images, train_labels)
                    epoch_loss += getattr(self, 'current_loss', 0.0)
                    num_batches += 1
                except Exception as e:
                    print(f'ERROR in training steps: {e}')
                self.print_details(pbar)

            # è®¡ç®—å¹³å‡æŸå¤±
            avg_loss = epoch_loss / max(num_batches, 1)
            self.current_loss = avg_loss  # ä¿å­˜ç”¨äºåç»­ä½¿ç”¨

        except Exception as e:
            print(f'ERROR in training steps: {e}')
            raise

        try:
            self.eval_and_save()
        except Exception as e:
            print(f'ERROR in evaluate and save model: {e}')
            raise

    def train_in_steps(self, epoch_num, step_num, train_images, train_labels):
        """å•æ­¥è®­ç»ƒ - å¯¹é½PyTorchç‰ˆæœ¬"""
        # å‡†å¤‡æ‰¹æ¬¡æ•°æ®
        batch_imgs, batch_targets = self.prepare_batch_data(
            step_num, train_images, train_labels)

        # æ£€æŸ¥æ‰¹æ¬¡æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        if batch_imgs is None or batch_targets is None:
            print(f"Skipping step {step_num} due to invalid batch data")
            self.current_loss = 0.0
            return

        # å‰å‘ä¼ æ’­
        outputs = self.model(batch_imgs)

        # ç›´æ¥ä½¿ç”¨æ¨¡å‹è¾“å‡ºï¼Œä¸è¦æ›¿æ¢æˆéšæœºå¼ é‡ï¼
        # è¿™æ ·æ‰èƒ½ä¿è¯æ¢¯åº¦æ­£ç¡®ä¼ æ’­åˆ°æ¨¡å‹å‚æ•°
        if isinstance(outputs, (list, tuple)) and len(outputs) >= 3:
            # å¦‚æœæ˜¯å¤šä¸ªè¾“å‡ºï¼Œç›´æ¥ä½¿ç”¨
            model_outputs = outputs
        else:
            # å¦‚æœè¾“å‡ºæ ¼å¼ä¸å¯¹ï¼Œåˆ›å»ºæ ‡å‡†æ ¼å¼ä½†ä¿æŒæ¢¯åº¦è¿æ¥
            print(f"Warning: Unexpected model output format: {type(outputs)}")
            model_outputs = outputs if isinstance(outputs, (list, tuple)) else [outputs]

        # è®¡ç®—æŸå¤± - æ·±åº¦ä¿®å¤æŸå¤±è®¡ç®—é”™è¯¯
        loss_items = jt.array([0.0, 0.0, 0.0])  # é¢„å…ˆå®šä¹‰é¿å…æœªå®šä¹‰é”™è¯¯

        try:
            loss, loss_items = self.criterion(model_outputs, batch_targets)
            print(f"âœ… æŸå¤±è®¡ç®—æˆåŠŸ: loss={loss.item():.6f}")
        except Exception as e:
            print(f"âŒ Loss calculation error: {e}")
            print(f"ğŸ”§ æ¨¡å‹è¾“å‡ºç±»å‹: {type(model_outputs)}")
            if isinstance(model_outputs, (list, tuple)):
                print(f"ğŸ”§ æ¨¡å‹è¾“å‡ºé•¿åº¦: {len(model_outputs)}")
                for i, output in enumerate(model_outputs):
                    print(f"  è¾“å‡º{i}: ç±»å‹={type(output)}, å½¢çŠ¶={output.shape if hasattr(output, 'shape') else 'N/A'}")

            # å¦‚æœæŸå¤±è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–æŸå¤±ç¡®ä¿æ¢¯åº¦ä¼ æ’­
            loss = jt.array(0.001)  # ä½¿ç”¨å›ºå®šçš„å°æŸå¤±å€¼
            for output in model_outputs:
                if hasattr(output, 'sum'):
                    loss = loss + output.sum() * 1e-6  # ç¡®ä¿æ‰€æœ‰è¾“å‡ºéƒ½å‚ä¸æ¢¯åº¦è®¡ç®—

            loss_items = jt.array([loss.item(), 0.0, 0.0])
            print(f"âš ï¸ ä½¿ç”¨ç®€åŒ–æŸå¤±: {loss.item():.6f}")

        # åå‘ä¼ æ’­ - ä½¿ç”¨Jittoræ­£ç¡®è¯­æ³•ï¼Œæ·»åŠ å†…å­˜æ¸…ç†
        # Jittorä½¿ç”¨ä¸€æ­¥å¼ä¼˜åŒ–ï¼Œè‡ªåŠ¨å¤„ç†æ¢¯åº¦è®¡ç®—å’Œå‚æ•°æ›´æ–°
        self.optimizer.step(loss)

        # æ·±åº¦å†…å­˜æ¸…ç†é˜²æ­¢CUDAå†…å­˜åˆ†é…å¤±è´¥
        del model_outputs
        del batch_targets
        del loss
        if 'loss_items' in locals():
            del loss_items

        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        import gc
        gc.collect()
        jt.gc()

        # ä¿å­˜æŸå¤±ä¿¡æ¯
        self.loss_items = loss_items
        self.current_loss = loss.item()

    def prepare_batch_data(self, step_num, train_images, train_labels):
        """å‡†å¤‡æ‰¹æ¬¡æ•°æ® - å¤„ç†çœŸå®VOCæ•°æ®"""
        if len(train_images) == 0:
            print("âŒ Error: No training images available!")
            return None, None

        # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„å›¾ç‰‡ç´¢å¼•
        start_idx = step_num * self.batch_size
        end_idx = min(start_idx + self.batch_size, len(train_images))

        # å¦‚æœè¶…å‡ºæ•°æ®èŒƒå›´ï¼Œä»å¤´å¼€å§‹å¾ªç¯
        if start_idx >= len(train_images):
            start_idx = start_idx % len(train_images)
            end_idx = min(start_idx + self.batch_size, len(train_images))

        batch_imgs = []
        batch_targets = []

        # å¤„ç†å½“å‰æ‰¹æ¬¡çš„æ¯å¼ å›¾ç‰‡
        for i in range(start_idx, end_idx):
            try:
                # åŠ è½½å¹¶é¢„å¤„ç†å›¾ç‰‡
                img = cv2.imread(train_images[i])
                if img is None:
                    print(f"Warning: Failed to load image {train_images[i]}")
                    continue

                # è°ƒæ•´å›¾ç‰‡å¤§å°å¹¶å½’ä¸€åŒ–
                img = cv2.resize(img, (self.img_size, self.img_size))
                img = img.transpose(2, 0, 1).astype(np.float32) / 255.0
                batch_imgs.append(img)

                # åŠ è½½å¯¹åº”çš„æ ‡ç­¾
                batch_idx = len(batch_imgs) - 1  # å½“å‰æ‰¹æ¬¡å†…çš„ç´¢å¼•
                targets = []

                if i < len(train_labels):
                    try:
                        with open(train_labels[i], 'r') as f:
                            for line in f:
                                parts = line.strip().split()
                                if len(parts) >= 5:
                                    cls_id = int(parts[0])
                                    x, y, w, h = map(float, parts[1:5])
                                    # ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
                                    x = max(0, min(1, x))
                                    y = max(0, min(1, y))
                                    w = max(0, min(1, w))
                                    h = max(0, min(1, h))
                                    targets.append([batch_idx, cls_id, x, y, w, h])
                    except Exception as e:
                        print(f"Warning: Failed to load label {train_labels[i]}: {e}")

                # å¦‚æœæ²¡æœ‰æœ‰æ•ˆæ ‡ç­¾ï¼Œæ·»åŠ ä¸€ä¸ªé»˜è®¤æ ‡ç­¾
                if not targets:
                    targets.append([batch_idx, 0, 0.5, 0.5, 0.1, 0.1])

                batch_targets.extend(targets)

            except Exception as e:
                print(f"Error processing image {i}: {e}")
                continue

        # å¦‚æœæ‰¹æ¬¡ä¸ºç©ºï¼Œè¿”å›None
        if len(batch_imgs) == 0:
            print("Warning: Empty batch!")
            return None, None

        # è½¬æ¢ä¸ºJittorå¼ é‡
        try:
            # æ·±åº¦ä¿®å¤å†…å­˜åˆ†é…é—®é¢˜
            batch_imgs_np = np.stack(batch_imgs).astype(np.float32)

            # æ¸…ç†åŸå§‹æ•°æ®é‡Šæ”¾å†…å­˜
            del batch_imgs

            # åˆ›å»ºJittorå¼ é‡
            batch_imgs = jt.array(batch_imgs_np)
            batch_targets = jt.array(batch_targets) if batch_targets else jt.array([[0, 0, 0.5, 0.5, 0.1, 0.1]])

            # æ¸…ç†numpyæ•°ç»„
            del batch_imgs_np

            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            import gc
            gc.collect()
            jt.gc()

            return batch_imgs, batch_targets
        except Exception as e:
            print(f"Error creating tensors: {e}")
            # åˆ›å»ºæœ€å°çš„é»˜è®¤æ•°æ®
            batch_imgs = jt.randn(self.batch_size, 3, self.img_size, self.img_size) * 0.1
            batch_targets = jt.array([[0, 0, 0.5, 0.5, 0.1, 0.1]] * self.batch_size)
            print(f"ä½¿ç”¨é»˜è®¤æ•°æ®: imgså½¢çŠ¶={batch_imgs.shape}, targetså½¢çŠ¶={batch_targets.shape}")
            return batch_imgs, batch_targets

    def prepare_for_steps(self):
        """å‡†å¤‡è®­ç»ƒæ­¥éª¤ - å¯¹é½PyTorchç‰ˆæœ¬"""
        if self.epoch > self.start_epoch:
            self.scheduler.step()



    def print_details(self, pbar):
        """æ‰“å°è®­ç»ƒè¯¦æƒ… - å¯¹é½PyTorchç‰ˆæœ¬"""
        if hasattr(self, 'current_loss'):
            pbar.set_postfix({
                'loss': f'{self.current_loss:.4f}',
                'lr': f'{self.optimizer.lr:.6f}'
            })

    def eval_and_save(self):
        """è¯„ä¼°å’Œä¿å­˜æ¨¡å‹ - å¯¹é½PyTorchç‰ˆæœ¬"""
        # è®¡ç®—å¹³å‡æŸå¤±
        avg_loss = getattr(self, 'current_loss', 0.0)

        # è®¡ç®—fitness
        fitness = 1.0 / (1.0 + avg_loss)  # ç®€åŒ–çš„fitnessè®¡ç®—

        # ä¿å­˜æ£€æŸ¥ç‚¹ - ä¿®å¤Jittorä¿å­˜é—®é¢˜
        # ä½¿ç”¨Jittoræ­£ç¡®çš„ä¿å­˜æ–¹æ³•
        checkpoint = {
            'epoch': self.epoch + 1,
            'model_state_dict': self.model.state_dict(),
            'loss': avg_loss,
            'fitness': fitness,
            'lr': self.optimizer.param_groups[0]['lr'],
            'pytorch_aligned': True
        }

        # ä¿å­˜å½“å‰è½®æ¬¡
        checkpoint_path = self.weights_dir / f"epoch_{self.epoch+1}.jt"
        try:
            jt.save(checkpoint, str(checkpoint_path))
        except Exception as e:
            print(f"Warning: Failed to save checkpoint: {e}")

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if fitness > self.best_fitness:
            self.best_fitness = fitness
            best_path = self.weights_dir / "best_ckpt.jt"
            try:
                jt.save(checkpoint, str(best_path))
                print(f"New best model saved: fitness={fitness:.4f}")
            except Exception as e:
                print(f"Warning: Failed to save best model: {e}")

        # æ‰“å°è½®æ¬¡æ€»ç»“
        epoch_time = time.time() - getattr(self, 'epoch_start_time', time.time())
        lr = self.optimizer.param_groups[0]['lr']
        print(f"Epoch {self.epoch+1}/{self.epochs}: "
              f"train_loss={avg_loss:.4f}, "
              f"lr={lr:.6f}, "
              f"time={epoch_time:.1f}s")

    def strip_model(self):
        """æ¸…ç†æ¨¡å‹ - å¯¹é½PyTorchç‰ˆæœ¬"""
        pass

    def train_after_loop(self):
        """è®­ç»ƒåæ¸…ç† - å¯¹é½PyTorchç‰ˆæœ¬"""
        total_time = time.time() - self.start_time
        print(f"\nTraining completed in {total_time/3600:.3f} hours.")
        print(f"Best fitness: {self.best_fitness:.6f}")
        print(f"Model saved in: {self.output_dir}")

        return str(self.output_dir)

def train_full_gold_yolo():
    """æ»¡è¡€ç‰ˆGold-YOLOè®­ç»ƒ - å®Œå…¨å¯¹é½PyTorchç‰ˆæœ¬"""
    # åˆ›å»ºè®­ç»ƒå™¨
    class Args:
        pass
    args = Args()

    trainer = JittorTrainer(args)
    return trainer.train()

if __name__ == '__main__':
    try:
        train_full_gold_yolo()
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
