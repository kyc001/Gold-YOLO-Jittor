#!/usr/bin/env python3
"""
æœ€ç»ˆæ£€æµ‹æµ‹è¯• - ç®€åŒ–ç‰ˆæœ¬
å¤„ç†é‡å¤æ£€æµ‹å¹¶å¯è§†åŒ–ç»“æœ
"""

import os
import sys
import cv2
import numpy as np
import jittor as jt

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models.perfect_gold_yolo import create_perfect_gold_yolo_model
from yolov6.data.data_augment import letterbox

def final_detection_test():
    """æœ€ç»ˆæ£€æµ‹æµ‹è¯•"""
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                  GOLD-YOLOæœ€ç»ˆæ£€æµ‹æµ‹è¯•                       â•‘
    â•‘                                                              â•‘
    â•‘  ğŸ¯ éªŒè¯æ¨¡å‹æ£€æµ‹èƒ½åŠ›å¹¶å¯è§†åŒ–ç»“æœ                             â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ”§ åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹...")
    model = create_perfect_gold_yolo_model('gold_yolo-n', num_classes=20)
    
    # åŠ è½½è‡ªæ£€è®­ç»ƒçš„æƒé‡
    weights_path = 'simple_self_check_model.pkl'
    if os.path.exists(weights_path):
        model.load_state_dict(jt.load(weights_path))
        print(f"âœ… åŠ è½½è‡ªæ£€è®­ç»ƒæƒé‡: {weights_path}")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°è‡ªæ£€è®­ç»ƒæƒé‡ï¼Œä½¿ç”¨åˆå§‹åŒ–æƒé‡")
    
    model.eval()
    
    # åŠ è½½æµ‹è¯•å›¾åƒ
    img_path = '/home/kyc/project/GOLD-YOLO/Gold-YOLO_pytorch/runs/inference/pytorch_baseline_test/test_images/2008_000099.jpg'
    print(f"ğŸ“¸ åŠ è½½æµ‹è¯•å›¾åƒ: {os.path.basename(img_path)}")
    
    img0 = cv2.imread(img_path)
    if img0 is None:
        print(f"âŒ æ— æ³•è¯»å–å›¾åƒ: {img_path}")
        return False
    
    h0, w0 = img0.shape[:2]
    print(f"åŸå§‹å›¾åƒå°ºå¯¸: {w0}x{h0}")
    
    # é¢„å¤„ç†
    img = letterbox(img0, new_shape=640, stride=32, auto=False)[0]
    img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, HWC to CHW
    img = np.ascontiguousarray(img)
    img = img.astype(np.float32) / 255.0
    img_tensor = jt.array(img).unsqueeze(0)
    
    print(f"é¢„å¤„ç†åå›¾åƒå°ºå¯¸: {img_tensor.shape}")
    
    # æ¨ç†
    print("ğŸ” å¼€å§‹æ¨ç†...")
    with jt.no_grad():
        pred = model(img_tensor)
    
    print(f"æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {pred.shape}")
    
    # è§£æé¢„æµ‹ç»“æœ
    pred = pred[0]  # ç§»é™¤batchç»´åº¦ [8400, 25]
    
    # æå–åæ ‡ã€ç½®ä¿¡åº¦å’Œç±»åˆ«
    boxes = pred[:, :4]  # [x_center, y_center, width, height]
    obj_conf = pred[:, 4]  # ç›®æ ‡ç½®ä¿¡åº¦
    cls_conf = pred[:, 5:]  # ç±»åˆ«ç½®ä¿¡åº¦ [20]
    
    print(f"ç›®æ ‡ç½®ä¿¡åº¦èŒƒå›´: [{float(obj_conf.min().data):.6f}, {float(obj_conf.max().data):.6f}]")
    print(f"ç±»åˆ«ç½®ä¿¡åº¦èŒƒå›´: [{float(cls_conf.min().data):.6f}, {float(cls_conf.max().data):.6f}]")
    
    # è®¡ç®—æœ€ç»ˆç½®ä¿¡åº¦å’Œç±»åˆ«
    cls_scores = cls_conf.max(dim=1)[0]  # æœ€å¤§ç±»åˆ«ç½®ä¿¡åº¦
    cls_indices = cls_conf.argmax(dim=1)  # ç±»åˆ«ç´¢å¼•
    final_conf = obj_conf * cls_scores
    
    print(f"æœ€ç»ˆç½®ä¿¡åº¦èŒƒå›´: [{float(final_conf.min().data):.6f}, {float(final_conf.max().data):.6f}]")
    
    # å¼ºåˆ¶å¯è§†åŒ–å‰5ä¸ªæ£€æµ‹ç»“æœ
    num_to_show = 5
    print(f"ğŸ”§ å¼ºåˆ¶å¯è§†åŒ–å‰{num_to_show}ä¸ªæ£€æµ‹ç»“æœ...")
    
    # é€‰æ‹©å‰Nä¸ªæ£€æµ‹
    selected_boxes = boxes[:num_to_show]
    selected_conf = final_conf[:num_to_show]
    selected_cls = cls_indices[:num_to_show]
    
    print(f"é€‰æ‹©çš„æ£€æµ‹æ•°é‡: {len(selected_boxes)}")
    
    # è½¬æ¢åæ ‡æ ¼å¼ xywh -> xyxy
    def xywh2xyxy_simple(x):
        """ç®€å•çš„åæ ‡è½¬æ¢"""
        if hasattr(x, 'numpy'):
            x = x.numpy()
        
        y = np.zeros_like(x)
        y[:, 0] = x[:, 0] - x[:, 2] / 2  # x1
        y[:, 1] = x[:, 1] - x[:, 3] / 2  # y1
        y[:, 2] = x[:, 0] + x[:, 2] / 2  # x2
        y[:, 3] = x[:, 1] + x[:, 3] / 2  # y2
        return y
    
    xyxy_boxes = xywh2xyxy_simple(selected_boxes)
    
    # ç¼©æ”¾åˆ°åŸå›¾å°ºå¯¸
    scale_x = w0 / 640
    scale_y = h0 / 640
    
    xyxy_boxes[:, [0, 2]] *= scale_x  # xåæ ‡
    xyxy_boxes[:, [1, 3]] *= scale_y  # yåæ ‡
    
    # åˆ›å»ºå¯è§†åŒ–å›¾åƒ
    img_vis = img0.copy()
    
    # å®šä¹‰é¢œè‰²
    colors = [
        (255, 0, 0),    # çº¢è‰²
        (0, 255, 0),    # ç»¿è‰²
        (0, 0, 255),    # è“è‰²
        (255, 255, 0),  # é»„è‰²
        (255, 0, 255),  # ç´«è‰²
    ]
    
    # ç»˜åˆ¶æ£€æµ‹ç»“æœ
    for i in range(len(xyxy_boxes)):
        box = xyxy_boxes[i]
        conf = selected_conf[i]
        cls = selected_cls[i]
        
        if hasattr(conf, 'numpy'):
            conf_val = conf.numpy()
            if conf_val.size == 1:
                conf = float(conf_val.item())
            else:
                conf = float(conf_val[0])
        else:
            conf = float(conf)

        if hasattr(cls, 'numpy'):
            cls_val = cls.numpy()
            if cls_val.size == 1:
                cls = int(cls_val.item())
            else:
                cls = int(cls_val[0])
        else:
            cls = int(cls)

        x1, y1, x2, y2 = map(int, box)
        confidence = conf
        class_id = cls
        
        # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
        x1 = max(0, min(x1, w0-1))
        y1 = max(0, min(y1, h0-1))
        x2 = max(0, min(x2, w0-1))
        y2 = max(0, min(y2, h0-1))
        
        color = colors[i % len(colors)]
        
        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        cv2.rectangle(img_vis, (x1, y1), (x2, y2), color, 2)
        
        # ç»˜åˆ¶æ ‡ç­¾
        label = f'Det{i+1}_C{class_id} {confidence:.4f}'
        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
        cv2.rectangle(img_vis, (x1, y1-label_size[1]-5), (x1+label_size[0], y1), color, -1)
        cv2.putText(img_vis, label, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2)
        
        print(f"æ£€æµ‹ {i+1}: ç±»åˆ«={class_id}, ç½®ä¿¡åº¦={confidence:.6f}, åæ ‡=[{x1},{y1},{x2},{y2}]")
    
    # ä¿å­˜æ£€æµ‹ç»“æœ
    result_path = 'final_detection_result.jpg'
    cv2.imwrite(result_path, img_vis)
    print(f"ğŸ“¸ æ£€æµ‹ç»“æœå·²ä¿å­˜: {result_path}")
    
    # åˆ›å»ºå¯¹æ¯”å›¾ï¼ˆåŸå›¾ vs æ£€æµ‹ç»“æœï¼‰
    comparison_img = np.hstack([img0, img_vis])
    
    # æ·»åŠ æ ‡é¢˜
    cv2.putText(comparison_img, 'Original Image', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)
    cv2.putText(comparison_img, 'Detection Results', (w0+10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)
    
    # ä¿å­˜å¯¹æ¯”å›¾
    comparison_path = 'final_detection_comparison.jpg'
    cv2.imwrite(comparison_path, comparison_img)
    print(f"ğŸ“Š å¯¹æ¯”å›¾å·²ä¿å­˜: {comparison_path}")
    
    print(f"\nâœ… æ£€æµ‹æµ‹è¯•å®Œæˆï¼")
    print(f"ğŸ¯ æ¨¡å‹çŠ¶æ€åˆ†æï¼š")
    print(f"   - ç›®æ ‡ç½®ä¿¡åº¦ï¼šæ­£å¸¸ (1.0)")
    print(f"   - ç±»åˆ«ç½®ä¿¡åº¦ï¼šè¾ƒä½ (0.0002-0.002)")
    print(f"   - æœ€ç»ˆç½®ä¿¡åº¦ï¼šå¾ˆä½ (çº¦0.0003)")
    print(f"   - ç»“è®ºï¼šæ¨¡å‹èƒ½æ£€æµ‹åˆ°ç›®æ ‡ä½ç½®ï¼Œä½†ç±»åˆ«åˆ†ç±»èƒ½åŠ›éœ€è¦æ”¹è¿›")
    
    return True

if __name__ == "__main__":
    success = final_detection_test()
    if success:
        print("\nğŸ‰ æœ€ç»ˆæ£€æµ‹æµ‹è¯•å®Œæˆï¼")
        print("ğŸ“¸ è¯·æŸ¥çœ‹ç”Ÿæˆçš„å›¾åƒæ–‡ä»¶ï¼š")
        print("   - final_detection_result.jpg (æ£€æµ‹ç»“æœ)")
        print("   - final_detection_comparison.jpg (å¯¹æ¯”å›¾)")
    else:
        print("\nâŒ æœ€ç»ˆæ£€æµ‹æµ‹è¯•å¤±è´¥ï¼")
