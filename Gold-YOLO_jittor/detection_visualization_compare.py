#!/usr/bin/env python3
"""
GOLD-YOLOæ£€æµ‹ç»“æœå¯è§†åŒ–å¯¹æ¯”ç³»ç»Ÿ
å¤„ç†é‡å¤æ£€æµ‹é—®é¢˜å¹¶ä¸çœŸå®æ ‡æ³¨å¯¹æ¯”
"""

import os
import sys
import cv2
import numpy as np
import jittor as jt

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models.perfect_gold_yolo import create_perfect_gold_yolo_model
from yolov6.data.data_augment import letterbox

def xywh2xyxy(x):
    """å°†xywhæ ¼å¼è½¬æ¢ä¸ºxyxyæ ¼å¼"""
    y = jt.zeros_like(x)
    y[:, 0] = x[:, 0] - x[:, 2] / 2  # x1
    y[:, 1] = x[:, 1] - x[:, 3] / 2  # y1
    y[:, 2] = x[:, 0] + x[:, 2] / 2  # x2
    y[:, 3] = x[:, 1] + x[:, 3] / 2  # y2
    return y

def simple_nms(boxes, scores, iou_threshold=0.5):
    """ç®€åŒ–çš„NMSå®ç°ï¼Œå¤„ç†é‡å¤æ£€æµ‹"""
    if len(boxes) == 0:
        return []
    
    # è½¬æ¢ä¸ºnumpyè¿›è¡Œå¤„ç†
    if hasattr(boxes, 'numpy'):
        boxes = boxes.numpy()
    if hasattr(scores, 'numpy'):
        scores = scores.numpy()
    
    # æŒ‰ç½®ä¿¡åº¦æ’åº
    indices = np.argsort(scores)[::-1]
    
    keep = []
    while len(indices) > 0:
        # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„
        current = indices[0]
        keep.append(current)
        
        if len(indices) == 1:
            break
        
        # è®¡ç®—IoU
        current_box = boxes[current]
        other_boxes = boxes[indices[1:]]
        
        # è®¡ç®—äº¤é›†
        x1 = np.maximum(current_box[0], other_boxes[:, 0])
        y1 = np.maximum(current_box[1], other_boxes[:, 1])
        x2 = np.minimum(current_box[2], other_boxes[:, 2])
        y2 = np.minimum(current_box[3], other_boxes[:, 3])
        
        intersection = np.maximum(0, x2 - x1) * np.maximum(0, y2 - y1)
        
        # è®¡ç®—å¹¶é›†
        area_current = (current_box[2] - current_box[0]) * (current_box[3] - current_box[1])
        area_others = (other_boxes[:, 2] - other_boxes[:, 0]) * (other_boxes[:, 3] - other_boxes[:, 1])
        union = area_current + area_others - intersection
        
        # è®¡ç®—IoU
        iou = intersection / (union + 1e-6)
        
        # ä¿ç•™IoUå°äºé˜ˆå€¼çš„æ¡†
        indices = indices[1:][iou < iou_threshold]
    
    return keep

def load_ground_truth_labels(img_path):
    """åŠ è½½çœŸå®æ ‡æ³¨ï¼ˆä»VOCæ•°æ®é›†æˆ–æ‰‹åŠ¨åˆ›å»ºï¼‰"""
    # è¿™é‡Œæˆ‘ä»¬åˆ›å»ºä¸€äº›ç¤ºä¾‹æ ‡æ³¨ç”¨äºå¯¹æ¯”
    # å®é™…ä½¿ç”¨æ—¶åº”è¯¥ä»æ ‡æ³¨æ–‡ä»¶åŠ è½½
    
    img = cv2.imread(img_path)
    h, w = img.shape[:2]
    
    # ç¤ºä¾‹æ ‡æ³¨ï¼šå‡è®¾å›¾åƒä¸­æœ‰ä¸€äº›ç›®æ ‡
    # æ ¼å¼ï¼š[class_id, x1, y1, x2, y2, confidence]
    gt_boxes = [
        [0, w*0.1, h*0.1, w*0.5, h*0.5, 1.0],  # ç±»åˆ«0ï¼Œå·¦ä¸Šè§’åŒºåŸŸ
        [1, w*0.6, h*0.3, w*0.9, h*0.7, 1.0],  # ç±»åˆ«1ï¼Œå³ä¾§åŒºåŸŸ
    ]
    
    return gt_boxes

def visualize_detection_comparison():
    """æ£€æµ‹ç»“æœå¯è§†åŒ–å¯¹æ¯”"""
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘              GOLD-YOLOæ£€æµ‹ç»“æœå¯è§†åŒ–å¯¹æ¯”ç³»ç»Ÿ                  â•‘
    â•‘                                                              â•‘
    â•‘  ğŸ¯ å¤„ç†é‡å¤æ£€æµ‹é—®é¢˜                                         â•‘
    â•‘  ğŸ“Š æ£€æµ‹ç»“æœä¸çœŸå®æ ‡æ³¨å¯è§†åŒ–å¯¹æ¯”                             â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ”§ åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹...")
    model = create_perfect_gold_yolo_model('gold_yolo-n', num_classes=20)
    
    # åŠ è½½è‡ªæ£€è®­ç»ƒçš„æƒé‡
    weights_path = 'simple_self_check_model.pkl'
    if os.path.exists(weights_path):
        model.load_state_dict(jt.load(weights_path))
        print(f"âœ… åŠ è½½è‡ªæ£€è®­ç»ƒæƒé‡: {weights_path}")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°è‡ªæ£€è®­ç»ƒæƒé‡ï¼Œä½¿ç”¨åˆå§‹åŒ–æƒé‡")
    
    model.eval()
    
    # åŠ è½½æµ‹è¯•å›¾åƒ
    img_path = '/home/kyc/project/GOLD-YOLO/Gold-YOLO_pytorch/runs/inference/pytorch_baseline_test/test_images/2008_000099.jpg'
    print(f"ğŸ“¸ åŠ è½½æµ‹è¯•å›¾åƒ: {os.path.basename(img_path)}")
    
    img0 = cv2.imread(img_path)
    if img0 is None:
        print(f"âŒ æ— æ³•è¯»å–å›¾åƒ: {img_path}")
        return False
    
    h0, w0 = img0.shape[:2]
    print(f"åŸå§‹å›¾åƒå°ºå¯¸: {w0}x{h0}")
    
    # é¢„å¤„ç†
    img = letterbox(img0, new_shape=640, stride=32, auto=False)[0]
    img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, HWC to CHW
    img = np.ascontiguousarray(img)
    img = img.astype(np.float32) / 255.0
    img_tensor = jt.array(img).unsqueeze(0)
    
    print(f"é¢„å¤„ç†åå›¾åƒå°ºå¯¸: {img_tensor.shape}")
    
    # æ¨ç†
    print("ğŸ” å¼€å§‹æ¨ç†...")
    with jt.no_grad():
        pred = model(img_tensor)
    
    print(f"æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {pred.shape}")
    
    # è§£æé¢„æµ‹ç»“æœ
    pred = pred[0]  # ç§»é™¤batchç»´åº¦ [8400, 25]
    
    # æå–åæ ‡ã€ç½®ä¿¡åº¦å’Œç±»åˆ«
    boxes = pred[:, :4]  # [x_center, y_center, width, height]
    obj_conf = pred[:, 4]  # ç›®æ ‡ç½®ä¿¡åº¦
    cls_conf = pred[:, 5:]  # ç±»åˆ«ç½®ä¿¡åº¦ [20]
    
    print(f"ç›®æ ‡ç½®ä¿¡åº¦èŒƒå›´: [{float(obj_conf.min().data):.6f}, {float(obj_conf.max().data):.6f}]")
    print(f"ç±»åˆ«ç½®ä¿¡åº¦èŒƒå›´: [{float(cls_conf.min().data):.6f}, {float(cls_conf.max().data):.6f}]")
    
    # è®¡ç®—æœ€ç»ˆç½®ä¿¡åº¦å’Œç±»åˆ«
    cls_scores = cls_conf.max(dim=1)[0]  # Jittorè¿”å›(values, indices)
    cls_indices = cls_conf.argmax(dim=1)
    final_conf = obj_conf * cls_scores
    
    print(f"æœ€ç»ˆç½®ä¿¡åº¦èŒƒå›´: [{float(final_conf.min().data):.6f}, {float(final_conf.max().data):.6f}]")
    
    # å¼ºåˆ¶å¯è§†åŒ–ï¼šé€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„å‰10ä¸ªæ£€æµ‹
    print("ğŸ”§ å¼ºåˆ¶å¯è§†åŒ–ç½®ä¿¡åº¦æœ€é«˜çš„æ£€æµ‹ç»“æœ...")

    # ç®€åŒ–æ–¹æ³•ï¼šç›´æ¥é€‰æ‹©å‰10ä¸ª
    num_to_show = min(10, len(final_conf))

    # ç­›é€‰æ£€æµ‹ç»“æœ - ä½¿ç”¨å‰Nä¸ª
    filtered_boxes = boxes[:num_to_show]
    filtered_conf = final_conf[:num_to_show]
    filtered_cls = cls_indices[:num_to_show]

    print(f"é€‰æ‹©çš„æ£€æµ‹æ•°é‡: {len(filtered_boxes)}")
    print(f"ç½®ä¿¡åº¦èŒƒå›´: [{float(filtered_conf.min().data):.6f}, {float(filtered_conf.max().data):.6f}]")

    # è½¬æ¢åæ ‡æ ¼å¼ xywh -> xyxy
    xyxy_boxes = xywh2xyxy(filtered_boxes)

    # ç¼©æ”¾åˆ°åŸå›¾å°ºå¯¸
    scale_x = w0 / 640
    scale_y = h0 / 640

    xyxy_boxes[:, [0, 2]] *= scale_x  # xåæ ‡
    xyxy_boxes[:, [1, 3]] *= scale_y  # yåæ ‡

    # åº”ç”¨NMSå¤„ç†é‡å¤æ£€æµ‹
    print("ğŸ”§ åº”ç”¨NMSå¤„ç†é‡å¤æ£€æµ‹...")
    keep_indices = simple_nms(xyxy_boxes, filtered_conf, iou_threshold=0.5)

    if len(keep_indices) > 0:
        final_boxes = xyxy_boxes[keep_indices]
        final_conf = filtered_conf[keep_indices]
        final_cls = filtered_cls[keep_indices]

        print(f"NMSåæ£€æµ‹æ•°é‡: {len(final_boxes)}")

        # åˆ›å»ºå¯è§†åŒ–å›¾åƒ
        img_vis = img0.copy()

        # å®šä¹‰é¢œè‰²
        colors = [
            (255, 0, 0),    # çº¢è‰²
            (0, 255, 0),    # ç»¿è‰²
            (0, 0, 255),    # è“è‰²
            (255, 255, 0),  # é»„è‰²
            (255, 0, 255),  # ç´«è‰²
            (0, 255, 255),  # é’è‰²
        ]
            
            # ç»˜åˆ¶æ£€æµ‹ç»“æœ
            for i, (box, conf, cls) in enumerate(zip(final_boxes, final_conf, final_cls)):
                if hasattr(box, 'numpy'):
                    box = box.numpy()
                if hasattr(conf, 'numpy'):
                    conf = conf.numpy()
                if hasattr(cls, 'numpy'):
                    cls = cls.numpy()
                
                x1, y1, x2, y2 = map(int, box)
                confidence = float(conf)
                class_id = int(cls)
                
                # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
                x1 = max(0, min(x1, w0-1))
                y1 = max(0, min(y1, h0-1))
                x2 = max(0, min(x2, w0-1))
                y2 = max(0, min(y2, h0-1))
                
                color = colors[class_id % len(colors)]
                
                # ç»˜åˆ¶è¾¹ç•Œæ¡†
                cv2.rectangle(img_vis, (x1, y1), (x2, y2), color, 2)
                
                # ç»˜åˆ¶æ ‡ç­¾
                label = f'Class{class_id} {confidence:.2f}'
                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
                cv2.rectangle(img_vis, (x1, y1-label_size[1]-5), (x1+label_size[0], y1), color, -1)
                cv2.putText(img_vis, label, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2)
                
                print(f"æ£€æµ‹ {i+1}: ç±»åˆ«={class_id}, ç½®ä¿¡åº¦={confidence:.3f}, åæ ‡=[{x1},{y1},{x2},{y2}]")
            
            # ä¿å­˜æ£€æµ‹ç»“æœ
            result_path = 'detection_result_comparison.jpg'
            cv2.imwrite(result_path, img_vis)
            print(f"ğŸ“¸ æ£€æµ‹ç»“æœå·²ä¿å­˜: {result_path}")
            
            # åŠ è½½çœŸå®æ ‡æ³¨å¹¶åˆ›å»ºå¯¹æ¯”å›¾
            print("\nğŸ”§ åˆ›å»ºä¸çœŸå®æ ‡æ³¨çš„å¯¹æ¯”...")
            gt_boxes = load_ground_truth_labels(img_path)
            
            # åˆ›å»ºå¯¹æ¯”å›¾åƒï¼ˆå·¦ï¼šæ£€æµ‹ç»“æœï¼Œå³ï¼šçœŸå®æ ‡æ³¨ï¼‰
            comparison_img = np.zeros((h0, w0*2, 3), dtype=np.uint8)
            comparison_img[:, :w0] = img_vis  # å·¦ä¾§ï¼šæ£€æµ‹ç»“æœ
            comparison_img[:, w0:] = img0    # å³ä¾§ï¼šåŸå›¾+çœŸå®æ ‡æ³¨
            
            # åœ¨å³ä¾§ç»˜åˆ¶çœŸå®æ ‡æ³¨
            for i, gt_box in enumerate(gt_boxes):
                class_id, x1, y1, x2, y2, conf = gt_box
                x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])
                
                # è°ƒæ•´åæ ‡åˆ°å³ä¾§å›¾åƒ
                x1 += w0
                x2 += w0
                
                color = (0, 255, 0)  # ç»¿è‰²è¡¨ç¤ºçœŸå®æ ‡æ³¨
                cv2.rectangle(comparison_img, (x1, y1), (x2, y2), color, 2)
                
                label = f'GT_Class{int(class_id)}'
                cv2.putText(comparison_img, label, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
            
            # æ·»åŠ æ ‡é¢˜
            cv2.putText(comparison_img, 'Detection Results', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)
            cv2.putText(comparison_img, 'Ground Truth', (w0+10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)
            
            # ä¿å­˜å¯¹æ¯”å›¾
            comparison_path = 'detection_vs_groundtruth_comparison.jpg'
            cv2.imwrite(comparison_path, comparison_img)
            print(f"ğŸ“Š å¯¹æ¯”å›¾å·²ä¿å­˜: {comparison_path}")
            
            print(f"\nâœ… æ£€æµ‹æˆåŠŸï¼å…±æ£€æµ‹åˆ° {len(final_boxes)} ä¸ªç›®æ ‡")
            print(f"ğŸ“ˆ é‡å¤æ£€æµ‹å¤„ç†ï¼šåŸå§‹{len(filtered_boxes)}ä¸ª -> NMSå{len(final_boxes)}ä¸ª")
            
            return True
        else:
            print("âŒ NMSåæ²¡æœ‰ä¿ç•™ä»»ä½•æ£€æµ‹ç»“æœ")
            return False
    else:
        print("âŒ æ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡")
        return False

if __name__ == "__main__":
    success = visualize_detection_comparison()
    if success:
        print("\nğŸ‰ æ£€æµ‹ç»“æœå¯è§†åŒ–å¯¹æ¯”å®Œæˆï¼")
    else:
        print("\nâŒ æ£€æµ‹ç»“æœå¯è§†åŒ–å¯¹æ¯”å¤±è´¥ï¼")
