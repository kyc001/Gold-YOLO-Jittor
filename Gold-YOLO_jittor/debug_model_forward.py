#!/usr/bin/env python3
"""
è°ƒè¯•æ¨¡å‹å‰å‘ä¼ æ’­é—®é¢˜
åˆ†æä¸ºä»€ä¹ˆæ‰€æœ‰è¾“å‡ºéƒ½ç›¸åŒ
"""

import os
import sys
import cv2
import numpy as np
import jittor as jt
from pathlib import Path

# æ·»åŠ è·¯å¾„
sys.path.append('.')
sys.path.append('./yolov6')

from models.perfect_gold_yolo import create_perfect_gold_yolo_model
from yolov6.data.data_augment import letterbox

def debug_model_forward():
    """è°ƒè¯•æ¨¡å‹å‰å‘ä¼ æ’­"""
    print(f"ğŸ” è°ƒè¯•æ¨¡å‹å‰å‘ä¼ æ’­é—®é¢˜")
    print("=" * 80)
    
    # å‡†å¤‡æ•°æ®
    img_path = "/home/kyc/project/GOLD-YOLO/2008_001420.jpg"
    original_img = cv2.imread(img_path)
    img = letterbox(original_img, new_shape=500, stride=32, auto=False)[0]
    img_tensor_input = img.transpose((2, 0, 1))[::-1]
    img_tensor_input = np.ascontiguousarray(img_tensor_input)
    img_tensor_input = img_tensor_input.astype(np.float32) / 255.0
    img_tensor = jt.array(img_tensor_input).unsqueeze(0)
    
    print(f"ğŸ“Š è¾“å…¥æ•°æ®:")
    print(f"   å›¾åƒå¼ é‡: {img_tensor.shape}")
    print(f"   åƒç´ èŒƒå›´: [{float(img_tensor.min()):.6f}, {float(img_tensor.max()):.6f}]")
    print(f"   åƒç´ å‡å€¼: {float(img_tensor.mean()):.6f}")
    print(f"   åƒç´ æ ‡å‡†å·®: {float(img_tensor.std()):.6f}")
    
    # åˆ›å»ºæ¨¡å‹
    print(f"\nğŸ¯ åˆ›å»ºæ¨¡å‹:")
    model = create_perfect_gold_yolo_model()
    model.train()
    
    # æ£€æŸ¥æ¨¡å‹å‚æ•°åˆå§‹åŒ–
    print(f"\nğŸ” æ£€æŸ¥æ¨¡å‹å‚æ•°åˆå§‹åŒ–:")
    
    param_stats = {}
    for name, param in model.named_parameters():
        if param.requires_grad:
            param_mean = float(param.mean())
            param_std = float(param.std())
            param_min = float(param.min())
            param_max = float(param.max())
            
            param_stats[name] = {
                'mean': param_mean,
                'std': param_std,
                'min': param_min,
                'max': param_max,
                'shape': param.shape
            }
            
            # åªæ˜¾ç¤ºå…³é”®å±‚
            if any(keyword in name for keyword in ['cls_pred', 'reg_pred', 'stem', 'head']):
                print(f"   {name}: å‡å€¼={param_mean:.6f}, æ ‡å‡†å·®={param_std:.6f}, èŒƒå›´=[{param_min:.6f}, {param_max:.6f}]")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å‚æ•°ä¸º0æˆ–å¸¸æ•°
    zero_params = []
    constant_params = []
    
    for name, stats in param_stats.items():
        if abs(stats['std']) < 1e-8:
            if abs(stats['mean']) < 1e-8:
                zero_params.append(name)
            else:
                constant_params.append(name)
    
    if zero_params:
        print(f"\nâš ï¸ é›¶å‚æ•° ({len(zero_params)}ä¸ª):")
        for name in zero_params[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"     {name}")
        if len(zero_params) > 5:
            print(f"     ... è¿˜æœ‰ {len(zero_params) - 5} ä¸ª")
    
    if constant_params:
        print(f"\nâš ï¸ å¸¸æ•°å‚æ•° ({len(constant_params)}ä¸ª):")
        for name in constant_params[:5]:
            print(f"     {name}")
        if len(constant_params) > 5:
            print(f"     ... è¿˜æœ‰ {len(constant_params) - 5} ä¸ª")
    
    # é€å±‚å‰å‘ä¼ æ’­åˆ†æ
    print(f"\nğŸ”„ é€å±‚å‰å‘ä¼ æ’­åˆ†æ:")
    
    # Hookå‡½æ•°æ¥æ•è·ä¸­é—´è¾“å‡º
    layer_outputs = {}
    
    def create_hook(layer_name):
        def hook_fn(module, input, output):
            if isinstance(output, jt.Var):
                layer_outputs[layer_name] = {
                    'shape': output.shape,
                    'mean': float(output.mean()),
                    'std': float(output.std()),
                    'min': float(output.min()),
                    'max': float(output.max())
                }
            elif isinstance(output, (list, tuple)):
                for i, out in enumerate(output):
                    if isinstance(out, jt.Var):
                        layer_outputs[f"{layer_name}_out{i}"] = {
                            'shape': out.shape,
                            'mean': float(out.mean()),
                            'std': float(out.std()),
                            'min': float(out.min()),
                            'max': float(out.max())
                        }
        return hook_fn
    
    # æ³¨å†Œå…³é”®å±‚çš„hook
    hooks = []
    
    # Backbone hooks
    if hasattr(model, 'backbone'):
        hook = model.backbone.register_forward_hook(create_hook('backbone'))
        hooks.append(hook)
    
    # Neck hooks
    if hasattr(model, 'neck'):
        hook = model.neck.register_forward_hook(create_hook('neck'))
        hooks.append(hook)
    
    # Head hooks
    if hasattr(model, 'head'):
        hook = model.head.register_forward_hook(create_hook('head'))
        hooks.append(hook)
        
        # Headå­æ¨¡å—hooks
        if hasattr(model.head, 'cls_pred'):
            for i, cls_pred in enumerate(model.head.cls_pred):
                hook = cls_pred.register_forward_hook(create_hook(f'cls_pred_{i}'))
                hooks.append(hook)
        
        if hasattr(model.head, 'reg_pred'):
            for i, reg_pred in enumerate(model.head.reg_pred):
                hook = reg_pred.register_forward_hook(create_hook(f'reg_pred_{i}'))
                hooks.append(hook)
    
    # å‰å‘ä¼ æ’­
    print(f"   æ‰§è¡Œå‰å‘ä¼ æ’­...")
    outputs = model(img_tensor)
    
    # ç§»é™¤hooks
    for hook in hooks:
        hook.remove()
    
    # åˆ†æä¸­é—´å±‚è¾“å‡º
    print(f"\nğŸ“Š ä¸­é—´å±‚è¾“å‡ºåˆ†æ:")
    for layer_name, stats in layer_outputs.items():
        print(f"   {layer_name}: {stats['shape']}, å‡å€¼={stats['mean']:.6f}, æ ‡å‡†å·®={stats['std']:.6f}, èŒƒå›´=[{stats['min']:.6f}, {stats['max']:.6f}]")
        
        # æ£€æŸ¥å¼‚å¸¸è¾“å‡º
        if abs(stats['std']) < 1e-8:
            print(f"     âš ï¸ è¾“å‡ºä¸ºå¸¸æ•°ï¼")
        if stats['min'] == stats['max']:
            print(f"     âš ï¸ æ‰€æœ‰å€¼ç›¸åŒï¼")
    
    # åˆ†ææœ€ç»ˆè¾“å‡º
    print(f"\nğŸ¯ æœ€ç»ˆè¾“å‡ºåˆ†æ:")
    if isinstance(outputs, (list, tuple)):
        for i, output in enumerate(outputs):
            if isinstance(output, jt.Var):
                print(f"   è¾“å‡º{i}: {output.shape}")
                print(f"     å‡å€¼: {float(output.mean()):.6f}")
                print(f"     æ ‡å‡†å·®: {float(output.std()):.6f}")
                print(f"     èŒƒå›´: [{float(output.min()):.6f}, {float(output.max()):.6f}]")
                
                # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å€¼ç›¸åŒ
                if float(output.std()) < 1e-8:
                    print(f"     âŒ æ‰€æœ‰å€¼ç›¸åŒï¼è¿™æ˜¯é—®é¢˜æ‰€åœ¨ï¼")
                    
                    # æ£€æŸ¥å…·ä½“å€¼
                    unique_values = jt.unique(output.flatten())
                    print(f"     å”¯ä¸€å€¼æ•°é‡: {len(unique_values)}")
                    if len(unique_values) <= 5:
                        print(f"     å”¯ä¸€å€¼: {[float(v) for v in unique_values]}")
    
    # æ£€æŸ¥æ¢¯åº¦è®¡ç®—
    print(f"\nğŸ” æ£€æŸ¥æ¢¯åº¦è®¡ç®—:")
    
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„æŸå¤±
    if isinstance(outputs, (list, tuple)) and len(outputs) >= 2:
        pred_scores = outputs[1]
        pred_distri = outputs[2]
        
        # ç®€å•çš„L2æŸå¤±
        target_scores = jt.ones_like(pred_scores) * 0.5
        target_distri = jt.ones_like(pred_distri) * 2.0
        
        loss = ((pred_scores - target_scores) ** 2).mean() + ((pred_distri - target_distri) ** 2).mean()
        print(f"   ç®€å•æŸå¤±: {float(loss):.6f}")
        
        # åå‘ä¼ æ’­
        optimizer = jt.optim.SGD(model.parameters(), lr=0.01)
        optimizer.zero_grad()
        optimizer.backward(loss)
        
        # æ£€æŸ¥æ¢¯åº¦
        grad_stats = {}
        for name, param in model.named_parameters():
            if param.requires_grad:
                try:
                    grad = param.opt_grad(optimizer)
                    if grad is not None:
                        grad_norm = float(grad.norm())
                        grad_stats[name] = grad_norm
                    else:
                        grad_stats[name] = 0.0
                except:
                    grad_stats[name] = 0.0
        
        # ç»Ÿè®¡æ¢¯åº¦
        non_zero_grads = sum(1 for g in grad_stats.values() if g > 1e-8)
        total_grads = len(grad_stats)
        
        print(f"   æœ‰æ¢¯åº¦çš„å‚æ•°: {non_zero_grads}/{total_grads}")
        
        # æ˜¾ç¤ºå…³é”®å±‚æ¢¯åº¦
        for name, grad_norm in grad_stats.items():
            if any(keyword in name for keyword in ['cls_pred', 'reg_pred', 'stem']) and grad_norm > 1e-8:
                print(f"     {name}: æ¢¯åº¦èŒƒæ•°={grad_norm:.6f}")
    
    return {
        'layer_outputs': layer_outputs,
        'param_stats': param_stats,
        'outputs': outputs
    }

def main():
    print("ğŸ” æ¨¡å‹å‰å‘ä¼ æ’­è°ƒè¯•")
    print("=" * 80)
    
    try:
        result = debug_model_forward()
        
        if result:
            print(f"\nâœ… è°ƒè¯•å®Œæˆ!")
            
            # æ€»ç»“é—®é¢˜
            outputs = result['outputs']
            if isinstance(outputs, (list, tuple)) and len(outputs) >= 2:
                pred_scores = outputs[1]
                pred_distri = outputs[2]
                
                scores_std = float(pred_scores.std())
                distri_std = float(pred_distri.std())
                
                if scores_std < 1e-8 and distri_std < 1e-8:
                    print(f"\nâŒ å‘ç°é—®é¢˜: æ¨¡å‹è¾“å‡ºä¸ºå¸¸æ•°")
                    print(f"   å¯èƒ½åŸå› :")
                    print(f"   1. æ¨¡å‹åˆå§‹åŒ–æœ‰é—®é¢˜")
                    print(f"   2. æŸäº›å±‚æ²¡æœ‰æ­£ç¡®å·¥ä½œ")
                    print(f"   3. æ¿€æ´»å‡½æ•°æœ‰é—®é¢˜")
                    print(f"   4. BatchNormå±‚æœ‰é—®é¢˜")
                else:
                    print(f"\nâœ… æ¨¡å‹è¾“å‡ºæ­£å¸¸")
        else:
            print(f"\nâŒ è°ƒè¯•å¤±è´¥!")
            
    except Exception as e:
        print(f"\nâŒ è°ƒè¯•å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
