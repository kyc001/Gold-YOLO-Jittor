#!/usr/bin/env python3
"""
é¡¹ç›®æ¸…ç†è„šæœ¬
æ¸…ç†å†—ä½™æ–‡ä»¶ã€è°ƒè¯•è„šæœ¬å’Œæ— ç”¨é‡å¤æ•°æ®
"""

import os
import shutil
from pathlib import Path

def cleanup_project():
    """æ¸…ç†é¡¹ç›®ç›®å½•"""
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                    é¡¹ç›®æ¸…ç†è„šæœ¬                               â•‘
    â•‘                                                              â•‘
    â•‘  ğŸ§¹ æ¸…ç†å†—ä½™æ–‡ä»¶å’Œè°ƒè¯•è„šæœ¬                                   â•‘
    â•‘  ğŸ“¦ æ•´ç†é¡¹ç›®ç»“æ„                                             â•‘
    â•‘  ğŸ’¾ ä¿ç•™æ ¸å¿ƒåŠŸèƒ½æ–‡ä»¶                                         â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # å®šä¹‰è¦åˆ é™¤çš„è°ƒè¯•è„šæœ¬
    debug_scripts = [
        'check_weights.py',
        'debug_loss_function.py',
        'debug_loss_preprocessing.py',
        'debug_model_output.py',
        'debug_weight_loading.py',
        'deep_analysis_confidence.py',
        'deep_classification_analysis.py',
        'detection_visualization_compare.py',
        'eval_pytorch_strict_aligned.py',
        'final_classification_fix.py',
        'final_complete_training.py',
        'final_detection_test.py',
        'final_evaluation_test.py',
        'fix_classification_head.py',
        'fix_coordinate_conversion.py',
        'monitored_self_check_training.py',
        'quick_fix_test.py',
        'self_check_training.py',
        'simple_final_test.py',
        'simple_self_check.py',
        'simplified_confidence_analysis.py',
        'test_gradient_fix.py',
        'test_model_loading.py',
        'train_pytorch_aligned_stable.py',
        'complete_self_check_training.py',
        'ultimate_final_training.py'
    ]
    
    # å®šä¹‰è¦åˆ é™¤çš„ä¸´æ—¶æ ‡ç­¾æ–‡ä»¶
    temp_labels = [
        'complete_self_check_label.txt',
        'final_classification_fix_label.txt',
        'final_complete_label.txt',
        'monitored_self_check_label.txt',
        'self_check_label.txt',
        'ultimate_final_label.txt'
    ]
    
    # å®šä¹‰è¦åˆ é™¤çš„ä¸´æ—¶æ¨¡å‹æ–‡ä»¶
    temp_models = [
        'complete_self_check_model.pkl',
        'final_classification_fixed_model.pkl',
        'final_complete_model.pkl',
        'fixed_classification_model.pkl',
        'self_check_model.pkl',
        'simple_self_check_model.pkl'
    ]
    
    # ä¿ç•™æœ€ç»ˆæ¨¡å‹
    keep_models = [
        'ultimate_final_model.pkl'  # è¿™æ˜¯æœ€ç»ˆè®­ç»ƒå¥½çš„æ¨¡å‹
    ]
    
    # ä¿ç•™æ ¸å¿ƒåŠŸèƒ½è„šæœ¬
    keep_scripts = [
        'final_inference_visualization.py',  # æ¨ç†å¯è§†åŒ–è„šæœ¬
        'train.py',  # ä¸»è®­ç»ƒè„šæœ¬
        'FINAL_REPORT.md',  # æœ€ç»ˆæŠ¥å‘Š
        'README.md',  # è¯´æ˜æ–‡æ¡£
        'requirements.txt',  # ä¾èµ–æ–‡ä»¶
        'setup.py'  # å®‰è£…è„šæœ¬
    ]
    
    deleted_files = []
    kept_files = []
    
    print("ğŸ§¹ å¼€å§‹æ¸…ç†è°ƒè¯•è„šæœ¬...")
    for script in debug_scripts:
        if os.path.exists(script):
            if script not in keep_scripts:
                os.remove(script)
                deleted_files.append(script)
                print(f"   âŒ åˆ é™¤è°ƒè¯•è„šæœ¬: {script}")
            else:
                kept_files.append(script)
                print(f"   âœ… ä¿ç•™æ ¸å¿ƒè„šæœ¬: {script}")
    
    print("\nğŸ§¹ å¼€å§‹æ¸…ç†ä¸´æ—¶æ ‡ç­¾æ–‡ä»¶...")
    for label in temp_labels:
        if os.path.exists(label):
            os.remove(label)
            deleted_files.append(label)
            print(f"   âŒ åˆ é™¤ä¸´æ—¶æ ‡ç­¾: {label}")
    
    print("\nğŸ§¹ å¼€å§‹æ¸…ç†ä¸´æ—¶æ¨¡å‹æ–‡ä»¶...")
    for model in temp_models:
        if os.path.exists(model):
            os.remove(model)
            deleted_files.append(model)
            print(f"   âŒ åˆ é™¤ä¸´æ—¶æ¨¡å‹: {model}")
    
    for model in keep_models:
        if os.path.exists(model):
            kept_files.append(model)
            print(f"   âœ… ä¿ç•™æœ€ç»ˆæ¨¡å‹: {model}")
    
    # æ¸…ç†__pycache__ç›®å½•
    print("\nğŸ§¹ æ¸…ç†Pythonç¼“å­˜æ–‡ä»¶...")
    for root, dirs, files in os.walk('.'):
        for dir_name in dirs:
            if dir_name == '__pycache__':
                cache_path = os.path.join(root, dir_name)
                shutil.rmtree(cache_path)
                deleted_files.append(cache_path)
                print(f"   âŒ åˆ é™¤ç¼“å­˜ç›®å½•: {cache_path}")
    
    # æ¸…ç†ç©ºçš„runsç›®å½•ä¸­çš„æ—§ç»“æœ
    runs_dir = Path('runs')
    if runs_dir.exists():
        print("\nğŸ§¹ æ¸…ç†æ—§çš„æ¨ç†ç»“æœ...")
        for subdir in runs_dir.iterdir():
            if subdir.is_dir():
                # ä¿ç•™æœ€æ–°çš„final_testç»“æœ
                if subdir.name != 'inference' or not (subdir / 'final_test').exists():
                    shutil.rmtree(subdir)
                    deleted_files.append(str(subdir))
                    print(f"   âŒ åˆ é™¤æ—§ç»“æœ: {subdir}")
                else:
                    kept_files.append(str(subdir))
                    print(f"   âœ… ä¿ç•™æœ€ç»ˆæ¨ç†ç»“æœ: {subdir}")
    
    # åˆ›å»ºæ¸…ç†æŠ¥å‘Š
    print("\nğŸ“Š ç”Ÿæˆæ¸…ç†æŠ¥å‘Š...")
    
    report = f"""# é¡¹ç›®æ¸…ç†æŠ¥å‘Š

## æ¸…ç†ç»Ÿè®¡
- åˆ é™¤æ–‡ä»¶æ•°é‡: {len(deleted_files)}
- ä¿ç•™æ–‡ä»¶æ•°é‡: {len(kept_files)}

## åˆ é™¤çš„æ–‡ä»¶
"""
    
    for file in sorted(deleted_files):
        report += f"- {file}\n"
    
    report += f"""
## ä¿ç•™çš„æ ¸å¿ƒæ–‡ä»¶
"""
    
    for file in sorted(kept_files):
        report += f"- {file}\n"
    
    report += f"""
## æ¸…ç†åçš„é¡¹ç›®ç»“æ„
```
Gold-YOLO_jittor/
â”œâ”€â”€ models/                    # æ¨¡å‹å®šä¹‰
â”œâ”€â”€ yolov6/                    # æ ¸å¿ƒç®—æ³•åº“
â”œâ”€â”€ configs/                   # é…ç½®æ–‡ä»¶
â”œâ”€â”€ tools/                     # å·¥å…·è„šæœ¬
â”œâ”€â”€ data/                      # æ•°æ®é…ç½®
â”œâ”€â”€ docs/                      # æ–‡æ¡£
â”œâ”€â”€ runs/inference/final_test/ # æœ€ç»ˆæ¨ç†ç»“æœ
â”œâ”€â”€ final_inference_visualization.py  # æ¨ç†è„šæœ¬
â”œâ”€â”€ train.py                   # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ ultimate_final_model.pkl   # æœ€ç»ˆæ¨¡å‹
â”œâ”€â”€ FINAL_REPORT.md           # æŠ€æœ¯æŠ¥å‘Š
â””â”€â”€ README.md                 # é¡¹ç›®è¯´æ˜
```

## é¡¹ç›®çŠ¶æ€
âœ… é¡¹ç›®æ¸…ç†å®Œæˆï¼Œç»“æ„æ¸…æ™°
âœ… ä¿ç•™æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½
âœ… åˆ é™¤å†—ä½™è°ƒè¯•æ–‡ä»¶
âœ… é¡¹ç›®å¯ç›´æ¥ä½¿ç”¨
"""
    
    with open('CLEANUP_REPORT.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"ğŸ“‹ æ¸…ç†æŠ¥å‘Šå·²ä¿å­˜: CLEANUP_REPORT.md")
    
    # è¾“å‡ºæ¸…ç†æ€»ç»“
    print("\n" + "="*70)
    print("ğŸ‰ é¡¹ç›®æ¸…ç†å®Œæˆï¼")
    print("="*70)
    print(f"ğŸ“Š æ¸…ç†ç»Ÿè®¡:")
    print(f"   åˆ é™¤æ–‡ä»¶: {len(deleted_files)} ä¸ª")
    print(f"   ä¿ç•™æ–‡ä»¶: {len(kept_files)} ä¸ª")
    print(f"   é¡¹ç›®å¤§å°: æ˜¾è‘—å‡å°‘")
    
    print(f"\nâœ… ä¿ç•™çš„æ ¸å¿ƒåŠŸèƒ½:")
    print(f"   - å®Œæ•´çš„æ¨¡å‹å®šä¹‰å’Œç®—æ³•åº“")
    print(f"   - æœ€ç»ˆè®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡")
    print(f"   - æ¨ç†å’Œå¯è§†åŒ–è„šæœ¬")
    print(f"   - å®Œæ•´çš„æŠ€æœ¯æ–‡æ¡£")
    print(f"   - æœ€ç»ˆæ¨ç†æµ‹è¯•ç»“æœ")
    
    print(f"\nğŸ¯ é¡¹ç›®ç°åœ¨å¯ä»¥ç›´æ¥ç”¨äº:")
    print(f"   - æ¨¡å‹æ¨ç†å’Œæ£€æµ‹")
    print(f"   - è¿›ä¸€æ­¥çš„è®­ç»ƒ")
    print(f"   - æ€§èƒ½è¯„ä¼°")
    print(f"   - éƒ¨ç½²åº”ç”¨")
    
    return len(deleted_files), len(kept_files)

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹é¡¹ç›®æ¸…ç†...")
    deleted_count, kept_count = cleanup_project()
    print(f"\nğŸ‰ æ¸…ç†å®Œæˆï¼åˆ é™¤äº†{deleted_count}ä¸ªæ–‡ä»¶ï¼Œä¿ç•™äº†{kept_count}ä¸ªæ ¸å¿ƒæ–‡ä»¶ã€‚")
