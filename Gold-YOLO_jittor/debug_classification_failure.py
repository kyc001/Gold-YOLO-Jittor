#!/usr/bin/env python3
"""
è°ƒè¯•åˆ†ç±»å­¦ä¹ å¤±è´¥é—®é¢˜
åˆ†æä¸ºä»€ä¹ˆæœŸæœ›ç±»åˆ«åˆ†æ•°å…¨ä¸º0ï¼Œaeroplaneåˆ†æ•°ä¸º1
"""

import os
import sys
import cv2
import numpy as np
import jittor as jt
import time
from pathlib import Path

# æ·»åŠ è·¯å¾„
sys.path.append('.')
sys.path.append('./yolov6')

from models.perfect_gold_yolo import create_perfect_gold_yolo_model
from yolov6.data.data_augment import letterbox
from yolov6.models.losses import ComputeLoss

# VOCæ•°æ®é›†ç±»åˆ«åç§°
VOC_CLASSES = [
    'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',
    'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'
]

def pytorch_exact_initialization(model):
    """å®Œå…¨ç…§æŠ„PyTorchç‰ˆæœ¬çš„åˆå§‹åŒ–"""
    for name, module in model.named_modules():
        if hasattr(module, 'initialize_biases'):
            module.initialize_biases()
            break
    return model

def debug_classification_failure():
    """è°ƒè¯•åˆ†ç±»å­¦ä¹ å¤±è´¥é—®é¢˜"""
    print(f"ğŸ”§ è°ƒè¯•åˆ†ç±»å­¦ä¹ å¤±è´¥é—®é¢˜")
    print("=" * 50)
    
    # å‡†å¤‡æ•°æ®
    label_file = "/home/kyc/project/GOLD-YOLO/2008_001420.txt"
    img_path = "/home/kyc/project/GOLD-YOLO/2008_001420.jpg"
    
    # è¯»å–çœŸå®æ ‡æ³¨
    annotations = []
    with open(label_file, 'r') as f:
        for line in f:
            line = line.strip()
            if line:
                parts = line.split()
                if len(parts) >= 5:
                    cls_id = int(parts[0])
                    x_center = float(parts[1])
                    y_center = float(parts[2])
                    width = float(parts[3])
                    height = float(parts[4])
                    annotations.append([cls_id, x_center, y_center, width, height])
    
    target_counts = {}
    for ann in annotations:
        cls_name = VOC_CLASSES[ann[0]]
        target_counts[cls_name] = target_counts.get(cls_name, 0) + 1
    
    print(f"ğŸ“‹ æœŸæœ›æ£€æµ‹ç»“æœ: {target_counts}")
    print(f"   æœŸæœ›ç±»åˆ«ID: {[ann[0] for ann in annotations]}")
    
    # å‡†å¤‡è¾“å…¥
    original_img = cv2.imread(img_path)
    img = letterbox(original_img, new_shape=640, stride=32, auto=False)[0]
    img = img.transpose((2, 0, 1))[::-1]
    img = np.ascontiguousarray(img)
    img = img.astype(np.float32) / 255.0
    img_tensor = jt.array(img).unsqueeze(0)
    
    # å‡†å¤‡æ ‡ç­¾
    targets = []
    for ann in annotations:
        cls_id, x_center, y_center, width, height = ann
        targets.append([0, cls_id, x_center, y_center, width, height])
    targets_tensor = jt.array(targets, dtype=jt.float32).unsqueeze(0)
    
    print(f"ğŸ“Š æ ‡ç­¾åˆ†æ:")
    print(f"   targets_tensorå½¢çŠ¶: {targets_tensor.shape}")
    targets_np = targets_tensor.numpy() if hasattr(targets_tensor, 'numpy') else targets_tensor
    print(f"   targets_tensorå†…å®¹: {targets_np}")
    
    # åˆ›å»ºæ¨¡å‹
    model = create_perfect_gold_yolo_model()
    model = pytorch_exact_initialization(model)
    model.train()
    
    # åˆ›å»ºæŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    loss_fn = ComputeLoss(
        num_classes=20,
        ori_img_size=640,
        warmup_epoch=4,
        use_dfl=False,
        reg_max=0,
        iou_type='giou',
        loss_weight={'class': 1.0, 'iou': 2.5, 'dfl': 0.5}
    )
    optimizer = jt.optim.AdamW(model.parameters(), lr=0.05)
    
    print(f"\nğŸ” æ·±å…¥åˆ†æåˆ†ç±»å­¦ä¹ è¿‡ç¨‹:")
    
    # è®­ç»ƒå‰æ£€æŸ¥
    print(f"\nğŸ“Š è®­ç»ƒå‰æ¨¡å‹è¾“å‡º:")
    model.eval()
    with jt.no_grad():
        initial_outputs = model(img_tensor)

        # æ£€æŸ¥è¾“å‡ºæ ¼å¼
        if isinstance(initial_outputs, tuple):
            print(f"   è¾“å‡ºæ˜¯tupleï¼Œé•¿åº¦: {len(initial_outputs)}")
            # ä½¿ç”¨æ¨ç†æ¨¡å¼çš„è¾“å‡ºæ ¼å¼
            if len(initial_outputs) >= 3:
                # æ¨ç†æ¨¡å¼ï¼š(pred_scores, pred_distri, ...)
                pred_scores = initial_outputs[1]  # [1, 8400, 20]
                pred_distri = initial_outputs[2]  # [1, 8400, 4]

                print(f"   pred_scoreså½¢çŠ¶: {pred_scores.shape}")
                print(f"   pred_distriå½¢çŠ¶: {pred_distri.shape}")
                print(f"   pred_scoresèŒƒå›´: [{pred_scores.min():.6f}, {pred_scores.max():.6f}]")

                # æ£€æŸ¥æ‰€æœ‰ç±»åˆ«çš„åˆå§‹åˆ†æ•°
                print(f"   æ‰€æœ‰ç±»åˆ«çš„åˆå§‹åˆ†æ•°:")
                for cls_id in range(20):
                    cls_scores = pred_scores[0, :, cls_id]
                    max_score = float(cls_scores.max())
                    if max_score > 0.005:  # åªæ˜¾ç¤ºæœ‰æ„ä¹‰çš„åˆ†æ•°
                        cls_name = VOC_CLASSES[cls_id]
                        print(f"     {cls_name}(ç±»åˆ«{cls_id}): æœ€å¤§{max_score:.6f}")
        else:
            # è®­ç»ƒæ¨¡å¼çš„è¾“å‡ºæ ¼å¼
            coords = initial_outputs[..., :4]
            objectness = initial_outputs[..., 4]
            classes = initial_outputs[..., 5:]

            print(f"   åæ ‡èŒƒå›´: [{coords.min():.3f}, {coords.max():.3f}]")
            print(f"   objectnessèŒƒå›´: [{objectness.min():.3f}, {objectness.max():.3f}]")
            print(f"   ç±»åˆ«åˆ†æ•°èŒƒå›´: [{classes.min():.6f}, {classes.max():.6f}]")

            # æ£€æŸ¥æ‰€æœ‰ç±»åˆ«çš„åˆå§‹åˆ†æ•°
            print(f"   æ‰€æœ‰ç±»åˆ«çš„åˆå§‹åˆ†æ•°:")
            for cls_id in range(20):
                cls_scores = classes[0, :, cls_id]
                max_score = float(cls_scores.max())
                if max_score > 0.005:  # åªæ˜¾ç¤ºæœ‰æ„ä¹‰çš„åˆ†æ•°
                    cls_name = VOC_CLASSES[cls_id]
                    print(f"     {cls_name}(ç±»åˆ«{cls_id}): æœ€å¤§{max_score:.6f}")

    model.train()
    
    # è®­ç»ƒå¾ªç¯ - è¯¦ç»†åˆ†æ
    for epoch in range(50):
        # å‰å‘ä¼ æ’­
        outputs = model(img_tensor)
        
        # è®¡ç®—æŸå¤±
        loss, loss_items = loss_fn(outputs, targets_tensor, epoch_num=epoch+1, step_num=1)
        
        # ä¼˜åŒ–
        optimizer.step(loss)
        
        epoch_loss = float(loss.numpy())
        
        # æ¯10è½®è¯¦ç»†åˆ†æ
        if (epoch + 1) % 10 == 0:
            print(f"\n   Epoch {epoch+1}: Loss {epoch_loss:.6f}")
            
            # åˆ†ææ¨¡å‹è¾“å‡º
            model.eval()
            with jt.no_grad():
                test_outputs = model(img_tensor)
                coords = test_outputs[..., :4]
                objectness = test_outputs[..., 4]
                classes = test_outputs[..., 5:]
                
                print(f"     æ¨¡å‹è¾“å‡ºåˆ†æ:")
                print(f"       åæ ‡èŒƒå›´: [{coords.min():.3f}, {coords.max():.3f}]")
                print(f"       objectnessèŒƒå›´: [{objectness.min():.3f}, {objectness.max():.3f}]")
                print(f"       ç±»åˆ«åˆ†æ•°èŒƒå›´: [{classes.min():.6f}, {classes.max():.6f}]")
                
                # æ£€æŸ¥æœŸæœ›ç±»åˆ«çš„åˆ†æ•°å˜åŒ–
                expected_classes = [3, 11, 14]  # boat, dog, person
                print(f"     æœŸæœ›ç±»åˆ«åˆ†æ•°å˜åŒ–:")
                for cls_id in expected_classes:
                    cls_scores = classes[0, :, cls_id]
                    max_score = float(cls_scores.max())
                    mean_score = float(cls_scores.mean())
                    nonzero_count = int((cls_scores > 0.001).sum())
                    print(f"       {VOC_CLASSES[cls_id]}(ç±»åˆ«{cls_id}): æœ€å¤§{max_score:.6f}, å¹³å‡{mean_score:.6f}, éé›¶{nonzero_count}")
                
                # æ£€æŸ¥aeroplaneçš„åˆ†æ•°
                aero_scores = classes[0, :, 0]
                aero_max_score = float(aero_scores.max())
                aero_mean_score = float(aero_scores.mean())
                aero_nonzero_count = int((aero_scores > 0.001).sum())
                print(f"       aeroplane(ç±»åˆ«0): æœ€å¤§{aero_max_score:.6f}, å¹³å‡{aero_mean_score:.6f}, éé›¶{aero_nonzero_count}")
                
                # æ£€æŸ¥æ‰€æœ‰ç±»åˆ«çš„åˆ†æ•°åˆ†å¸ƒ
                print(f"     æ‰€æœ‰ç±»åˆ«åˆ†æ•°ç»Ÿè®¡:")
                for cls_id in range(20):
                    cls_scores = classes[0, :, cls_id]
                    max_score = float(cls_scores.max())
                    if max_score > 0.01:  # åªæ˜¾ç¤ºæœ‰æ„ä¹‰çš„åˆ†æ•°
                        mean_score = float(cls_scores.mean())
                        nonzero_count = int((cls_scores > 0.001).sum())
                        cls_name = VOC_CLASSES[cls_id]
                        print(f"       {cls_name}(ç±»åˆ«{cls_id}): æœ€å¤§{max_score:.6f}, å¹³å‡{mean_score:.6f}, éé›¶{nonzero_count}")
                
                # **å…³é”®æ£€æŸ¥ï¼šåˆ†ç±»å¤´çš„æƒé‡å’Œæ¢¯åº¦**
                print(f"     åˆ†ç±»å¤´æƒé‡å’Œæ¢¯åº¦åˆ†æ:")
                for name, param in model.named_parameters():
                    if 'cls_preds' in name and param.requires_grad:
                        if param.grad is not None:
                            grad_norm = float(param.grad.norm())
                            weight_norm = float(param.norm())
                            print(f"       {name}: æƒé‡èŒƒæ•°{weight_norm:.6f}, æ¢¯åº¦èŒƒæ•°{grad_norm:.6f}")
                        else:
                            weight_norm = float(param.norm())
                            print(f"       {name}: æƒé‡èŒƒæ•°{weight_norm:.6f}, æ¢¯åº¦ä¸ºNone")
                
                # **å…³é”®æ£€æŸ¥ï¼šæŸå¤±å‡½æ•°çš„åˆ†ç±»æŸå¤±**
                if hasattr(loss_items, '__len__') and len(loss_items) >= 3:
                    cls_loss = float(loss_items[0]) if len(loss_items) > 0 else 0.0
                    iou_loss = float(loss_items[1]) if len(loss_items) > 1 else 0.0
                    dfl_loss = float(loss_items[2]) if len(loss_items) > 2 else 0.0
                    print(f"     æŸå¤±åˆ†è§£: åˆ†ç±»{cls_loss:.6f}, IoU{iou_loss:.6f}, DFL{dfl_loss:.6f}")
                    
                    if cls_loss < 0.001:
                        print(f"     âš ï¸ åˆ†ç±»æŸå¤±è¿‡å°ï¼Œå¯èƒ½å­¦ä¹ ç‡è¿‡ä½æˆ–æŸå¤±è®¡ç®—æœ‰é—®é¢˜")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å­¦ä¹ è¿›å±•
                if epoch == 10:
                    # ä¿å­˜ç¬¬10è½®çš„åˆ†æ•°ä½œä¸ºåŸºå‡†
                    baseline_scores = {}
                    for cls_id in expected_classes:
                        cls_scores = classes[0, :, cls_id]
                        baseline_scores[cls_id] = float(cls_scores.max())
                elif epoch == 40:
                    # æ£€æŸ¥ç¬¬40è½®ç›¸æ¯”ç¬¬10è½®çš„è¿›å±•
                    print(f"     å­¦ä¹ è¿›å±•åˆ†æ (Epoch 10 vs 40):")
                    for cls_id in expected_classes:
                        cls_scores = classes[0, :, cls_id]
                        current_score = float(cls_scores.max())
                        if cls_id in baseline_scores:
                            improvement = current_score - baseline_scores[cls_id]
                            cls_name = VOC_CLASSES[cls_id]
                            print(f"       {cls_name}(ç±»åˆ«{cls_id}): {baseline_scores[cls_id]:.6f} -> {current_score:.6f} (æ”¹è¿›{improvement:+.6f})")
                            
                            if improvement < 0.001:
                                print(f"       âŒ {cls_name}æ²¡æœ‰å­¦ä¹ è¿›å±•ï¼")
                            else:
                                print(f"       âœ… {cls_name}æœ‰å­¦ä¹ è¿›å±•")
            
            model.train()
    
    print(f"\nğŸ“Š æœ€ç»ˆåˆ†æç»“æœ:")
    print(f"å¦‚æœæœŸæœ›ç±»åˆ«åˆ†æ•°ä»ç„¶ä¸º0ï¼Œè¯´æ˜åˆ†ç±»å­¦ä¹ å®Œå…¨å¤±è´¥")
    print(f"å¯èƒ½çš„åŸå› ï¼š")
    print(f"1. æ ‡ç­¾åˆ†é…é—®é¢˜ - TaskAlignedAssigneræ²¡æœ‰æ­£ç¡®åˆ†é…æ­£æ ·æœ¬")
    print(f"2. æŸå¤±å‡½æ•°é—®é¢˜ - VarifocalLossè®¡ç®—é”™è¯¯")
    print(f"3. åˆ†ç±»å¤´åˆå§‹åŒ–é—®é¢˜ - æƒé‡åˆå§‹åŒ–ä¸å½“")
    print(f"4. å­¦ä¹ ç‡é—®é¢˜ - å­¦ä¹ ç‡è¿‡ä½æˆ–è¿‡é«˜")
    print(f"5. æ¢¯åº¦ä¼ æ’­é—®é¢˜ - åˆ†ç±»å¤´æ²¡æœ‰æ¥æ”¶åˆ°æ¢¯åº¦")
    
    return False

def main():
    print("ğŸ”¥ è°ƒè¯•åˆ†ç±»å­¦ä¹ å¤±è´¥é—®é¢˜")
    print("=" * 70)
    print("ç›®æ ‡ï¼šæ‰¾å‡ºä¸ºä»€ä¹ˆæœŸæœ›ç±»åˆ«åˆ†æ•°å…¨ä¸º0")
    print("=" * 70)
    
    debug_classification_failure()

if __name__ == "__main__":
    main()
