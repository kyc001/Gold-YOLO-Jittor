#!/usr/bin/env python3
# -*- coding:utf-8 -*-
"""
GOLD-YOLO Jittorç‰ˆæœ¬æŽ¨ç†å™¨
å®Œå…¨å¯¹é½PyTorchç‰ˆæœ¬çš„æŽ¨ç†é€»è¾‘
"""

import os
import cv2
import time
import math
import numpy as np
import os.path as osp
from tqdm import tqdm
from pathlib import Path
from collections import deque

import jittor as jt
from jittor import nn

from yolov6.models.yolo import Model
from yolov6.data.data_augment import letterbox
from yolov6.utils.nms import non_max_suppression
from yolov6.utils.general import check_img_size, scale_coords
from yolov6.utils.events import load_yaml


class DetectBackendJittor:
    """Jittorç‰ˆæœ¬çš„æ£€æµ‹åŽç«¯ï¼Œå¯¹é½PyTorchç‰ˆæœ¬çš„DetectBackend"""
    
    def __init__(self, weights='yolov6s.pkl', device='cpu'):
        """åˆå§‹åŒ–æ£€æµ‹åŽç«¯"""
        self.weights = weights
        self.device = device
        
        # åŠ è½½æ¨¡åž‹
        self.model, self.stride = self._load_model(weights)
        
    def _load_model(self, weights):
        """åŠ è½½Jittoræ¨¡åž‹ï¼Œä½¿ç”¨ä¸Žè®­ç»ƒæ—¶ç›¸åŒçš„æ¨¡åž‹åˆ›å»ºæ–¹æ³•"""
        print(f"ðŸ“¦ åŠ è½½Jittoræ¨¡åž‹: {weights}")

        # ä½¿ç”¨ä¸Žè®­ç»ƒæ—¶ç›¸åŒçš„æ¨¡åž‹åˆ›å»ºæ–¹æ³•
        from models.perfect_gold_yolo import create_perfect_gold_yolo_model
        model = create_perfect_gold_yolo_model('gold_yolo-n', num_classes=20)
        
        # åŠ è½½æƒé‡
        if os.path.exists(weights):
            checkpoint = jt.load(weights)
            if isinstance(checkpoint, dict):
                if 'model_state_dict' in checkpoint:
                    model.load_state_dict(checkpoint['model_state_dict'])
                    print(f"âœ… æˆåŠŸåŠ è½½æƒé‡ (epoch: {checkpoint.get('epoch', 'unknown')})")
                elif 'model' in checkpoint:
                    model.load_state_dict(checkpoint['model'])
                    print(f"âœ… æˆåŠŸåŠ è½½æƒé‡ (epoch: {checkpoint.get('epoch', 'unknown')})")
                else:
                    model.load_state_dict(checkpoint)
                    print(f"âœ… æˆåŠŸåŠ è½½æƒé‡")
            else:
                model.load_state_dict(checkpoint)
                print(f"âœ… æˆåŠŸåŠ è½½æƒé‡")
        else:
            raise FileNotFoundError(f"æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {weights}")
        
        model.eval()
        
        # èŽ·å–strideä¿¡æ¯
        stride = 32  # GOLD-YOLOé»˜è®¤stride
        
        return model, stride
    
    def __call__(self, img):
        """å‰å‘æŽ¨ç†"""
        return self.model(img)


class InfererJittor:
    """Jittorç‰ˆæœ¬æŽ¨ç†å™¨ï¼Œå®Œå…¨å¯¹é½PyTorchç‰ˆæœ¬"""
    
    def __init__(self, source, weights, device, yaml, img_size, half=False):
        """åˆå§‹åŒ–æŽ¨ç†å™¨"""
        self.__dict__.update(locals())
        
        # åˆå§‹åŒ–æ¨¡åž‹
        self.device = device
        self.img_size = img_size
        self.model = DetectBackendJittor(weights, device=device)
        self.stride = self.model.stride
        self.class_names = load_yaml(yaml)['names']
        self.img_size = check_img_size(self.img_size, s=self.stride)  # æ£€æŸ¥å›¾åƒå°ºå¯¸
        self.half = half
        
        # æ¨¡åž‹åˆ‡æ¢åˆ°éƒ¨ç½²çŠ¶æ€ï¼ˆJittorç‰ˆæœ¬æš‚æ—¶è·³è¿‡ï¼‰
        # self.model.model = self.model_switch(self.model.model, self.img_size)
        
        # åŠç²¾åº¦ï¼ˆJittorç‰ˆæœ¬æš‚æ—¶è·³è¿‡ï¼‰
        if self.half:
            print("WARNING: Jittorç‰ˆæœ¬æš‚ä¸æ”¯æŒåŠç²¾åº¦æŽ¨ç†ï¼Œä½¿ç”¨å…¨ç²¾åº¦")
            self.half = False
        
        # é¢„çƒ­
        self.warmup()
        
    def warmup(self):
        """æ¨¡åž‹é¢„çƒ­"""
        print("ðŸ”¥ æ¨¡åž‹é¢„çƒ­ä¸­...")
        img_size = self.img_size
        if isinstance(img_size, list):
            img_size = max(img_size)
        
        # åˆ›å»ºè™šæ‹Ÿè¾“å…¥è¿›è¡Œé¢„çƒ­
        dummy_input = jt.zeros((1, 3, img_size, img_size))
        for _ in range(2):
            with jt.no_grad():
                _ = self.model(dummy_input)
        print("âœ… æ¨¡åž‹é¢„çƒ­å®Œæˆ")
    
    def model_switch(self, model, img_size):
        """æ¨¡åž‹åˆ‡æ¢åˆ°éƒ¨ç½²çŠ¶æ€ï¼ˆå¯¹é½PyTorchç‰ˆæœ¬ï¼‰"""
        # Jittorç‰ˆæœ¬æš‚æ—¶è¿”å›žåŽŸæ¨¡åž‹
        return model
    
    def preprocess(self, img_src):
        """å›¾åƒé¢„å¤„ç†ï¼Œå®Œå…¨å¯¹é½PyTorchç‰ˆæœ¬"""
        img_size = self.img_size
        if isinstance(img_size, list):
            img_size = max(img_size)
        
        # Letterbox resize
        img = letterbox(img_src, new_shape=img_size, stride=self.stride, auto=False)[0]
        
        # è½¬æ¢é¢œè‰²ç©ºé—´å’Œæ•°æ®ç±»åž‹
        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, HWC to CHW
        img = np.ascontiguousarray(img)
        img = img.astype(np.float32) / 255.0  # å½’ä¸€åŒ–åˆ°[0,1]
        
        # è½¬æ¢ä¸ºJittorå¼ é‡
        img = jt.array(img)
        if img.ndim == 3:
            img = img.unsqueeze(0)  # æ·»åŠ batchç»´åº¦
        
        return img
    
    def postprocess(self, pred, img_src, img_processed):
        """åŽå¤„ç†ï¼Œå®Œå…¨å¯¹é½PyTorchç‰ˆæœ¬"""
        # NMS
        pred = non_max_suppression(
            pred, 
            conf_thres=0.25, 
            iou_thres=0.45, 
            max_det=1000
        )
        
        detections = []
        for i, det in enumerate(pred):
            if len(det):
                # åæ ‡ç¼©æ”¾å›žåŽŸå›¾å°ºå¯¸
                det[:, :4] = scale_coords(img_processed.shape[2:], det[:, :4], img_src.shape).round()
                detections.append(det)
            else:
                detections.append(jt.empty((0, 6)))
        
        return detections
    
    def infer(self, img_src, conf_thres=0.25, iou_thres=0.45, max_det=1000):
        """å•å¼ å›¾åƒæŽ¨ç†"""
        # é¢„å¤„ç†
        img = self.preprocess(img_src)
        
        # æŽ¨ç†
        with jt.no_grad():
            pred = self.model(img)
        
        # åŽå¤„ç†
        pred = non_max_suppression(pred, conf_thres, iou_thres, max_det=max_det)
        
        detections = []
        for i, det in enumerate(pred):
            if len(det):
                # åæ ‡ç¼©æ”¾å›žåŽŸå›¾å°ºå¯¸
                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img_src.shape).round()
                detections.append(det)
            else:
                detections.append(jt.empty((0, 6)))
        
        return detections
    
    def draw_detections(self, img, detections, conf_thres=0.25):
        """ç»˜åˆ¶æ£€æµ‹ç»“æžœï¼Œå¯¹é½PyTorchç‰ˆæœ¬"""
        colors = np.random.randint(0, 255, size=(len(self.class_names), 3), dtype=np.uint8)
        
        for det in detections:
            if len(det):
                # è½¬æ¢ä¸ºnumpy
                if hasattr(det, 'numpy'):
                    det = det.numpy()
                
                for *xyxy, conf, cls in det:
                    if conf >= conf_thres:
                        # ç»˜åˆ¶è¾¹ç•Œæ¡†
                        x1, y1, x2, y2 = map(int, xyxy)
                        cls_id = int(cls)
                        color = colors[cls_id].tolist()
                        
                        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)
                        
                        # ç»˜åˆ¶æ ‡ç­¾
                        label = f'{self.class_names[cls_id]} {conf:.2f}'
                        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
                        cv2.rectangle(img, (x1, y1 - label_size[1] - 10), 
                                    (x1 + label_size[0], y1), color, -1)
                        cv2.putText(img, label, (x1, y1 - 5), 
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        
        return img
