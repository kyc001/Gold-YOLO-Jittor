#!/usr/bin/env python3
# -*- coding:utf-8 -*-
"""
GOLD-YOLO Jittorç‰ˆæœ¬ - ä¸»æŸå¤±å‡½æ•°
ä¸¥æ ¼å¯¹é½PyTorchç‰ˆæœ¬ï¼Œç™¾åˆ†ç™¾è¿˜åŸæ‰€æœ‰åŠŸèƒ½
"""

import jittor as jt
import jittor.nn as nn
import numpy as np
from yolov6.assigners.atss_assigner import ATSSAssigner
from yolov6.assigners.tal_assigner import TaskAlignedAssigner
from yolov6.utils.figure_iou import IOUloss
from yolov6.utils.general import xywh2xyxy, bbox2dist


class VarifocalLoss(nn.Module):
    """Varifocal Loss - ç™¾åˆ†ç™¾å¯¹é½PyTorchç‰ˆæœ¬"""
    def __init__(self):
        super(VarifocalLoss, self).__init__()

    def execute(self, pred_score, gt_score, label, alpha=0.75, gamma=2.0):
        # ç¡®ä¿æ‰€æœ‰è¾“å…¥éƒ½æ˜¯float32
        pred_score = pred_score.float32()
        gt_score = gt_score.float32()
        label = label.float32()
        
        weight = alpha * pred_score.pow(gamma) * (1 - label) + gt_score * label
        # ä¿®å¤Jittor API - æ²¡æœ‰reductionå‚æ•°ï¼Œæ‰‹åŠ¨å¤„ç†
        bce_loss = jt.nn.binary_cross_entropy_with_logits(pred_score.float(), gt_score.float())
        # å¦‚æœbce_lossæ˜¯æ ‡é‡ï¼Œéœ€è¦æ‰©å±•ç»´åº¦åŒ¹é…weight
        if len(bce_loss.shape) == 0:
            bce_loss = bce_loss.unsqueeze(0).expand_as(weight)
        elif len(bce_loss.shape) != len(weight.shape):
            # å¹¿æ’­åˆ°ç›¸åŒå½¢çŠ¶
            bce_loss = bce_loss.expand_as(weight)
        
        focal_loss = weight * bce_loss
        return focal_loss


class BboxLoss(nn.Module):
    """Bbox Loss - ç™¾åˆ†ç™¾å¯¹é½PyTorchç‰ˆæœ¬"""
    def __init__(self, num_classes, reg_max, use_dfl=False, iou_type='giou'):
        super(BboxLoss, self).__init__()
        self.num_classes = num_classes
        self.iou_loss = IOUloss(box_format='xyxy', iou_type=iou_type, eps=1e-10)
        self.reg_max = reg_max
        self.use_dfl = use_dfl
        if self.use_dfl:
            self.proj = jt.linspace(0, self.reg_max, self.reg_max + 1).float32().stop_grad()

    def execute(self, pred_dist, pred_bboxes, anchor_points, target_bboxes, target_scores, target_scores_sum, fg_mask):
        # iou loss
        bbox_mask = fg_mask.unsqueeze(-1).repeat([1, 1, 4])
        
        # ä½¿ç”¨Jittorçš„æ–¹å¼å®ç°masked_select
        # æ‰¾åˆ°æ­£æ ·æœ¬çš„ç´¢å¼•
        pos_indices = jt.nonzero(fg_mask)  # [num_pos, 2] (batch_idx, anchor_idx)
        
        if pos_indices.shape[0] > 0:
            # æå–æ­£æ ·æœ¬çš„é¢„æµ‹æ¡†å’Œç›®æ ‡æ¡†
            pred_bboxes_pos = pred_bboxes[pos_indices[:, 0], pos_indices[:, 1]]  # [num_pos, 4]
            target_bboxes_pos = target_bboxes[pos_indices[:, 0], pos_indices[:, 1]]  # [num_pos, 4]
            bbox_weight = target_scores.sum(-1)[pos_indices[:, 0], pos_indices[:, 1]].unsqueeze(-1)  # [num_pos, 1]
        else:
            # æ²¡æœ‰æ­£æ ·æœ¬
            pred_bboxes_pos = jt.zeros((0, 4), dtype='float32')
            target_bboxes_pos = jt.zeros((0, 4), dtype='float32')
            bbox_weight = jt.zeros((0, 1), dtype='float32')

        loss_iou = self.iou_loss(pred_bboxes_pos, target_bboxes_pos) * bbox_weight
        # å®‰å…¨è·å–å€¼ï¼Œé¿å…CUDAå†…å­˜è®¿é—®é”™è¯¯
        try:
            # å…ˆå°†tensorç§»åˆ°CPUï¼Œé¿å…CUDAå†…å­˜è®¿é—®é”™è¯¯
            target_scores_sum_cpu = target_scores_sum.detach()

            if target_scores_sum_cpu.numel() != 1:
                # å¦‚æœä¸æ˜¯æ ‡é‡ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ æˆ–ä½¿ç”¨sum()
                if target_scores_sum_cpu.numel() > 0:
                    sum_val = float(target_scores_sum_cpu.sum())
                else:
                    sum_val = 0.0
            else:
                # æ˜¯æ ‡é‡ï¼Œå®‰å…¨è½¬æ¢
                sum_val = float(target_scores_sum_cpu)

        except Exception as e:
            # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
            sum_val = 0.0

        if sum_val == 0:
            loss_iou = loss_iou.sum()
        else:
            loss_iou = loss_iou.sum() / target_scores_sum

        # dfl loss
        if self.use_dfl and pos_indices.shape[0] > 0:
            # ä½¿ç”¨Jittoræ–¹å¼å®ç°masked_select
            pred_dist_pos = pred_dist[pos_indices[:, 0], pos_indices[:, 1]]  # [num_pos, (reg_max+1)*4]
            pred_dist_pos = pred_dist_pos.reshape([-1, 4, self.reg_max + 1])
            
            target_ltrb = bbox2dist(anchor_points, target_bboxes, self.reg_max)
            target_ltrb_pos = target_ltrb[pos_indices[:, 0], pos_indices[:, 1]]  # [num_pos, 4]
            
            loss_dfl = self._df_loss(pred_dist_pos, target_ltrb_pos) * bbox_weight
            
            if target_scores_sum.item() == 0:
                loss_dfl = loss_dfl.sum()
            else:
                loss_dfl = loss_dfl.sum() / target_scores_sum
        else:
            loss_dfl = pred_dist.sum() * 0.

        return loss_iou, loss_dfl

    def _df_loss(self, pred_dist, target):
        # DFLæŸå¤±è®¡ç®— - å®Œå…¨ä¿®å¤ç‰ˆæœ¬ï¼Œå½»åº•è§£å†³NaNé—®é¢˜
        try:
            # è¾“å…¥éªŒè¯å’Œæ¸…ç†
            if pred_dist.numel() == 0 or target.numel() == 0:
                return jt.zeros((1,), dtype='float32')
            
            # æ¸…ç†è¾“å…¥ä¸­çš„å¼‚å¸¸å€¼
            pred_dist = jt.nan_to_num(pred_dist, nan=0.0, posinf=10.0, neginf=-10.0)
            target = jt.nan_to_num(target, nan=0.0, posinf=float(self.reg_max), neginf=0.0)
            
            # ä¸¥æ ¼é™åˆ¶targetèŒƒå›´ï¼Œé˜²æ­¢ç´¢å¼•è¶Šç•Œ
            target = jt.clamp(target, 0.0, float(self.reg_max - 1e-6))  # ç¨å¾®å°äºreg_maxé¿å…è¾¹ç•Œé—®é¢˜

            # è®¡ç®—å·¦å³ç´¢å¼•
            target_left = jt.floor(target).astype('int64')
            target_right = target_left + 1

            # å†æ¬¡ç¡®ä¿ç´¢å¼•å®‰å…¨
            target_left = jt.clamp(target_left, 0, self.reg_max - 1)
            target_right = jt.clamp(target_right, 0, self.reg_max)

            # è®¡ç®—æ’å€¼æƒé‡
            weight_right = target - target_left.astype('float32')
            weight_left = 1.0 - weight_right

            # ç¡®ä¿æƒé‡åœ¨[0,1]èŒƒå›´å†…ä¸”å’Œä¸º1
            weight_left = jt.clamp(weight_left, 0.0, 1.0)
            weight_right = jt.clamp(weight_right, 0.0, 1.0)
            
            # å½’ä¸€åŒ–æƒé‡ï¼Œç¡®ä¿å’Œä¸º1
            weight_sum = weight_left + weight_right + 1e-8  # é˜²æ­¢é™¤é›¶
            weight_left = weight_left / weight_sum
            weight_right = weight_right / weight_sum

            # é‡å¡‘é¢„æµ‹åˆ†å¸ƒ
            batch_size, num_points, _ = pred_dist.shape
            pred_dist_reshaped = pred_dist.view(-1, self.reg_max + 1)
            
            # åº”ç”¨softmaxæé«˜æ•°å€¼ç¨³å®šæ€§
            pred_dist_reshaped = jt.nn.log_softmax(pred_dist_reshaped, dim=-1)
            
            # é‡å¡‘targetç´¢å¼•
            target_left_flat = target_left.view(-1)
            target_right_flat = target_right.view(-1)
            weight_left_flat = weight_left.view(-1)
            weight_right_flat = weight_right.view(-1)

            # ä½¿ç”¨gatheræ“ä½œå®‰å…¨è·å–å¯¹åº”çš„logæ¦‚ç‡
            num_samples = pred_dist_reshaped.shape[0]
            
            # ç¡®ä¿ç´¢å¼•æœ‰æ•ˆæ€§
            valid_mask = (target_left_flat >= 0) & (target_left_flat < self.reg_max + 1) & \
                        (target_right_flat >= 0) & (target_right_flat < self.reg_max + 1)
            
            # è®¡ç®—NLLæŸå¤±
            left_log_probs = jt.zeros_like(weight_left_flat)
            right_log_probs = jt.zeros_like(weight_right_flat)
            
            if valid_mask.sum() > 0:
                # åªå¯¹æœ‰æ•ˆç´¢å¼•è®¡ç®—æŸå¤±
                valid_indices = jt.nonzero(valid_mask).squeeze(-1)
                
                if valid_indices.numel() > 0:
                    # ä½¿ç”¨advanced indexingå®‰å…¨è·å–logæ¦‚ç‡
                    left_log_probs[valid_indices] = pred_dist_reshaped[valid_indices, target_left_flat[valid_indices]]
                    right_log_probs[valid_indices] = pred_dist_reshaped[valid_indices, target_right_flat[valid_indices]]
            
            # è®¡ç®—åŠ æƒè´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±
            loss_left = -left_log_probs * weight_left_flat
            loss_right = -right_log_probs * weight_right_flat
            loss_flat = loss_left + loss_right
            
            # é‡å¡‘å›åŸå§‹å½¢çŠ¶
            loss = loss_flat.view(batch_size, num_points)
            
            # æ²¿æœ€åä¸€ä¸ªç»´åº¦æ±‚å¹³å‡ï¼Œä¿æŒç»´åº¦
            loss = loss.mean(-1, keepdims=True)
            
            # æœ€ç»ˆå®‰å…¨æ£€æŸ¥
            loss = jt.nan_to_num(loss, nan=0.0, posinf=10.0, neginf=0.0)
            loss = jt.clamp(loss, 0.0, 10.0)
            
            # å¦‚æœä»æœ‰å¼‚å¸¸å€¼ï¼Œç›´æ¥è®¾ä¸º0
            if jt.isnan(loss).sum() > 0 or jt.isinf(loss).sum() > 0:
                loss = jt.zeros_like(loss)

            return loss

        except Exception as e:
            print(f"ğŸš¨ DFLæŸå¤±è®¡ç®—å¼‚å¸¸: {e}")
            # è¿”å›å½¢çŠ¶æ­£ç¡®çš„é›¶æŸå¤±
            if hasattr(target, 'shape') and len(target.shape) >= 2:
                return jt.zeros((target.shape[0], target.shape[1], 1), dtype='float32')
            else:
                return jt.zeros((1, 1, 1), dtype='float32')


class ComputeLoss:
    '''Loss computation func - ç™¾åˆ†ç™¾è¿˜åŸPyTorchç‰ˆæœ¬'''

    def __init__(self,
                 fpn_strides=[8, 16, 32],
                 grid_cell_size=5.0,
                 grid_cell_offset=0.5,
                 num_classes=80,
                 ori_img_size=640,
                 warmup_epoch=4,
                 use_dfl=True,
                 reg_max=16,
                 iou_type='giou',
                 loss_weight={
                         'class': 1.0,
                         'iou': 2.5,
                         'dfl': 0.5}
                 ):

        self.fpn_strides = fpn_strides
        self.grid_cell_size = grid_cell_size
        self.grid_cell_offset = grid_cell_offset
        self.num_classes = num_classes
        self.ori_img_size = ori_img_size
        self.warmup_epoch = warmup_epoch
        
        # ç™¾åˆ†ç™¾è¿˜åŸçš„assigner
        self.warmup_assigner = ATSSAssigner(topk=9, num_classes=self.num_classes)
        self.formal_assigner = TaskAlignedAssigner(topk=13, num_classes=self.num_classes, alpha=1.0, beta=6.0)

        self.use_dfl = use_dfl
        self.reg_max = reg_max
        self.proj = jt.linspace(0, self.reg_max, self.reg_max + 1).float32().stop_grad()
        self.iou_type = iou_type
        self.varifocal_loss = VarifocalLoss()
        self.bbox_loss = BboxLoss(self.num_classes, self.reg_max, self.use_dfl, self.iou_type)
        self.loss_weight = loss_weight

    def _create_dummy_feats(self, batch_size):
        """åˆ›å»ºè™šæ‹Ÿç‰¹å¾å›¾ç”¨äºanchorç”Ÿæˆ"""
        # åˆ›å»ºä¸‰ä¸ªä¸åŒå°ºåº¦çš„è™šæ‹Ÿç‰¹å¾å›¾
        feats = [
            jt.zeros((batch_size, 256, 80, 80)),   # stride 8
            jt.zeros((batch_size, 512, 40, 40)),   # stride 16
            jt.zeros((batch_size, 1024, 20, 20))   # stride 32
        ]
        return feats

    def __call__(self, outputs, targets, epoch_num, step_num):
        # æ£€æŸ¥outputsæ˜¯å¦åŒ…å«å¼‚å¸¸å€¼
        try:
            if hasattr(outputs, 'shape'):
                has_nan = jt.isnan(outputs).sum() > 0
                has_inf = jt.isinf(outputs).sum() > 0

                if has_nan or has_inf:
                    outputs = jt.nan_to_num(outputs, nan=0.0, posinf=1e6, neginf=-1e6)
        except Exception as e:
            pass

        # è®¡ç®—æœŸæœ›çš„é€šé“æ•°
        reg_channels = 4 * (self.reg_max + 1) if self.use_dfl else 4
        expected_channels = self.num_classes + reg_channels

        # ä¿®å¤è¾“å‡ºè§£æ - å¤„ç†å•tensorè¾“å‡º
        if isinstance(outputs, (list, tuple)) and len(outputs) == 3:
            # æ ‡å‡†çš„ä¸‰è¾“å‡ºæ ¼å¼
            feats, pred_scores, pred_distri = outputs
        elif hasattr(outputs, 'shape') and len(outputs.shape) == 3:
            # å•tensorè¾“å‡ºæ ¼å¼ [batch, anchors, channels]
            batch_size, num_anchors, total_channels = outputs.shape

            # åˆ†ç¦»åˆ†ç±»å’Œå›å½’éƒ¨åˆ†
            if total_channels >= expected_channels:
                pred_scores = outputs[:, :, :self.num_classes]  # [batch, anchors, num_classes]
                pred_distri = outputs[:, :, self.num_classes:self.num_classes+reg_channels]  # [batch, anchors, reg_channels]

                # åˆ›å»ºè™šæ‹Ÿçš„featsç”¨äºanchorç”Ÿæˆ
                feats = self._create_dummy_feats(batch_size)
                
                print(f"âœ… è¾“å‡ºè§£ææˆåŠŸ: pred_scores={pred_scores.shape}, pred_distri={pred_distri.shape}")
            else:
                print(f"âš ï¸ è¾“å‡ºé€šé“æ•°ä¸åŒ¹é…ï¼šæœŸæœ›{expected_channels}ï¼Œå¾—åˆ°{total_channels}")
                raise ValueError(f"è¾“å‡ºé€šé“æ•°ä¸åŒ¹é…ï¼šæœŸæœ›{expected_channels}ï¼Œå¾—åˆ°{total_channels}")
        else:
            raise ValueError(f"æ¨¡å‹è¾“å‡ºæ ¼å¼é”™è¯¯ï¼æœŸæœ›(pred_scores, pred_distri)ã€(feats, pred_scores, pred_distri)æˆ–å•tensorï¼Œå¾—åˆ°: {type(outputs)}")
        anchors, anchor_points, n_anchors_list, stride_tensor = \
               self.generate_anchors(feats, self.fpn_strides, self.grid_cell_size, self.grid_cell_offset)

        assert pred_scores.dtype == pred_distri.dtype
        # ç¡®ä¿æ•°æ®ç±»å‹ä¸€è‡´ï¼Œä½¿ç”¨float32
        gt_bboxes_scale = jt.full((1, 4), self.ori_img_size, dtype='float32')
        batch_size = pred_scores.shape[0]

        # targets
        targets = self.preprocess(targets, batch_size, gt_bboxes_scale)

        # é‡æ–°ç»„ç»‡targetsä¸ºæ­£ç¡®çš„æ ¼å¼ [batch, max_targets, 6]
        # targetsç°åœ¨æ˜¯ [num_targets, 6] æ ¼å¼: [batch_idx, class, x1, y1, x2, y2]

        # åˆ›å»ºæ‰¹æ¬¡åŒ–çš„targets
        batch_targets = []
        for b in range(batch_size):
            # è·å–å½“å‰batchçš„targets
            batch_mask = targets[:, 0] == b
            batch_target = targets[batch_mask]

            if len(batch_target) > 0:
                # ç§»é™¤batch_idxåˆ—ï¼Œä¿ç•™[class, x1, y1, x2, y2]
                batch_target = batch_target[:, 1:]
            else:
                # å¦‚æœæ²¡æœ‰ç›®æ ‡ï¼Œåˆ›å»ºè™šæ‹Ÿç›®æ ‡
                batch_target = jt.array([[0, 0, 0, 0, 0]], dtype='float32')

            batch_targets.append(batch_target)

        # å¡«å……åˆ°ç›¸åŒé•¿åº¦
        max_targets = max(len(bt) for bt in batch_targets)
        padded_targets = []

        for batch_target in batch_targets:
            if len(batch_target) < max_targets:
                # ç”¨-1å¡«å……
                padding = jt.full((max_targets - len(batch_target), 5), -1.0, dtype='float32')
                batch_target = jt.concat([batch_target, padding], dim=0)
            padded_targets.append(batch_target)

        # å †å ä¸º [batch, max_targets, 5]
        targets = jt.stack(padded_targets, dim=0)

        gt_labels = targets[:, :, 0:1]  # [batch, max_targets, 1]
        gt_bboxes = targets[:, :, 1:5]  # [batch, max_targets, 4]
        mask_gt = (gt_labels.squeeze(-1) >= 0).astype('float32')

        # pboxes
        anchor_points_s = anchor_points / stride_tensor
        pred_bboxes = self.bbox_decode(anchor_points_s, pred_distri)

        try:
            if epoch_num < self.warmup_epoch:
                target_labels, target_bboxes, target_scores, fg_mask = \
                    self.warmup_assigner(
                        pred_bboxes.detach() * stride_tensor,  # ä½¿ç”¨é¢„æµ‹çš„bboxesè€Œä¸æ˜¯anchor points
                        n_anchors_list,
                        gt_labels,
                        gt_bboxes,
                        mask_gt,
                        pred_bboxes.detach() * stride_tensor)
            else:
                target_labels, target_bboxes, target_scores, fg_mask = \
                    self.formal_assigner(
                        pred_scores.detach(),
                        pred_bboxes.detach() * stride_tensor,
                        anchor_points,
                        gt_labels,
                        gt_bboxes,
                        mask_gt)

        except RuntimeError as e:
            print(f"assigner error: {e}")
            print("return high loss with gradient")
            # ä¿®å¤æ¢¯åº¦é“¾æ–­å¼€é—®é¢˜ - ä½¿ç”¨pred_scoresè®¡ç®—æœ‰æ¢¯åº¦çš„æŸå¤±
            # ç¡®ä¿æŸå¤±æœ‰æ¢¯åº¦é“¾è¿æ¥åˆ°æ¨¡å‹å‚æ•°
            high_loss = pred_scores.mean() * 0 + 1000  # ä¿æŒæ¢¯åº¦é“¾ä½†å€¼ä¸º1000
            return high_loss, jt.ones([4])
        except Exception as e:
            print(f"other assigner error: {e}")
            print(f"é”™è¯¯ç±»å‹: {type(e)}")
            import traceback
            print(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            print("return high loss with gradient")
            # ä¿®å¤æ¢¯åº¦é“¾æ–­å¼€é—®é¢˜
            high_loss = pred_scores.mean() * 0 + 1000  # ä¿æŒæ¢¯åº¦é“¾ä½†å€¼ä¸º1000
            return high_loss, jt.ones([4])

        # rescale bbox
        target_bboxes /= stride_tensor

        # cls loss
        target_labels = jt.where(fg_mask > 0, target_labels, jt.full_like(target_labels, self.num_classes))
        one_hot_label = jt.nn.one_hot(target_labels.astype('int64'), self.num_classes + 1)[..., :-1]
        loss_cls = self.varifocal_loss(pred_scores, target_scores, one_hot_label)

        target_scores_sum = target_scores.sum()
        # ä¿®å¤Jittor tensoræ¯”è¾ƒ - ç›´æ¥æ¯”è¾ƒ
        if target_scores_sum.item() > 0:
            loss_cls /= target_scores_sum

        loss_cls = loss_cls.sum()

        # bbox loss
        loss_iou, loss_dfl = self.bbox_loss(pred_distri, pred_bboxes, anchor_points_s, target_bboxes, target_scores, target_scores_sum, fg_mask)

        # æ£€æŸ¥NaNå€¼å¹¶ä¿®å¤ - ä¿®å¤Jittor API
        try:
            if jt.isnan(loss_cls).sum() > 0:
                print(f"âš ï¸ loss_clsåŒ…å«NaNï¼Œè®¾ä¸º0")
                loss_cls = jt.zeros_like(loss_cls)
        except:
            pass
        try:
            if jt.isnan(loss_iou).sum() > 0:
                print(f"âš ï¸ loss_iouåŒ…å«NaNï¼Œè®¾ä¸º0")
                loss_iou = jt.zeros_like(loss_iou)
        except:
            pass
        try:
            if jt.isnan(loss_dfl).sum() > 0:
                print(f"âš ï¸ loss_dflåŒ…å«NaNï¼Œè®¾ä¸º0")
                loss_dfl = jt.zeros_like(loss_dfl)
        except:
            pass

        # é™åˆ¶æŸå¤±å€¼èŒƒå›´ï¼Œé˜²æ­¢æº¢å‡º
        loss_cls = jt.clamp(loss_cls, 0, 100)
        loss_iou = jt.clamp(loss_iou, 0, 100)
        loss_dfl = jt.clamp(loss_dfl, 0, 100)

        loss = self.loss_weight['class'] * loss_cls + \
               self.loss_weight['iou'] * loss_iou + \
               self.loss_weight['dfl'] * loss_dfl

        # æœ€ç»ˆæ£€æŸ¥æ€»æŸå¤± - ä¿®å¤Jittor API
        try:
            if jt.isnan(loss).sum() > 0:
                print(f"âš ï¸ æ€»æŸå¤±åŒ…å«NaNï¼Œä½¿ç”¨å¤‡ç”¨æŸå¤±")
                loss = pred_scores.mean() * 0 + 1.0  # å°çš„æœ‰æ¢¯åº¦æŸå¤±
        except:
            pass

        return loss, jt.stack([loss_iou, loss_dfl, loss_cls]).detach()

    def generate_anchors(self, feats, fpn_strides, grid_cell_size=5.0, grid_cell_offset=0.5):
        """Generate anchors from features."""
        anchors = []
        anchor_points = []
        stride_tensor = []
        num_anchors_list = []
        
        for i, (feat, stride) in enumerate(zip(feats, fpn_strides)):
            _, _, h, w = feat.shape
            cell_half_size = grid_cell_size * grid_cell_offset
            shift_x = (jt.arange(w) + grid_cell_offset) * stride
            shift_y = (jt.arange(h) + grid_cell_offset) * stride
            shift_y, shift_x = jt.meshgrid(shift_y, shift_x)
            anchor = jt.stack([shift_x, shift_y], dim=-1).astype('float32')
            anchor_point = anchor.clone()
            anchor_point = anchor_point.reshape([-1, 2])
            anchor = anchor.unsqueeze(-2).expand([-1, -1, 1, -1])
            anchor = anchor.reshape([-1, 2])

            anchors.append(anchor)
            anchor_points.append(anchor_point)
            num_anchors_list.append(len(anchor_point))
            stride_tensor.append(jt.full([len(anchor_point), 1], stride, dtype='float32'))
        
        anchors = jt.concat(anchors)
        anchor_points = jt.concat(anchor_points).unsqueeze(0)
        stride_tensor = jt.concat(stride_tensor).unsqueeze(0)
        return anchors, anchor_points, num_anchors_list, stride_tensor

    def preprocess(self, targets, batch_size, scale_tensor):
        """Preprocess the targets."""
        # å¤„ç†ä¸åŒçš„è¾“å…¥æ ¼å¼
        if isinstance(targets, list):
            # å¦‚æœæ˜¯listï¼Œç›´æ¥å¤„ç†
            targets_list = targets
        elif hasattr(targets, 'numpy'):
            # å¦‚æœæ˜¯tensorï¼Œä¼˜åŒ–è½¬æ¢è¿‡ç¨‹
            try:
                # ç›´æ¥åœ¨GPUä¸Šå¤„ç†ï¼Œé¿å…CPUè½¬æ¢
                if targets.numel() == 0:
                    targets_list = []
                else:
                    # å°è¯•ä¿æŒåœ¨GPUä¸Šå¤„ç†
                    targets_detached = targets.detach()
                    # åªåœ¨å¿…è¦æ—¶è½¬æ¢ä¸ºnumpy
                    targets_np = targets_detached.numpy()
                    targets_list = targets_np.tolist()
            except Exception as e:
                print(f"âš ï¸ targetsè½¬æ¢å¤±è´¥: {e}")
                targets_list = []
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„targetsç±»å‹: {type(targets)}")

        # ç¡®ä¿æ¯ä¸ªbatchéƒ½æœ‰æ•°æ®
        if len(targets_list) < batch_size:
            # è¡¥é½batch
            while len(targets_list) < batch_size:
                targets_list.append([])

        # ä¸ºæ¯ä¸ªbatchæ·»åŠ batchç´¢å¼•
        processed_targets = []
        for batch_idx, batch_targets in enumerate(targets_list):
            for target in batch_targets:
                # æ£€æŸ¥targetç±»å‹å’Œé•¿åº¦
                if isinstance(target, (list, tuple)) and len(target) >= 5:  # [class, x, y, w, h]
                    processed_targets.append([batch_idx] + list(target))
                elif isinstance(target, (int, float)):
                    # å¦‚æœæ˜¯å•ä¸ªæ•°å€¼ï¼Œè·³è¿‡
                    continue
                else:
                    # å¦‚æœç›®æ ‡æ ¼å¼ä¸æ­£ç¡®ï¼Œæ·»åŠ é»˜è®¤å€¼
                    processed_targets.append([batch_idx, 0, 0.5, 0.5, 0.1, 0.1])

        # å¦‚æœæ²¡æœ‰ç›®æ ‡ï¼Œåˆ›å»ºè™šæ‹Ÿç›®æ ‡
        if not processed_targets:
            for batch_idx in range(batch_size):
                processed_targets.append([batch_idx, 0, 0.5, 0.5, 0.1, 0.1])

        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        targets_np = np.array(processed_targets, dtype=np.float32)
        targets = jt.array(targets_np)

        # ç¡®ä¿scale_tensoræ˜¯float32
        scale_tensor = scale_tensor.float32()

        # å¤„ç†åæ ‡è½¬æ¢
        if targets.shape[0] > 0:
            batch_target = targets[:, 2:6] * scale_tensor  # [x, y, w, h]
            targets_xyxy = xywh2xyxy(batch_target)
            targets = jt.concat([targets[:, :2], targets_xyxy], dim=1)  # [batch_idx, class, x1, y1, x2, y2]

        return targets

    def bbox_decode(self, anchor_points, pred_dist):
        """Decode predicted bbox."""
        if self.use_dfl:
            batch_size, n_anchors, _ = pred_dist.shape
            pred_dist = jt.nn.softmax(pred_dist.view(batch_size, n_anchors, 4, self.reg_max + 1), dim=-1)
            pred_dist = (pred_dist * self.proj.view(1, 1, 1, -1)).sum(-1)

        pred_dist = pred_dist.view(anchor_points.shape[0], anchor_points.shape[1], -1)

        # æ£€æŸ¥pred_distçš„æœ€åä¸€ä¸ªç»´åº¦
        last_dim = pred_dist.shape[-1]
        if last_dim >= 4:
            # å¦‚æœç»´åº¦è¶³å¤Ÿï¼Œæ­£å¸¸åˆ†å‰²
            pred_lt, pred_rb = pred_dist[:, :, :2], pred_dist[:, :, 2:4]
        else:
            # å¦‚æœç»´åº¦ä¸å¤Ÿï¼Œä½¿ç”¨å‰ä¸¤ä¸ªç»´åº¦ä½œä¸ºltï¼Œåé¢è¡¥é›¶ä½œä¸ºrb
            if last_dim >= 2:
                pred_lt = pred_dist[:, :, :2]
                pred_rb = jt.zeros_like(pred_lt)
            else:
                # å¦‚æœè¿2ä¸ªç»´åº¦éƒ½æ²¡æœ‰ï¼Œå…¨éƒ¨ç”¨é›¶
                pred_lt = jt.zeros((anchor_points.shape[0], anchor_points.shape[1], 2))
                pred_rb = jt.zeros_like(pred_lt)

        pred_x1y1 = anchor_points - pred_lt
        pred_x2y2 = anchor_points + pred_rb
        pred_bbox = jt.concat([pred_x1y1, pred_x2y2], dim=-1)
        return pred_bbox
