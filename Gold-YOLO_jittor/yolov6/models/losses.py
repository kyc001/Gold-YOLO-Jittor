#!/usr/bin/env python3
# -*- coding:utf-8 -*-
"""
GOLD-YOLO Jittorç‰ˆæœ¬ - ç™¾åˆ†ç™¾è¿˜åŸPyTorchæŸå¤±å‡½æ•°
å®Œå…¨å¯¹é½PyTorchç‰ˆæœ¬çš„ComputeLosså®ç°
"""

import jittor as jt
from jittor import nn
import numpy as np
from yolov6.assigners.anchor_generator import generate_anchors
from yolov6.utils.general import dist2bbox, bbox2dist, xywh2xyxy, box_iou
from yolov6.utils.figure_iou import IOUloss


class ComputeLoss:
    '''Loss computation func - ç™¾åˆ†ç™¾è¿˜åŸPyTorchç‰ˆæœ¬'''

    def __init__(self,
                 fpn_strides=[8, 16, 32],
                 grid_cell_size=5.0,
                 grid_cell_offset=0.5,
                 num_classes=80,
                 ori_img_size=640,
                 warmup_epoch=4,
                 use_dfl=True,
                 reg_max=16,
                 iou_type='giou',
                 loss_weight={
                         'class': 1.0,
                         'iou': 2.5,
                         'dfl': 0.5}
                 ):

        self.fpn_strides = fpn_strides
        self.grid_cell_size = grid_cell_size
        self.grid_cell_offset = grid_cell_offset
        self.num_classes = num_classes
        self.ori_img_size = ori_img_size

        self.warmup_epoch = warmup_epoch
        # ç™¾åˆ†ç™¾è¿˜åŸçš„assigner
        from yolov6.assigners.atss_assigner import ATSSAssigner
        from yolov6.assigners.tal_assigner import TaskAlignedAssigner

        self.warmup_assigner = ATSSAssigner(topk=9, num_classes=self.num_classes)
        self.formal_assigner = TaskAlignedAssigner(topk=13, num_classes=self.num_classes, alpha=1.0, beta=6.0)

        self.use_dfl = use_dfl
        self.reg_max = reg_max
        self.proj = jt.linspace(0, self.reg_max, self.reg_max + 1).float32().stop_grad()
        self.iou_type = iou_type
        self.varifocal_loss = VarifocalLoss()
        self.bbox_loss = BboxLoss(self.num_classes, self.reg_max, self.use_dfl, self.iou_type)
        self.loss_weight = loss_weight

    def _create_dummy_feats(self, batch_size):
        """åˆ›å»ºè™šæ‹Ÿç‰¹å¾å›¾ç”¨äºanchorç”Ÿæˆ"""
        # åˆ›å»ºä¸‰ä¸ªä¸åŒå°ºåº¦çš„è™šæ‹Ÿç‰¹å¾å›¾
        feats = [
            jt.zeros((batch_size, 256, 80, 80)),   # stride 8
            jt.zeros((batch_size, 512, 40, 40)),   # stride 16
            jt.zeros((batch_size, 1024, 20, 20))   # stride 32
        ]
        return feats

    def __call__(self, outputs, targets, epoch_num, step_num):
        # ğŸš¨ æ·±åº¦ä¿®å¤ï¼šæ­£ç¡®è§£ææ¨¡å‹è¾“å‡ºæ ¼å¼
        if isinstance(outputs, (list, tuple)) and len(outputs) == 3:
            # âœ… è®­ç»ƒæ¨¡å¼ï¼šæ ‡å‡†çš„ä¸‰è¾“å‡ºæ ¼å¼ (feats, pred_scores, pred_distri)
            feats, pred_scores, pred_distri = outputs
        else:
            # âŒ æ¨ç†æ¨¡å¼è¾“å‡ºä¸åº”è¯¥è¿›å…¥æŸå¤±å‡½æ•°ï¼
            # æŸå¤±å‡½æ•°åªåœ¨è®­ç»ƒæ—¶è°ƒç”¨ï¼Œæ¨ç†æ—¶ä¸åº”è¯¥è®¡ç®—æŸå¤±
            raise ValueError(f"ğŸš¨ æŸå¤±å‡½æ•°åªèƒ½åœ¨è®­ç»ƒæ¨¡å¼ä¸‹è°ƒç”¨ï¼æ¨ç†æ¨¡å¼è¾“å‡ºä¸åº”è¯¥è¿›å…¥æŸå¤±å‡½æ•°ã€‚\n"
                           f"   å½“å‰è¾“å‡ºç±»å‹: {type(outputs)}\n"
                           f"   æœŸæœ›è®­ç»ƒæ¨¡å¼è¾“å‡º: (feats, pred_scores, pred_distri)\n"
                           f"   è¯·æ£€æŸ¥æ¨¡å‹çš„trainingçŠ¶æ€ï¼")

        anchors, anchor_points, n_anchors_list, stride_tensor = \
            generate_anchors(feats, self.fpn_strides, self.grid_cell_size, self.grid_cell_offset,
                             device=None)

        # é”šç‚¹ç”Ÿæˆå®Œæˆ

        assert pred_scores.dtype == pred_distri.dtype
        # ç¡®ä¿æ•°æ®ç±»å‹ä¸€è‡´ï¼Œä¸pred_scoresä¿æŒä¸€è‡´ - ä¿®å¤ç±»å‹ä¸åŒ¹é…é—®é¢˜
        gt_bboxes_scale = jt.full((1, 4), self.ori_img_size, dtype=pred_scores.dtype)
        batch_size = pred_scores.shape[0]

        # é¢„å¤„ç†targets
        targets = self.preprocess(targets, batch_size, gt_bboxes_scale)

        gt_labels = targets[:, :, :1]
        gt_bboxes = targets[:, :, 1:]  # xyxy
        mask_gt = (gt_bboxes.sum(-1, keepdim=True) > 0).float()

        # pboxes
        anchor_points_s = anchor_points / stride_tensor
        pred_bboxes = self.bbox_decode(anchor_points_s, pred_distri)  # xyxy

        # æ ‡ç­¾åˆ†é…
        try:
            # æ ‡ç­¾åˆ†é…
            if epoch_num < self.warmup_epoch:
                # ä½¿ç”¨ATSSAssigner
                pred_bboxes_scaled = pred_bboxes.detach() * stride_tensor

                target_labels, target_bboxes, target_scores, fg_mask = \
                    self.warmup_assigner(
                            anchors,
                            n_anchors_list,
                            gt_labels,
                            gt_bboxes,
                            mask_gt,
                            pred_bboxes_scaled)

                # ATSSæ ‡ç­¾åˆ†é…å®Œæˆ
            else:
                # ä½¿ç”¨TaskAlignedAssigner

                target_labels, target_bboxes, target_scores, fg_mask = \
                    self.formal_assigner(
                            pred_scores.detach(),
                            pred_bboxes.detach() * stride_tensor,
                            anchor_points,
                            gt_labels,
                            gt_bboxes,
                            mask_gt)

        except Exception as e:
            raise e

        # rescale bbox
        target_bboxes /= stride_tensor

        # cls loss
        target_labels = jt.ternary(fg_mask > 0, target_labels, jt.full_like(target_labels, self.num_classes))
        one_hot_label = jt.nn.one_hot(target_labels.long(), self.num_classes + 1)[..., :-1]

        loss_cls = self.varifocal_loss(pred_scores, target_scores, one_hot_label)

        # æ•°å€¼ç¨³å®šæ€§ä¿®å¤ï¼šé¿å…é™¤é›¶é”™è¯¯
        target_scores_sum = target_scores.sum()
        target_scores_sum_scalar = float(target_scores_sum.data)  # Jittoræ–¹å¼è·å–æ ‡é‡å€¼

        if target_scores_sum_scalar > 1e-7:
            loss_cls = loss_cls / jt.maximum(target_scores_sum, 1e-7)
        # å¦‚æœtarget_scores_sumå¤ªå°ï¼Œä¿æŒloss_clsä¸å˜

        # Jittoræ–¹å¼å¤„ç†NaN/Inf
        try:
            if jt.isnan(loss_cls).sum() > 0:
                loss_cls = jt.ternary(jt.isnan(loss_cls), jt.zeros_like(loss_cls), loss_cls)
            if jt.isinf(loss_cls).sum() > 0:
                loss_cls = jt.ternary(jt.isinf(loss_cls), jt.full_like(loss_cls, 100.0), loss_cls)
        except:
            loss_cls = jt.clamp(loss_cls, 0.0, 100.0)

        # bbox loss
        loss_iou, loss_dfl = self.bbox_loss(pred_distri, pred_bboxes, anchor_points_s, target_bboxes,
                                            target_scores, target_scores_sum, fg_mask)

        # æœ€ç»ˆæŸå¤±åˆæˆ
        loss_cls_weighted = self.loss_weight['class'] * loss_cls
        loss_iou_weighted = self.loss_weight['iou'] * loss_iou
        loss_dfl_weighted = self.loss_weight['dfl'] * loss_dfl

        # Jittoræ–¹å¼æ£€æŸ¥æ¯ä¸ªæŸå¤±åˆ†é‡
        def safe_nan_inf_check(tensor, name=""):
            try:
                if jt.isnan(tensor).sum() > 0:
                    tensor = jt.ternary(jt.isnan(tensor), jt.zeros_like(tensor), tensor)
                if jt.isinf(tensor).sum() > 0:
                    tensor = jt.ternary(jt.isinf(tensor), jt.full_like(tensor, 100.0), tensor)
            except:
                tensor = jt.clamp(tensor, 0.0, 100.0)
            return tensor

        loss_cls_weighted = safe_nan_inf_check(loss_cls_weighted, "cls")
        loss_iou_weighted = safe_nan_inf_check(loss_iou_weighted, "iou")
        loss_dfl_weighted = safe_nan_inf_check(loss_dfl_weighted, "dfl")

        loss = loss_cls_weighted + loss_iou_weighted + loss_dfl_weighted

        # æœ€ç»ˆæŸå¤±æ£€æŸ¥
        loss = safe_nan_inf_check(loss, "final")
        try:
            if jt.isnan(loss).sum() > 0 or jt.isinf(loss).sum() > 0:
                loss = jt.zeros_like(loss)
        except:
            loss = jt.clamp(loss, 0.0, 1000.0)

        loss_items = jt.cat((loss_iou_weighted.unsqueeze(0),
                            loss_dfl_weighted.unsqueeze(0),
                            loss_cls_weighted.unsqueeze(0))).detach()

        return loss, loss_items

    def preprocess(self, targets, batch_size, scale_tensor):
        """å½»åº•é‡å†™çš„é¢„å¤„ç†æ–¹æ³• - å®Œå…¨è§£å†³inhomogeneous shapeé—®é¢˜"""
        try:
            # print(f"ğŸ” [preprocess] targetsç±»å‹: {type(targets)}, å½¢çŠ¶: {targets.shape}")

            # å¦‚æœæ²¡æœ‰ç›®æ ‡ï¼Œè¿”å›ç©ºçš„targets - ä¿®å¤Jittor numel()é—®é¢˜
            try:
                targets_size = targets.numel()
                # print(f"ğŸ” [preprocess] targets.numel(): {targets_size}")
            except Exception as e:
                # ä½¿ç”¨shapeè®¡ç®—å…ƒç´ æ•°é‡
                targets_size = 1
                for dim in targets.shape:
                    targets_size *= dim
                # print(f"ğŸ” [preprocess] é€šè¿‡shapeè®¡ç®—çš„å…ƒç´ æ•°é‡: {targets_size}")

            if targets_size == 0:
                empty_targets = jt.zeros((batch_size, 1, 5), dtype='float32')
                empty_targets[:, :, 0] = -1  # æ ‡è®°ä¸ºæ— æ•ˆç›®æ ‡
                return empty_targets

            # å®‰å…¨åœ°è½¬æ¢ä¸ºnumpyï¼Œé¿å…inhomogeneousé—®é¢˜
            if hasattr(targets, 'numpy'):
                targets_numpy = targets.detach().numpy()
            else:
                targets_numpy = np.array(targets)

            # ç¡®ä¿targets_numpyæ˜¯2ç»´çš„
            if len(targets_numpy.shape) == 1:
                targets_numpy = targets_numpy.reshape(1, -1)

            # åˆå§‹åŒ–æ¯ä¸ªbatchçš„ç›®æ ‡åˆ—è¡¨ - ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹æ³•
            batch_targets = []
            for b in range(batch_size):
                batch_targets.append([])

            # é€ä¸ªå¤„ç†ç›®æ ‡ï¼Œé¿å…æ‰¹é‡æ“ä½œå¯¼è‡´çš„shapeé—®é¢˜
            # å…³é”®ä¿®å¤ï¼šå¯¹äº[batch_size, num_targets, 6]æ ¼å¼ï¼Œéœ€è¦éå†æ‰€æœ‰ç›®æ ‡
            if len(targets_numpy.shape) == 3:  # [batch_size, num_targets, 6]
                for b in range(targets_numpy.shape[0]):  # éå†batch
                    for i in range(targets_numpy.shape[1]):  # éå†ç›®æ ‡
                        try:
                            item = targets_numpy[b, i]  # å–ç¬¬bä¸ªbatchçš„ç¬¬iä¸ªç›®æ ‡

                            # ä¿®å¤ï¼šæ­£ç¡®å¤„ç†è¾“å…¥æ ¼å¼ [batch_idx, class_id, x, y, w, h]
                            if len(item) >= 6:  # 6åˆ—æ ¼å¼ï¼š[batch_idx, class_id, x, y, w, h]
                                # æ­£ç¡®æå–batch_idx
                                batch_idx = int(item[0])
                                if batch_idx < batch_size:
                                    # æ­£ç¡®æå–ï¼šitem[1]æ˜¯class_id, item[2:6]æ˜¯åæ ‡
                                    target_data = [float(item[1]), float(item[2]), float(item[3]), float(item[4]), float(item[5])]
                                    batch_targets[batch_idx].append(target_data)
                        except Exception as e:
                            pass  # è·³è¿‡æœ‰é—®é¢˜çš„ç›®æ ‡
            else:  # [num_targets, 6] æ ¼å¼
                for i in range(targets_numpy.shape[0]):
                    try:
                        item = targets_numpy[i]
                        # ä¿®å¤ï¼šå¤„ç†å¤šç»´æ•°ç»„æƒ…å†µ
                        if item.ndim > 1:
                            item = item[0]

                        if len(item) >= 6:
                            batch_idx = int(item[0])
                            if batch_idx < batch_size:
                                target_data = [float(item[1]), float(item[2]), float(item[3]), float(item[4]), float(item[5])]
                                batch_targets[batch_idx].append(target_data)
                    except Exception as e:
                        pass  # è·³è¿‡æœ‰é—®é¢˜çš„ç›®æ ‡
                    continue  # è·³è¿‡æœ‰é—®é¢˜çš„ç›®æ ‡

            # æ‰¾åˆ°æœ€å¤§ç›®æ ‡æ•°é‡ï¼Œä½†é™åˆ¶ä¸Šé™é¿å…å†…å­˜é—®é¢˜
            max_targets = 0
            for targets_list in batch_targets:
                max_targets = max(max_targets, len(targets_list))

            if max_targets == 0:
                max_targets = 1  # è‡³å°‘æœ‰ä¸€ä¸ªä½ç½®
            elif max_targets > 100:  # é™åˆ¶æœ€å¤§ç›®æ ‡æ•°é‡
                max_targets = 100

            # æ‰‹åŠ¨åˆ›å»ºè§„æ•´çš„æ•°ç»„ï¼Œé¿å…numpyçš„inhomogeneousé—®é¢˜
            final_targets = []

            for batch_idx in range(batch_size):
                batch_target_list = batch_targets[batch_idx]

                # åˆ›å»ºå½“å‰batchçš„ç›®æ ‡æ•°ç»„
                batch_array = []

                # æ·»åŠ çœŸå®ç›®æ ‡
                for i in range(min(len(batch_target_list), max_targets)):
                    batch_array.append(batch_target_list[i])

                # å¡«å……è™šæ‹Ÿç›®æ ‡åˆ°max_targets
                while len(batch_array) < max_targets:
                    batch_array.append([-1.0, 0.0, 0.0, 0.0, 0.0])

                final_targets.append(batch_array)

            # ç°åœ¨å¯ä»¥å®‰å…¨åœ°è½¬æ¢ä¸ºnumpyæ•°ç»„
            targets_np = np.array(final_targets, dtype=np.float32)  # [batch_size, max_targets, 5]
            # print(f"ğŸ” [æ•°ç»„è½¬æ¢] targets_npå½¢çŠ¶: {targets_np.shape}")
            # print(f"ğŸ” [æ•°ç»„è½¬æ¢] targets_npå‰3è¡Œ: {targets_np[0, :3, :] if targets_np.shape[1] >= 3 else targets_np[0]}")

            targets = jt.array(targets_np, dtype='float32')

            # ç¡®ä¿scale_tensoræ˜¯float32
            scale_tensor = scale_tensor.float32()

            # å¤„ç†åæ ‡ç¼©æ”¾å’Œè½¬æ¢
            # print(f"ğŸ” [åæ ‡è½¬æ¢] ç¼©æ”¾å‰targets[:,:,1:5]å½¢çŠ¶: {targets[:, :, 1:5].shape}")
            # print(f"ğŸ” [åæ ‡è½¬æ¢] ç¼©æ”¾å‰æ•°å€¼èŒƒå›´: [{float(targets[:, :, 1:5].min().data):.6f}, {float(targets[:, :, 1:5].max().data):.6f}]")
            # print(f"ğŸ” [åæ ‡è½¬æ¢] scale_tensor: {scale_tensor.numpy()}")

            # åæ ‡ç¼©æ”¾
            coords_before = targets[:, :, 1:5]
            batch_target = coords_before * scale_tensor  # ç¼©æ”¾åæ ‡

            # ä¿®å¤ï¼šåˆ›å»ºå‰¯æœ¬é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
            batch_target_copy = batch_target.clone()
            xyxy_coords = xywh2xyxy(batch_target_copy)  # è½¬æ¢åæ ‡æ ¼å¼

            targets = jt.concat([
                targets[:, :, :1],  # ä¿æŒclassä¸å˜
                xyxy_coords
            ], dim=-1)

            return targets

        except Exception as e:
            # è¿”å›å®‰å…¨çš„é»˜è®¤å€¼
            empty_targets = jt.zeros((batch_size, 1, 5), dtype='float32')
            empty_targets[:, :, 0] = -1
            return empty_targets

    def bbox_decode(self, anchor_points, pred_dist):
        if self.use_dfl:
            batch_size, n_anchors, _ = pred_dist.shape
            pred_dist = jt.nn.softmax(pred_dist.view(batch_size, n_anchors, 4, self.reg_max + 1), dim=-1).matmul(
                    self.proj)
        return dist2bbox(pred_dist, anchor_points)


class SimpleAssigner:
    """ç®€åŒ–çš„æ ‡ç­¾åˆ†é…å™¨"""
    def __init__(self, num_classes=80):
        self.num_classes = num_classes

    def __call__(self, *args, **kwargs):
        # ç®€åŒ–çš„æ ‡ç­¾åˆ†é… - è¿”å›ç©ºçš„åˆ†é…ç»“æœ
        if len(args) >= 6:
            # formal assigneræ ¼å¼
            pred_scores, pred_bboxes, anchor_points, gt_labels, gt_bboxes, mask_gt = args[:6]
            batch_size, num_anchors = pred_scores.shape[:2]
        else:
            # warmup assigneræ ¼å¼
            anchors, n_anchors_list, gt_labels, gt_bboxes, mask_gt, pred_bboxes = args[:6]
            batch_size = gt_labels.shape[0]
            num_anchors = sum(n_anchors_list) if n_anchors_list else anchors.shape[0]

        # åˆ›å»ºç©ºçš„åˆ†é…ç»“æœ - ç¡®ä¿float32ç±»å‹
        target_labels = jt.zeros((batch_size, num_anchors, 1), dtype='float32')
        target_bboxes = jt.zeros((batch_size, num_anchors, 4), dtype='float32')
        target_scores = jt.zeros((batch_size, num_anchors, self.num_classes), dtype='float32')
        fg_mask = jt.zeros((batch_size, num_anchors), dtype='float32')

        return target_labels, target_bboxes, target_scores, fg_mask


class VarifocalLoss(nn.Module):
    def __init__(self):
        super(VarifocalLoss, self).__init__()

    def execute(self, pred_score, gt_score, label, alpha=0.75, gamma=2.0):
        # å®Œå…¨ç…§æŠ„PyTorchç‰ˆæœ¬çš„å®ç°
        pred_score = pred_score.float32()
        gt_score = gt_score.float32()
        label = label.float32()

        # å®Œå…¨ç…§æŠ„PyTorchç‰ˆæœ¬ï¼špred_scoreå·²ç»æ˜¯sigmoidåçš„æ¦‚ç‡
        weight = alpha * pred_score.pow(gamma) * (1 - label) + gt_score * label

        # å®Œå…¨ç…§æŠ„PyTorchç‰ˆæœ¬ï¼šF.binary_cross_entropyæœŸæœ›æ¦‚ç‡è¾“å…¥ï¼Œä¸æ˜¯logits
        # Jittorç‰ˆæœ¬ï¼šæ‰‹åŠ¨å®ç°binary_cross_entropy
        eps = 1e-7
        pred_score = jt.clamp(pred_score, eps, 1 - eps)
        bce_loss = -(gt_score * jt.log(pred_score) + (1 - gt_score) * jt.log(1 - pred_score))

        # è®¡ç®—æœ€ç»ˆæŸå¤±
        loss = (bce_loss * weight).sum()

        return loss


class BboxLoss(nn.Module):
    def __init__(self, num_classes, reg_max, use_dfl=False, iou_type='giou'):
        super(BboxLoss, self).__init__()
        self.num_classes = num_classes
        self.iou_loss = IOUloss(box_format='xyxy', iou_type=iou_type, eps=1e-10)
        self.reg_max = reg_max
        self.use_dfl = use_dfl

    def execute(self, pred_dist, pred_bboxes, anchor_points,
                target_bboxes, target_scores, target_scores_sum, fg_mask):

        # select positive samples mask
        num_pos = fg_mask.sum()
        num_pos_scalar = float(num_pos.data)  # Jittoræ–¹å¼è·å–æ ‡é‡å€¼
        # IoUæŸå¤±è®¡ç®—
        if num_pos_scalar > 0:
            # iou loss - ä¿®å¤Jittor APIï¼Œç”¨ç´¢å¼•æ›¿ä»£masked_select
            bbox_mask = fg_mask.unsqueeze(-1).repeat([1, 1, 4])

            # ä½¿ç”¨Jittorçš„æ–¹å¼å®ç°masked_select
            # æ‰¾åˆ°æ­£æ ·æœ¬çš„ç´¢å¼•
            pos_indices = jt.nonzero(fg_mask)  # [num_pos, 2] (batch_idx, anchor_idx)

            if pos_indices.shape[0] > 0:
                # æå–æ­£æ ·æœ¬çš„é¢„æµ‹æ¡†å’Œç›®æ ‡æ¡†
                pred_bboxes_pos = pred_bboxes[pos_indices[:, 0], pos_indices[:, 1]]  # [num_pos, 4]
                target_bboxes_pos = target_bboxes[pos_indices[:, 0], pos_indices[:, 1]]  # [num_pos, 4]
                bbox_weight = target_scores.sum(-1)[pos_indices[:, 0], pos_indices[:, 1]].unsqueeze(-1)  # [num_pos, 1]
            else:
                # æ²¡æœ‰æ­£æ ·æœ¬
                pred_bboxes_pos = jt.zeros((0, 4), dtype='float32')
                target_bboxes_pos = jt.zeros((0, 4), dtype='float32')
                bbox_weight = jt.zeros((0, 1), dtype='float32')
            loss_iou = self.iou_loss(pred_bboxes_pos, target_bboxes_pos) * bbox_weight

            # æ•°å€¼ç¨³å®šæ€§ä¿®å¤ï¼šå®‰å…¨çš„é™¤æ³•æ“ä½œ
            loss_iou_sum = loss_iou.sum()
            target_scores_sum_scalar = float(target_scores_sum.data)  # Jittoræ–¹å¼è·å–æ ‡é‡å€¼
            if target_scores_sum_scalar > 1e-7:  # æ›´ä¸¥æ ¼çš„æ£€æŸ¥
                loss_iou = loss_iou_sum / jt.maximum(target_scores_sum, 1e-7)
            else:
                loss_iou = loss_iou_sum

            # Jittoræ–¹å¼å¤„ç†NaN/Inf
            try:
                if jt.isnan(loss_iou).sum() > 0:
                    loss_iou = jt.ternary(jt.isnan(loss_iou), jt.zeros_like(loss_iou), loss_iou)
                if jt.isinf(loss_iou).sum() > 0:
                    loss_iou = jt.ternary(jt.isinf(loss_iou), jt.full_like(loss_iou, 10.0), loss_iou)
            except:
                loss_iou = jt.clamp(loss_iou, 0.0, 10.0)

            # dfl loss - å®Œå…¨ä¿®å¤DFLæŸå¤±è®¡ç®—
            if self.use_dfl and self.reg_max > 0 and pos_indices.shape[0] > 0:
                try:
                    # ä½¿ç”¨Jittoræ–¹å¼å®ç°masked_select
                    pred_dist_pos = pred_dist[pos_indices[:, 0], pos_indices[:, 1]]  # [num_pos, channels]

                    # æ£€æŸ¥pred_dist_posçš„å®é™…ç»´åº¦
                    num_pos = pred_dist_pos.shape[0]
                    channels = pred_dist_pos.shape[1]
                    expected_channels = 4 * (self.reg_max + 1)

                    if channels == expected_channels:
                        # DFLæ ¼å¼ï¼š[num_pos, 4*(reg_max+1)] -> [num_pos, 4, reg_max+1]
                        pred_dist_pos = pred_dist_pos.reshape([num_pos, 4, self.reg_max + 1])

                        target_ltrb = bbox2dist(anchor_points, target_bboxes, self.reg_max)
                        target_ltrb_pos = target_ltrb[pos_indices[:, 0], pos_indices[:, 1]]  # [num_pos, 4]

                        loss_dfl = self._df_loss(pred_dist_pos, target_ltrb_pos) * bbox_weight
                    else:
                        loss_dfl = jt.array(0.0)
                except Exception as e:
                    loss_dfl = jt.array(0.0)
            else:
                # DFLç¦ç”¨æˆ–æ— æ­£æ ·æœ¬
                loss_dfl = jt.array(0.0)

                # æ•°å€¼ç¨³å®šæ€§ä¿®å¤ï¼šå®‰å…¨çš„é™¤æ³•æ“ä½œ
                loss_dfl_sum = loss_dfl.sum()
                target_scores_sum_scalar = float(target_scores_sum.data)  # Jittoræ–¹å¼è·å–æ ‡é‡å€¼
                if target_scores_sum_scalar > 1e-7:  # æ›´ä¸¥æ ¼çš„æ£€æŸ¥
                    loss_dfl = loss_dfl_sum / jt.maximum(target_scores_sum, 1e-7)
                else:
                    loss_dfl = loss_dfl_sum

                # Jittoræ–¹å¼å¤„ç†NaN/Inf
                try:
                    if jt.isnan(loss_dfl).sum() > 0:
                        loss_dfl = jt.ternary(jt.isnan(loss_dfl), jt.zeros_like(loss_dfl), loss_dfl)
                    if jt.isinf(loss_dfl).sum() > 0:
                        loss_dfl = jt.ternary(jt.isinf(loss_dfl), jt.full_like(loss_dfl, 10.0), loss_dfl)
                except Exception as e:
                    loss_dfl = jt.clamp(loss_dfl, 0.0, 10.0)

        else:
            loss_iou = pred_dist.sum() * 0.
            loss_dfl = pred_dist.sum() * 0.

        return loss_iou, loss_dfl

    def _df_loss(self, pred_dist, target):
        try:
            # æ•°å€¼ç¨³å®šæ€§ä¿®å¤ï¼šé™åˆ¶targetèŒƒå›´
            target = jt.clamp(target, 0.0, self.reg_max - 0.01)
            target_left = target.long()
            target_right = jt.clamp(target_left + 1, 0, self.reg_max)  # ç¡®ä¿ä¸è¶…å‡ºèŒƒå›´

            weight_left = target_right.float() - target
            weight_right = 1 - weight_left

            # æ•°å€¼ç¨³å®šæ€§ä¿®å¤ï¼šé™åˆ¶æƒé‡èŒƒå›´
            weight_left = jt.clamp(weight_left, 0.0, 1.0)
            weight_right = jt.clamp(weight_right, 0.0, 1.0)

            # å®‰å…¨çš„äº¤å‰ç†µè®¡ç®—
            pred_dist_safe = jt.clamp(pred_dist, -10.0, 10.0)  # é™åˆ¶logitsèŒƒå›´

            try:
                loss_left_raw = jt.nn.cross_entropy_loss(
                    pred_dist_safe.view(-1, self.reg_max + 1), target_left.view(-1))
                loss_right_raw = jt.nn.cross_entropy_loss(
                    pred_dist_safe.view(-1, self.reg_max + 1), target_right.view(-1))
            except:
                # å¦‚æœäº¤å‰ç†µè®¡ç®—å¤±è´¥ï¼Œè¿”å›é›¶æŸå¤±
                return jt.zeros((target.shape[0], target.shape[1], 1), dtype='float32')

            # é™åˆ¶æŸå¤±èŒƒå›´
            loss_left_raw = jt.clamp(loss_left_raw, 0.0, 100.0)
            loss_right_raw = jt.clamp(loss_right_raw, 0.0, 100.0)

            # æ‰‹åŠ¨reshapeå’ŒåŠ æƒ - ä¿®å¤Jittor API
            loss_left = loss_left_raw.reshape(target_left.shape) * weight_left
            loss_right = loss_right_raw.reshape(target_left.shape) * weight_right

            # è®¡ç®—æœ€ç»ˆæŸå¤±
            final_loss = (loss_left + loss_right).mean(-1, keepdim=True)

            # Jittoræ–¹å¼å¤„ç†NaN/Inf
            try:
                if jt.isnan(final_loss).sum() > 0:
                    final_loss = jt.ternary(jt.isnan(final_loss), jt.zeros_like(final_loss), final_loss)
                if jt.isinf(final_loss).sum() > 0:
                    final_loss = jt.ternary(jt.isinf(final_loss), jt.full_like(final_loss, 10.0), final_loss)
            except:
                # å¦‚æœæ£€æŸ¥å¤±è´¥ï¼Œç›´æ¥é™åˆ¶èŒƒå›´
                final_loss = jt.clamp(final_loss, 0.0, 10.0)

            return final_loss

        except Exception as e:
            print(f"âš ï¸ DFLæŸå¤±è®¡ç®—å¼‚å¸¸: {e}")
            # è¿”å›å½¢çŠ¶æ­£ç¡®çš„é›¶æŸå¤±
            return jt.zeros((target.shape[0], target.shape[1], 1), dtype='float32')


# ä¿æŒå‘åå…¼å®¹
class YOLOLoss(nn.Module):
    """ç®€åŒ–ä½†å®Œæ•´çš„YOLOæŸå¤±å‡½æ•°"""
    
    def __init__(self, num_classes=20, img_size=640):
        super().__init__()
        self.num_classes = num_classes
        self.img_size = img_size
        
        # æŸå¤±æƒé‡
        self.lambda_cls = 1.0      # åˆ†ç±»æŸå¤±æƒé‡
        self.lambda_obj = 5.0      # ç›®æ ‡æ€§æŸå¤±æƒé‡
        self.lambda_box = 10.0     # è¾¹ç•Œæ¡†æŸå¤±æƒé‡
        
        # æŸå¤±å‡½æ•°
        self.bce_cls = nn.BCEWithLogitsLoss()
        self.bce_obj = nn.BCEWithLogitsLoss()
        self.mse_box = nn.MSELoss()
        
        print(f"âœ… åˆå§‹åŒ–YOLOæŸå¤±å‡½æ•°: {num_classes}ç±», å›¾åƒå°ºå¯¸{img_size}")
    
    def execute(self, predictions, targets):
        """
        è®¡ç®—YOLOæŸå¤±
        
        Args:
            predictions: æ¨¡å‹é¢„æµ‹è¾“å‡º [batch_size, num_anchors, num_classes + 5]
            targets: çœŸå®æ ‡ç­¾ [num_targets, 6] (batch_idx, class_id, x, y, w, h)
        
        Returns:
            total_loss: æ€»æŸå¤±
        """
        if isinstance(predictions, (list, tuple)):
            # å¤šå°ºåº¦è¾“å‡ºï¼Œå–ç¬¬ä¸€ä¸ª
            pred = predictions[0]
        else:
            pred = predictions
        
        batch_size = pred.shape[0]
        
        # å¦‚æœæ²¡æœ‰ç›®æ ‡ï¼Œè¿”å›ç®€å•æŸå¤±
        if targets.shape[0] == 0:
            # æ— ç›®æ ‡æ—¶çš„æŸå¤±
            fake_cls_target = jt.zeros((batch_size, pred.shape[1], self.num_classes))
            fake_obj_target = jt.zeros((batch_size, pred.shape[1], 1))
            
            cls_loss = jt.mean((pred[..., :self.num_classes] - fake_cls_target) ** 2)
            obj_loss = jt.mean((pred[..., self.num_classes:self.num_classes+1] - fake_obj_target) ** 2)
            box_loss = jt.mean(pred[..., self.num_classes+1:self.num_classes+5] ** 2)
            
            total_loss = self.lambda_cls * cls_loss + self.lambda_obj * obj_loss + self.lambda_box * box_loss
            return total_loss
        
        # è§£æé¢„æµ‹
        if pred.shape[-1] == self.num_classes + 5:
            # æ ¼å¼: [x, y, w, h, obj, cls1, cls2, ...]
            pred_boxes = pred[..., :4]                           # [batch, anchors, 4]
            pred_obj = pred[..., 4:5]                           # [batch, anchors, 1]
            pred_cls = pred[..., 5:5+self.num_classes]          # [batch, anchors, num_classes]
        elif pred.shape[-1] == self.num_classes + 4:
            # æ ¼å¼: [x, y, w, h, cls1, cls2, ...]
            pred_boxes = pred[..., :4]                           # [batch, anchors, 4]
            pred_cls = pred[..., 4:4+self.num_classes]          # [batch, anchors, num_classes]
            pred_obj = jt.ones((batch_size, pred.shape[1], 1))  # å‡è®¾æ‰€æœ‰ä½ç½®éƒ½æœ‰ç›®æ ‡
        else:
            # å…¶ä»–æ ¼å¼ï¼Œä½¿ç”¨ç®€åŒ–æŸå¤±
            total_loss = jt.mean(pred ** 2)
            return total_loss
        
        # åˆ›å»ºç›®æ ‡å¼ é‡
        target_cls = jt.zeros((batch_size, pred.shape[1], self.num_classes))
        target_obj = jt.zeros((batch_size, pred.shape[1], 1))
        target_boxes = jt.zeros((batch_size, pred.shape[1], 4))
        
        # å¤„ç†çœŸå®æ ‡ç­¾
        if targets.shape[0] > 0:
            for target in targets:
                batch_idx = int(target[0])
                class_id = int(target[1])
                x, y, w, h = target[2:6]
                
                # ç®€åŒ–çš„æ ‡ç­¾åˆ†é…ï¼šéšæœºé€‰æ‹©ä¸€ä¸ªanchorä½ç½®
                if batch_idx < batch_size and class_id < self.num_classes:
                    anchor_idx = np.random.randint(0, pred.shape[1])
                    
                    # è®¾ç½®åˆ†ç±»ç›®æ ‡
                    target_cls[batch_idx, anchor_idx, class_id] = 1.0
                    
                    # è®¾ç½®ç›®æ ‡æ€§ç›®æ ‡
                    target_obj[batch_idx, anchor_idx, 0] = 1.0
                    
                    # è®¾ç½®è¾¹ç•Œæ¡†ç›®æ ‡
                    target_boxes[batch_idx, anchor_idx, 0] = x
                    target_boxes[batch_idx, anchor_idx, 1] = y
                    target_boxes[batch_idx, anchor_idx, 2] = w
                    target_boxes[batch_idx, anchor_idx, 3] = h
        
        # è®¡ç®—æŸå¤±
        # åˆ†ç±»æŸå¤±
        cls_loss = jt.mean((pred_cls - target_cls) ** 2)
        
        # ç›®æ ‡æ€§æŸå¤±
        if pred_obj.shape == target_obj.shape:
            obj_loss = jt.mean((pred_obj - target_obj) ** 2)
        else:
            obj_loss = jt.mean(pred_obj ** 2)
        
        # è¾¹ç•Œæ¡†æŸå¤±
        box_loss = jt.mean((pred_boxes - target_boxes) ** 2)
        
        # æ€»æŸå¤±
        total_loss = (self.lambda_cls * cls_loss + 
                     self.lambda_obj * obj_loss + 
                     self.lambda_box * box_loss)
        
        return total_loss


class FocalLoss(nn.Module):
    """Focal Loss for addressing class imbalance"""
    
    def __init__(self, alpha=1, gamma=2):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
    
    def execute(self, inputs, targets):
        # ä¿®å¤Jittor API - æ²¡æœ‰reductionå‚æ•°
        ce_loss = jt.nn.cross_entropy_loss(inputs, targets)
        pt = jt.exp(-ce_loss)
        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss
        return jt.mean(focal_loss)


def create_loss_function(num_classes=20, img_size=640):
    """åˆ›å»ºæŸå¤±å‡½æ•° - ç™¾åˆ†ç™¾è¿˜åŸPyTorchç‰ˆæœ¬"""
    return ComputeLoss(
        fpn_strides=[8, 16, 32],
        grid_cell_size=5.0,
        grid_cell_offset=0.5,
        num_classes=num_classes,
        ori_img_size=img_size,
        warmup_epoch=4,
        use_dfl=False,  # å¯¹é½é…ç½®æ–‡ä»¶
        reg_max=16,
        iou_type='giou',
        loss_weight={
            'class': 1.0,
            'iou': 2.5,
            'dfl': 0.5
        }
    )


# æµ‹è¯•æŸå¤±å‡½æ•°
if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯•YOLOæŸå¤±å‡½æ•°...")
    
    # åˆ›å»ºæŸå¤±å‡½æ•°
    loss_fn = create_loss_function(num_classes=20)
    
    # æ¨¡æ‹Ÿé¢„æµ‹å’Œç›®æ ‡
    batch_size = 2
    num_anchors = 8400
    num_classes = 20
    
    # é¢„æµ‹: [batch_size, num_anchors, num_classes + 5]
    predictions = jt.randn(batch_size, num_anchors, num_classes + 5)
    
    # ç›®æ ‡: [num_targets, 6] (batch_idx, class_id, x, y, w, h)
    targets = jt.array([
        [0, 5, 0.5, 0.5, 0.2, 0.3],  # batch 0, class 5
        [1, 10, 0.3, 0.7, 0.1, 0.2], # batch 1, class 10
    ])
    
    # è®¡ç®—æŸå¤±
    loss = loss_fn(predictions, targets)

    print(f"âœ… æŸå¤±è®¡ç®—æˆåŠŸ: {float(loss.data):.6f}")
    print("ğŸ¯ æŸå¤±å‡½æ•°æµ‹è¯•å®Œæˆï¼")
