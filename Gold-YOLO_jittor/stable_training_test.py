#!/usr/bin/env python3
"""
ç¨³å®šè®­ç»ƒæµ‹è¯•
ä½¿ç”¨æ›´å°çš„å­¦ä¹ ç‡ï¼Œé€æ­¥æ’æŸ¥é—®é¢˜
"""

import os
import sys
import cv2
import numpy as np
import jittor as jt
from pathlib import Path
import time
import math

# æ·»åŠ è·¯å¾„
sys.path.append('.')
sys.path.append('./yolov6')

from models.perfect_gold_yolo import create_perfect_gold_yolo_model
from yolov6.data.data_augment import letterbox
from yolov6.models.pytorch_aligned_losses import ComputeLoss

def pytorch_exact_initialization(model):
    """å®Œå…¨ç…§æŠ„PyTorchç‰ˆæœ¬çš„åˆå§‹åŒ–"""
    for module in model.modules():
        if hasattr(module, 'initialize_biases'):
            module.initialize_biases()
            break
    return model

def stable_training_test():
    """ç¨³å®šè®­ç»ƒæµ‹è¯•"""
    print(f"ğŸ”§ ç¨³å®šè®­ç»ƒæµ‹è¯•")
    print("=" * 80)
    print(f"ä½¿ç”¨æ›´å°çš„å­¦ä¹ ç‡ï¼Œé€æ­¥æ’æŸ¥è®­ç»ƒä¸ç¨³å®šé—®é¢˜")
    print("=" * 80)
    
    # å‡†å¤‡æ•°æ®
    label_file = "/home/kyc/project/GOLD-YOLO/2008_001420.txt"
    img_path = "/home/kyc/project/GOLD-YOLO/2008_001420.jpg"
    
    # è¯»å–æ ‡æ³¨
    annotations = []
    with open(label_file, 'r') as f:
        for line in f:
            line = line.strip()
            if line:
                parts = line.split()
                if len(parts) >= 5:
                    cls_id = int(parts[0])
                    x_center = float(parts[1])
                    y_center = float(parts[2])
                    width = float(parts[3])
                    height = float(parts[4])
                    annotations.append([cls_id, x_center, y_center, width, height])
    
    # è¯»å–å›¾åƒ
    original_img = cv2.imread(img_path)
    img = letterbox(original_img, new_shape=500, stride=32, auto=False)[0]
    img_tensor_input = img.transpose((2, 0, 1))[::-1]
    img_tensor_input = np.ascontiguousarray(img_tensor_input)
    img_tensor_input = img_tensor_input.astype(np.float32) / 255.0
    img_tensor = jt.array(img_tensor_input).unsqueeze(0)
    
    # å‡†å¤‡æ ‡ç­¾
    targets = []
    for ann in annotations:
        cls_id, x_center, y_center, width, height = ann
        targets.append([0, cls_id, x_center, y_center, width, height])
    targets_tensor = jt.array(targets, dtype=jt.float32).unsqueeze(0)
    
    print(f"ğŸ“Š æ•°æ®å‡†å¤‡:")
    print(f"   å›¾åƒå¼ é‡: {img_tensor.shape}")
    print(f"   æ ‡ç­¾å¼ é‡: {targets_tensor.shape}")
    print(f"   ç›®æ ‡æ•°é‡: {len(annotations)}ä¸ª")
    
    # åˆ›å»ºæ¨¡å‹
    print(f"\nğŸ¯ åˆ›å»ºæ¨¡å‹:")
    model = create_perfect_gold_yolo_model()
    model = pytorch_exact_initialization(model)
    model.train()
    
    # åˆ›å»ºæŸå¤±å‡½æ•°
    loss_fn = ComputeLoss(
        num_classes=20,
        ori_img_size=500,
        warmup_epoch=0,
        use_dfl=False,
        reg_max=0,
        fpn_strides=[8, 16, 32],
        grid_cell_size=5.0,
        grid_cell_offset=0.5,
        loss_weight={'class': 1.0, 'iou': 2.5, 'dfl': 0.5}
    )
    
    # æµ‹è¯•ä¸åŒå­¦ä¹ ç‡
    learning_rates = [0.001, 0.005, 0.01, 0.02]
    
    for lr in learning_rates:
        print(f"\nğŸ”§ æµ‹è¯•å­¦ä¹ ç‡: {lr}")
        print("-" * 60)
        
        # é‡æ–°åˆ›å»ºæ¨¡å‹å’Œä¼˜åŒ–å™¨
        model = create_perfect_gold_yolo_model()
        model = pytorch_exact_initialization(model)
        model.train()
        
        optimizer = jt.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=0.0)
        
        # è®°å½•è®­ç»ƒè¿‡ç¨‹
        loss_history = []
        stable_training = True
        
        print(f"   å¼€å§‹è®­ç»ƒ (20è½®):")
        
        for epoch in range(20):
            try:
                # å‰å‘ä¼ æ’­
                outputs = model(img_tensor)
                
                # è®¡ç®—æŸå¤±
                loss, loss_items = loss_fn(outputs, targets_tensor, epoch_num=epoch, step_num=epoch)
                
                # æ£€æŸ¥æŸå¤±å€¼
                loss_value = float(loss.data.item())
                loss_items_values = [float(item.data.item()) for item in loss_items]
                
                # æ£€æŸ¥æ˜¯å¦ç¨³å®š
                if not math.isfinite(loss_value):
                    print(f"     è½®æ¬¡ {epoch+1:2d}: âŒ æŸå¤±ä¸ºNaNæˆ–Inf")
                    stable_training = False
                    break
                elif loss_value > 10000:
                    print(f"     è½®æ¬¡ {epoch+1:2d}: âŒ æŸå¤±çˆ†ç‚¸ ({loss_value:.2f})")
                    stable_training = False
                    break
                elif any(not math.isfinite(v) for v in loss_items_values):
                    print(f"     è½®æ¬¡ {epoch+1:2d}: âŒ æŸå¤±é¡¹æœ‰NaN/Inf")
                    stable_training = False
                    break
                elif any(v > 100000 for v in loss_items_values):
                    print(f"     è½®æ¬¡ {epoch+1:2d}: âŒ æŸå¤±é¡¹çˆ†ç‚¸")
                    stable_training = False
                    break
                
                # åå‘ä¼ æ’­
                optimizer.zero_grad()
                optimizer.backward(loss)
                
                # æ£€æŸ¥æ¢¯åº¦
                max_grad_norm = 0.0
                nan_grads = 0
                
                for param in model.parameters():
                    if param.requires_grad:
                        try:
                            grad = param.opt_grad(optimizer)
                            if grad is not None:
                                grad_norm = float(grad.norm())
                                if not math.isfinite(grad_norm):
                                    nan_grads += 1
                                else:
                                    max_grad_norm = max(max_grad_norm, grad_norm)
                        except:
                            pass
                
                if nan_grads > 0:
                    print(f"     è½®æ¬¡ {epoch+1:2d}: âŒ {nan_grads}ä¸ªæ¢¯åº¦ä¸ºNaN")
                    stable_training = False
                    break
                elif max_grad_norm > 1000:
                    print(f"     è½®æ¬¡ {epoch+1:2d}: âŒ æ¢¯åº¦è¿‡å¤§ ({max_grad_norm:.2f})")
                    stable_training = False
                    break
                
                # æ›´æ–°å‚æ•°
                optimizer.step()
                
                loss_history.append(loss_value)
                
                # æ¯5è½®æ‰“å°ä¸€æ¬¡
                if (epoch + 1) % 5 == 0:
                    print(f"     è½®æ¬¡ {epoch+1:2d}: æŸå¤±={loss_value:.6f}, æŸå¤±é¡¹={[f'{x:.4f}' for x in loss_items_values]}, æœ€å¤§æ¢¯åº¦={max_grad_norm:.4f}")
                
            except Exception as e:
                print(f"     è½®æ¬¡ {epoch+1:2d}: âŒ è®­ç»ƒå¼‚å¸¸: {e}")
                stable_training = False
                break
        
        # åˆ†æç»“æœ
        if stable_training and len(loss_history) >= 20:
            initial_loss = loss_history[0]
            final_loss = loss_history[-1]
            loss_reduction = (initial_loss - final_loss) / initial_loss * 100
            
            print(f"   âœ… è®­ç»ƒç¨³å®š:")
            print(f"     åˆå§‹æŸå¤±: {initial_loss:.6f}")
            print(f"     æœ€ç»ˆæŸå¤±: {final_loss:.6f}")
            print(f"     æŸå¤±ä¸‹é™: {loss_reduction:.1f}%")
            
            # åˆ¤æ–­æ˜¯å¦æœ‰å­¦ä¹ æ•ˆæœ
            if loss_reduction > 5:
                print(f"     ğŸ‰ å­¦ä¹ ç‡ {lr} æ•ˆæœè‰¯å¥½ï¼")
                
                # ç»§ç»­è®­ç»ƒæ›´å¤šè½®æ¬¡
                print(f"   ç»§ç»­è®­ç»ƒåˆ°50è½®:")
                
                for epoch in range(20, 50):
                    try:
                        outputs = model(img_tensor)
                        loss, loss_items = loss_fn(outputs, targets_tensor, epoch_num=epoch, step_num=epoch)
                        loss_value = float(loss.data.item())
                        
                        if not math.isfinite(loss_value) or loss_value > 10000:
                            print(f"     è½®æ¬¡ {epoch+1:2d}: âŒ è®­ç»ƒå˜ä¸ç¨³å®š")
                            break
                        
                        optimizer.zero_grad()
                        optimizer.backward(loss)
                        optimizer.step()
                        
                        loss_history.append(loss_value)
                        
                        if (epoch + 1) % 10 == 0:
                            print(f"     è½®æ¬¡ {epoch+1:2d}: æŸå¤±={loss_value:.6f}")
                    
                    except Exception as e:
                        print(f"     è½®æ¬¡ {epoch+1:2d}: âŒ è®­ç»ƒå¼‚å¸¸: {e}")
                        break
                
                # æœ€ç»ˆç»“æœ
                if len(loss_history) >= 50:
                    final_loss = loss_history[-1]
                    total_reduction = (initial_loss - final_loss) / initial_loss * 100
                    print(f"   ğŸ¯ 50è½®è®­ç»ƒç»“æœ:")
                    print(f"     æ€»æŸå¤±ä¸‹é™: {total_reduction:.1f}%")
                    print(f"     æœ€ç»ˆæŸå¤±: {final_loss:.6f}")
                    
                    if total_reduction > 50:
                        print(f"     ğŸ‰ğŸ‰ğŸ‰ å­¦ä¹ ç‡ {lr} è®­ç»ƒæˆåŠŸï¼")
                        return lr, True
            else:
                print(f"     âš ï¸ å­¦ä¹ ç‡ {lr} å­¦ä¹ æ•ˆæœä¸ä½³")
        else:
            print(f"   âŒ å­¦ä¹ ç‡ {lr} è®­ç»ƒä¸ç¨³å®š")
    
    print(f"\nğŸ“Š æµ‹è¯•æ€»ç»“:")
    print(f"   æ‰€æœ‰æµ‹è¯•çš„å­¦ä¹ ç‡éƒ½æœ‰é—®é¢˜")
    print(f"   å»ºè®®è¿›ä¸€æ­¥é™ä½å­¦ä¹ ç‡æˆ–æ£€æŸ¥æŸå¤±å‡½æ•°")
    
    return None, False

def main():
    print("ğŸ”§ ç¨³å®šè®­ç»ƒæµ‹è¯•")
    print("=" * 80)
    
    try:
        best_lr, success = stable_training_test()
        
        if success:
            print(f"\nğŸ‰ æ‰¾åˆ°ç¨³å®šçš„å­¦ä¹ ç‡: {best_lr}")
            print(f"   å¯ä»¥ä½¿ç”¨æ­¤å­¦ä¹ ç‡è¿›è¡Œæ­£å¼è®­ç»ƒ")
        else:
            print(f"\nâŒ æ²¡æœ‰æ‰¾åˆ°ç¨³å®šçš„å­¦ä¹ ç‡")
            print(f"   éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•æ¨¡å‹æˆ–æŸå¤±å‡½æ•°")
            
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
