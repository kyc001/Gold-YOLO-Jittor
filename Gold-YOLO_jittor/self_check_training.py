#!/usr/bin/env python3
"""
GOLD-YOLO-n è‡ªæ£€è®­ç»ƒéªŒè¯ç³»ç»Ÿ
ç”¨å•å¼ å›¾ç‰‡è®­ç»ƒ500æ¬¡ï¼Œç„¶åæ£€æµ‹åŒä¸€å¼ å›¾ç‰‡éªŒè¯æ¨¡å‹åŠŸèƒ½
"""

import os
import sys
import time
import cv2
import numpy as np
import yaml
from pathlib import Path

import jittor as jt
from jittor import nn
from jittor.dataset import Dataset, DataLoader

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models.perfect_gold_yolo import create_perfect_gold_yolo_model
from yolov6.data.data_augment import letterbox
from yolov6.utils.nms import non_max_suppression
from yolov6.utils.general import scale_coords

class SingleImageDataset(Dataset):
    """å•å¼ å›¾ç‰‡æ•°æ®é›†"""
    
    def __init__(self, img_path, label_path, img_size=640):
        super().__init__()
        self.img_path = img_path
        self.label_path = label_path
        self.img_size = img_size
        
        # åŠ è½½å›¾åƒ
        self.img = cv2.imread(img_path)
        assert self.img is not None, f"æ— æ³•è¯»å–å›¾åƒ: {img_path}"
        
        # åŠ è½½æ ‡ç­¾
        self.labels = self.load_labels(label_path)
        
        print(f"ğŸ“¸ è‡ªæ£€å›¾åƒ: {img_path}")
        print(f"ğŸ·ï¸ å›¾åƒå°ºå¯¸: {self.img.shape}")
        print(f"ğŸ¯ ç›®æ ‡æ•°é‡: {len(self.labels)}")
        if len(self.labels) > 0:
            print(f"ğŸ¯ ç›®æ ‡ç±»åˆ«: {[int(label[0]) for label in self.labels]}")
    
    def load_labels(self, label_path):
        """åŠ è½½YOLOæ ¼å¼æ ‡ç­¾"""
        if not os.path.exists(label_path):
            print(f"âš ï¸ æ ‡ç­¾æ–‡ä»¶ä¸å­˜åœ¨: {label_path}")
            return []
        
        labels = []
        with open(label_path, 'r') as f:
            for line in f:
                line = line.strip()
                if line:
                    parts = line.split()
                    if len(parts) >= 5:
                        cls_id = int(parts[0])
                        x_center = float(parts[1])
                        y_center = float(parts[2])
                        width = float(parts[3])
                        height = float(parts[4])
                        labels.append([cls_id, x_center, y_center, width, height])
        
        return labels
    
    def __len__(self):
        return 1  # åªæœ‰ä¸€å¼ å›¾ç‰‡
    
    def __getitem__(self, idx):
        # å›¾åƒé¢„å¤„ç†
        img = letterbox(self.img, new_shape=self.img_size, stride=32, auto=False)[0]
        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, HWC to CHW
        img = np.ascontiguousarray(img)
        img = img.astype(np.float32) / 255.0  # å½’ä¸€åŒ–åˆ°[0,1]

        # æ ‡ç­¾å¤„ç† - ä½¿ç”¨è°ƒè¯•éªŒè¯çš„æ­£ç¡®æ ¼å¼
        if len(self.labels) > 0:
            # å•ä¸ªç›®æ ‡çš„æ ¼å¼ï¼š[cls, x_center, y_center, width, height, 0]
            label = self.labels[0]  # åªä½¿ç”¨ç¬¬ä¸€ä¸ªæ ‡ç­¾
            labels_out = jt.array([[label[0], label[1], label[2], label[3], label[4], 0]], dtype='float32')
        else:
            labels_out = jt.zeros((1, 6), dtype='float32')  # ç©ºæ ‡ç­¾

        return jt.array(img, dtype='float32'), labels_out

def create_self_check_dataset():
    """åˆ›å»ºè‡ªæ£€æ•°æ®é›†"""
    # é€‰æ‹©æµ‹è¯•å›¾åƒ
    img_path = '/home/kyc/project/GOLD-YOLO/Gold-YOLO_pytorch/runs/inference/pytorch_baseline_test/test_images/2008_000099.jpg'
    
    # åˆ›å»ºå¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶ï¼ˆæ‰‹åŠ¨æ ‡æ³¨ä¸€ä¸ªç®€å•çš„ç›®æ ‡ï¼‰
    label_path = 'self_check_label.txt'
    
    # æ£€æŸ¥å›¾åƒæ˜¯å¦å­˜åœ¨
    if not os.path.exists(img_path):
        print(f"âŒ æµ‹è¯•å›¾åƒä¸å­˜åœ¨: {img_path}")
        return None, None
    
    # åˆ›å»ºç®€å•çš„æ ‡ç­¾ï¼ˆå‡è®¾å›¾åƒä¸­å¿ƒæœ‰ä¸€ä¸ªå¤§ç›®æ ‡ï¼‰
    with open(label_path, 'w') as f:
        # ç±»åˆ«0ï¼Œä¸­å¿ƒä½ç½®(0.5, 0.5)ï¼Œå°ºå¯¸(0.8, 0.8) - æ›´å¤§çš„ç›®æ ‡æ›´å®¹æ˜“å­¦ä¹ 
        f.write("0 0.5 0.5 0.8 0.8\n")
    
    print(f"âœ… åˆ›å»ºè‡ªæ£€æ ‡ç­¾: {label_path}")
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = SingleImageDataset(img_path, label_path)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0)
    
    return dataset, dataloader

def self_check_training():
    """è‡ªæ£€è®­ç»ƒä¸»å‡½æ•°"""
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                GOLD-YOLO-n è‡ªæ£€è®­ç»ƒéªŒè¯ç³»ç»Ÿ                  â•‘
    â•‘                                                              â•‘
    â•‘  ğŸ¯ ç”¨å•å¼ å›¾ç‰‡è®­ç»ƒ500æ¬¡éªŒè¯æ¨¡å‹åŠŸèƒ½                          â•‘
    â•‘  ğŸ“Š è®­ç»ƒå®Œæˆåæ£€æµ‹åŒä¸€å¼ å›¾ç‰‡éªŒè¯è¯†åˆ«èƒ½åŠ›                     â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # åˆ›å»ºè‡ªæ£€æ•°æ®é›†
    print("ğŸ“¦ åˆ›å»ºè‡ªæ£€æ•°æ®é›†...")
    dataset, dataloader = create_self_check_dataset()
    if dataset is None:
        return False
    
    # åˆ›å»ºæ¨¡å‹
    print("ğŸ”§ åˆ›å»ºæ¨¡å‹...")
    model = create_perfect_gold_yolo_model('gold_yolo-n', num_classes=20)
    
    # åˆ›å»ºæŸå¤±å‡½æ•°
    print("ğŸ”§ åˆ›å»ºæŸå¤±å‡½æ•°...")
    import importlib.util
    losses_file = os.path.join(os.path.dirname(__file__), 'yolov6', 'models', 'losses.py')
    spec = importlib.util.spec_from_file_location("losses", losses_file)
    losses_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(losses_module)
    
    loss_fn = losses_module.ComputeLoss(
        num_classes=20,
        ori_img_size=640,
        warmup_epoch=0,
        use_dfl=False,
        reg_max=0,
        iou_type='siou',
        loss_weight={
            'class': 1.0,
            'iou': 2.5,
            'dfl': 0.5
        }
    )
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    print("ğŸ”§ åˆ›å»ºä¼˜åŒ–å™¨...")
    optimizer = nn.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)
    
    # å¼€å§‹è‡ªæ£€è®­ç»ƒ
    print("ğŸš€ å¼€å§‹è‡ªæ£€è®­ç»ƒ...")
    print(f"   è®­ç»ƒè½®æ•°: 500")
    print(f"   å­¦ä¹ ç‡: 0.01")
    print("=" * 70)
    
    model.train()
    
    for epoch in range(500):
        epoch_loss = 0.0
        
        for batch_idx, (images, targets) in enumerate(dataloader):

            # å‰å‘ä¼ æ’­
            predictions = model(images)

            # è®¡ç®—æŸå¤±
            loss, _ = loss_fn(predictions, targets, epoch_num=epoch+1, step_num=batch_idx+1)
            
            if loss is not None:
                # åå‘ä¼ æ’­
                optimizer.zero_grad()
                optimizer.backward(loss)
                optimizer.step()
                
                epoch_loss += float(loss.data)
        
        # æ‰“å°è®­ç»ƒè¿›åº¦
        if (epoch + 1) % 50 == 0:
            print(f"Epoch {epoch+1:3d}/500 | Loss: {epoch_loss:.6f}")
    
    print("âœ… è‡ªæ£€è®­ç»ƒå®Œæˆï¼")
    
    # ä¿å­˜è‡ªæ£€æ¨¡å‹
    save_path = 'self_check_model.pkl'
    jt.save(model.state_dict(), save_path)
    print(f"ğŸ’¾ è‡ªæ£€æ¨¡å‹å·²ä¿å­˜: {save_path}")
    
    # è¿›è¡Œè‡ªæ£€æ¨ç†
    print("\nğŸ” å¼€å§‹è‡ªæ£€æ¨ç†...")
    model.eval()
    
    # åŠ è½½æµ‹è¯•å›¾åƒ
    img_path = '/home/kyc/project/GOLD-YOLO/Gold-YOLO_pytorch/runs/inference/pytorch_baseline_test/test_images/2008_000099.jpg'
    img0 = cv2.imread(img_path)
    
    # é¢„å¤„ç†
    img = letterbox(img0, new_shape=640, stride=32, auto=False)[0]
    img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, HWC to CHW
    img = np.ascontiguousarray(img)
    img = img.astype(np.float32) / 255.0  # å½’ä¸€åŒ–åˆ°[0,1]
    img = jt.array(img)
    if img.ndim == 3:
        img = img.unsqueeze(0)  # æ·»åŠ batchç»´åº¦
    
    # æ¨ç†
    with jt.no_grad():
        pred = model(img)
    
    # åå¤„ç†
    pred = non_max_suppression(pred, conf_thres=0.01, iou_thres=0.45, max_det=1000)
    
    # ç»Ÿè®¡æ£€æµ‹ç»“æœ
    detections = []
    for i, det in enumerate(pred):
        if len(det):
            # åæ ‡ç¼©æ”¾å›åŸå›¾å°ºå¯¸
            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()
            detections.append(det)
        else:
            detections.append(jt.empty((0, 6)))
    
    # è¾“å‡ºæ£€æµ‹ç»“æœ
    num_det = len(detections[0]) if len(detections) > 0 and len(detections[0]) > 0 else 0
    print(f"ğŸ¯ æ£€æµ‹ç»“æœ: {num_det} ä¸ªç›®æ ‡")
    
    if num_det > 0:
        det = detections[0]
        if hasattr(det, 'numpy'):
            det = det.numpy()
        
        for i, (*xyxy, conf, cls) in enumerate(det):
            print(f"   ç›®æ ‡ {i+1}: ç±»åˆ«={int(cls)}, ç½®ä¿¡åº¦={conf:.3f}, åæ ‡=[{xyxy[0]:.1f}, {xyxy[1]:.1f}, {xyxy[2]:.1f}, {xyxy[3]:.1f}]")
        
        # ä¿å­˜å¯è§†åŒ–ç»“æœ
        img_vis = img0.copy()
        colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255)]
        
        for i, (*xyxy, conf, cls) in enumerate(det):
            if conf >= 0.01:
                x1, y1, x2, y2 = map(int, xyxy)
                color = colors[i % len(colors)]
                
                cv2.rectangle(img_vis, (x1, y1), (x2, y2), color, 2)
                label = f'Class{int(cls)} {conf:.2f}'
                cv2.putText(img_vis, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        cv2.imwrite('self_check_result.jpg', img_vis)
        print(f"ğŸ“¸ å¯è§†åŒ–ç»“æœå·²ä¿å­˜: self_check_result.jpg")
        
        print("ğŸ‰ è‡ªæ£€éªŒè¯æˆåŠŸï¼æ¨¡å‹èƒ½å¤Ÿæ£€æµ‹åˆ°ç›®æ ‡ï¼")
        return True
    else:
        print("âš ï¸ è‡ªæ£€éªŒè¯å¤±è´¥ï¼šæ¨¡å‹æœªæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡")
        return False

if __name__ == "__main__":
    success = self_check_training()
    if success:
        print("\nâœ… è‡ªæ£€è®­ç»ƒéªŒè¯å®Œæˆï¼æ¨¡å‹åŠŸèƒ½æ­£å¸¸ï¼")
    else:
        print("\nâŒ è‡ªæ£€è®­ç»ƒéªŒè¯å¤±è´¥ï¼éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•ï¼")
