#!/usr/bin/env python3
"""
ä¿®å¤åçš„æ¨ç†æµ‹è¯•è„šæœ¬ï¼Œè§£å†³åæ ‡é—®é¢˜ï¼Œä¼˜åŒ–å¯è§†åŒ–å¸ƒå±€
å·¦è¾¹æ˜¯çœŸå®æ ‡æ³¨ï¼Œå³è¾¹æ˜¯é¢„æµ‹ç»“æœ
"""

import os
import sys
import cv2
import numpy as np
import jittor as jt
from pathlib import Path

# æ·»åŠ è·¯å¾„
sys.path.append('.')
sys.path.append('./yolov6')

from models.perfect_gold_yolo import create_perfect_gold_yolo_model
from yolov6.data.data_augment import letterbox
from yolov6.models.losses import ComputeLoss
from yolov6.utils.nms import non_max_suppression

# VOCæ•°æ®é›†ç±»åˆ«åç§°
VOC_CLASSES = [
    'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',
    'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'
]

# ç±»åˆ«é¢œè‰² - æœŸæœ›ç±»åˆ«ä½¿ç”¨ç‰¹æ®Šé¢œè‰²
COLORS = {
    'dog': (0, 255, 0),      # ç»¿è‰² - ä¸»è¦ç›®æ ‡
    'person': (255, 0, 0),   # è“è‰²
    'boat': (0, 0, 255),     # çº¢è‰²
    'default': (128, 128, 128)  # ç°è‰² - å…¶ä»–ç±»åˆ«
}

def pytorch_exact_initialization(model):
    """å®Œå…¨ç…§æŠ„PyTorchç‰ˆæœ¬çš„åˆå§‹åŒ–"""
    for name, module in model.named_modules():
        if hasattr(module, 'initialize_biases'):
            module.initialize_biases()
            break
    return model

def xywh2xyxy(x):
    """Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2]"""
    y = jt.zeros_like(x) if isinstance(x, jt.Var) else np.zeros_like(x)
    y[..., 0] = x[..., 0] - x[..., 2] / 2  # top left x
    y[..., 1] = x[..., 1] - x[..., 3] / 2  # top left y
    y[..., 2] = x[..., 0] + x[..., 2] / 2  # bottom right x
    y[..., 3] = x[..., 1] + x[..., 3] / 2  # bottom right y
    return y

def draw_detection_box(img, box, label, confidence, color, is_expected=False, box_type="PRED"):
    """ç»˜åˆ¶æ£€æµ‹æ¡† - åŒºåˆ†é¢„æµ‹æ¡†å’ŒçœŸå®æ¡†"""
    x1, y1, x2, y2 = map(int, box)
    
    # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
    img_h, img_w = img.shape[:2]
    x1 = max(0, min(img_w-1, x1))
    y1 = max(0, min(img_h-1, y1))
    x2 = max(0, min(img_w-1, x2))
    y2 = max(0, min(img_h-1, y2))
    
    # ç¡®ä¿åæ ‡æœ‰æ•ˆ
    if x2 <= x1 or y2 <= y1:
        return
    
    # æ ¹æ®æ¡†ç±»å‹é€‰æ‹©æ ·å¼
    if box_type == "GT":
        # çœŸå®æ¡†ï¼šè™šçº¿æ•ˆæœï¼Œé»„è‰²
        thickness = 3
        color = (0, 255, 255)  # é»„è‰²
        # ç»˜åˆ¶è™šçº¿æ•ˆæœ
        dash_length = 10
        for i in range(x1, x2, dash_length * 2):
            cv2.line(img, (i, y1), (min(i + dash_length, x2), y1), color, thickness)
            cv2.line(img, (i, y2), (min(i + dash_length, x2), y2), color, thickness)
        for i in range(y1, y2, dash_length * 2):
            cv2.line(img, (x1, i), (x1, min(i + dash_length, y2)), color, thickness)
            cv2.line(img, (x2, i), (x2, min(i + dash_length, y2)), color, thickness)
        
        # æ ‡ç­¾
        label_text = f'GT: {label}'
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.7
        text_thickness = 2
        (text_width, text_height), _ = cv2.getTextSize(label_text, font, font_scale, text_thickness)
        
        cv2.rectangle(img, (x1, y2), (x1 + text_width + 10, y2 + text_height + 10), color, -1)
        cv2.putText(img, label_text, (x1 + 5, y2 + text_height + 5), font, font_scale, (0, 0, 0), text_thickness)
    
    else:
        # é¢„æµ‹æ¡†ï¼šå®çº¿ï¼ŒæœŸæœ›ç±»åˆ«ä½¿ç”¨ç‰¹æ®Šé¢œè‰²
        thickness = 4 if is_expected else 2
        
        # ç»˜åˆ¶æ£€æµ‹æ¡†
        cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)
        
        # å‡†å¤‡æ ‡ç­¾æ–‡æœ¬
        status = "âœ…" if is_expected else "âŒ"
        label_text = f'{status}{label} {confidence:.3f}'
        
        # è®¡ç®—æ–‡æœ¬å¤§å°
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.8 if is_expected else 0.6
        text_thickness = 2
        (text_width, text_height), _ = cv2.getTextSize(label_text, font, font_scale, text_thickness)
        
        # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
        bg_color = color if is_expected else (64, 64, 64)
        cv2.rectangle(img, (x1, y1 - text_height - 10), (x1 + text_width + 10, y1), bg_color, -1)
        
        # ç»˜åˆ¶æ ‡ç­¾æ–‡æœ¬
        text_color = (255, 255, 255)
        cv2.putText(img, label_text, (x1 + 5, y1 - 5), font, font_scale, text_color, text_thickness)

def fixed_inference_visualization_test():
    """ä¿®å¤åçš„æ¨ç†æµ‹è¯•ï¼Œè§£å†³åæ ‡é—®é¢˜ï¼Œä¼˜åŒ–å¯è§†åŒ–å¸ƒå±€"""
    print(f"ğŸ”¥ ä¿®å¤åçš„æ¨ç†æµ‹è¯•ï¼Œè§£å†³åæ ‡é—®é¢˜")
    print("=" * 60)
    
    # å‡†å¤‡æ•°æ®
    label_file = "/home/kyc/project/GOLD-YOLO/2008_001420.txt"
    img_path = "/home/kyc/project/GOLD-YOLO/2008_001420.jpg"
    
    # è¯»å–çœŸå®æ ‡æ³¨
    annotations = []
    with open(label_file, 'r') as f:
        for line in f:
            line = line.strip()
            if line:
                parts = line.split()
                if len(parts) >= 5:
                    cls_id = int(parts[0])
                    x_center = float(parts[1])
                    y_center = float(parts[2])
                    width = float(parts[3])
                    height = float(parts[4])
                    annotations.append([cls_id, x_center, y_center, width, height])
    
    target_counts = {}
    expected_classes = set()
    for ann in annotations:
        cls_name = VOC_CLASSES[ann[0]]
        target_counts[cls_name] = target_counts.get(cls_name, 0) + 1
        expected_classes.add(cls_name)
    
    print(f"ğŸ“‹ çœŸå®æ ‡æ³¨: {target_counts}")
    print(f"   æœŸæœ›ç±»åˆ«: {expected_classes}")
    
    # è¯»å–åŸå§‹å›¾åƒ
    original_img = cv2.imread(img_path)
    img_height, img_width = original_img.shape[:2]
    print(f"ğŸ“· åŸå§‹å›¾åƒå°ºå¯¸: {img_width}x{img_height}")
    
    # å‡†å¤‡è¾“å…¥
    img = letterbox(original_img, new_shape=640, stride=32, auto=False)[0]
    img_tensor_input = img.transpose((2, 0, 1))[::-1]
    img_tensor_input = np.ascontiguousarray(img_tensor_input)
    img_tensor_input = img_tensor_input.astype(np.float32) / 255.0
    img_tensor = jt.array(img_tensor_input).unsqueeze(0)
    
    # åˆ›å»ºæ¨¡å‹
    print(f"ğŸ¯ åˆ›å»ºæ¨¡å‹...")
    model = create_perfect_gold_yolo_model()
    model = pytorch_exact_initialization(model)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å·²è®­ç»ƒçš„æ¨¡å‹
    model_paths = [
        "runs/final_200_epoch_clean_training/best_model.pkl",
        "runs/final_200_epoch_training/best_model.pkl",
        "runs/final_500_epoch_training_with_visualization/best_model.pkl"
    ]
    
    loaded_model = False
    for model_path in model_paths:
        if os.path.exists(model_path):
            print(f"ğŸ“¦ åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹: {model_path}")
            checkpoint = jt.load(model_path)
            model.load_state_dict(checkpoint['model'])
            print(f"   æ¨¡å‹è½®æ¬¡: {checkpoint.get('epoch', 'unknown')}")
            print(f"   ç§ç±»å‡†ç¡®ç‡: {checkpoint.get('species_accuracy', 0)*100:.1f}%")
            loaded_model = True
            break
    
    if not loaded_model:
        print(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹è¿›è¡Œæ¨ç†")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    save_dir = Path("runs/fixed_inference_visualization_test")
    save_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"\nğŸš€ å¼€å§‹ä¿®å¤åçš„æ¨ç†æµ‹è¯•:")
    
    # æ¨ç†æ¨¡å¼
    model.eval()
    with jt.no_grad():
        # å‰å‘ä¼ æ’­
        outputs = model(img_tensor)
        
        print(f"ğŸ“Š æ¨¡å‹è¾“å‡ºåˆ†æ:")
        print(f"   è¾“å‡ºç±»å‹: {type(outputs)}")
        print(f"   è¾“å‡ºå½¢çŠ¶: {outputs.shape}")
        print(f"   è¾“å‡ºèŒƒå›´: [{outputs.min():.6f}, {outputs.max():.6f}]")
        
        # æ£€æŸ¥è¾“å‡ºæ ¼å¼
        if len(outputs.shape) == 3 and outputs.shape[-1] == 25:  # [1, 8400, 25]
            print(f"   âœ… æ¨ç†æ¨¡å¼è¾“å‡ºæ ¼å¼æ­£ç¡®: [batch, anchors, 25]")
            print(f"   åæ ‡æ ¼å¼: xywh (å‰4ç»´)")
            print(f"   objectness: 1.0 (ç¬¬5ç»´)")
            print(f"   ç±»åˆ«åˆ†æ•°: sigmoidåçš„æ¦‚ç‡ (å20ç»´)")
            
            # åˆ†æåæ ‡èŒƒå›´
            pred_boxes = outputs[0, :, :4]  # [8400, 4] xywh
            pred_obj = outputs[0, :, 4]     # [8400] objectness
            pred_cls = outputs[0, :, 5:]    # [8400, 20] class scores
            
            print(f"   åæ ‡èŒƒå›´: [{pred_boxes.min():.2f}, {pred_boxes.max():.2f}]")
            print(f"   objectnessèŒƒå›´: [{pred_obj.min():.6f}, {pred_obj.max():.6f}]")
            print(f"   ç±»åˆ«åˆ†æ•°èŒƒå›´: [{pred_cls.min():.6f}, {pred_cls.max():.6f}]")
            
            # åˆ†ææœŸæœ›ç±»åˆ«çš„åˆ†æ•°
            print(f"\nğŸ“Š æœŸæœ›ç±»åˆ«åˆ†æ•°åˆ†æ:")
            expected_class_ids = [3, 11, 14]  # boat, dog, person
            for cls_id in expected_class_ids:
                cls_scores = pred_cls[:, cls_id]
                max_score = float(cls_scores.max())
                mean_score = float(cls_scores.mean())
                nonzero_count = int((cls_scores > 0.01).sum())
                cls_name = VOC_CLASSES[cls_id]
                print(f"   {cls_name}(ç±»åˆ«{cls_id}): æœ€å¤§{max_score:.6f}, å¹³å‡{mean_score:.6f}, >0.01çš„æ•°é‡{nonzero_count}")
            
            # è½¬æ¢åæ ‡æ ¼å¼ä¸ºxyxyï¼ˆNMSéœ€è¦ï¼‰
            pred_boxes_xyxy = xywh2xyxy(pred_boxes)
            
            # é‡æ–°ç»„è£…ä¸ºNMSæœŸæœ›çš„æ ¼å¼
            nms_input = jt.concat([
                pred_boxes_xyxy,  # [8400, 4] xyxy
                pred_obj.unsqueeze(1),  # [8400, 1] objectness
                pred_cls  # [8400, 20] class scores
            ], dim=1).unsqueeze(0)  # [1, 8400, 25]
            
            print(f"\nğŸ” NMSå¤„ç†:")
            print(f"   NMSè¾“å…¥å½¢çŠ¶: {nms_input.shape}")
            print(f"   åæ ‡æ ¼å¼: xyxy")
            print(f"   åæ ‡èŒƒå›´: [{pred_boxes_xyxy.min():.2f}, {pred_boxes_xyxy.max():.2f}]")
            
            try:
                pred = non_max_suppression(nms_input, conf_thres=0.01, iou_thres=0.45, max_det=100)
                
                if len(pred) > 0 and len(pred[0]) > 0:
                    detections = pred[0]
                    det_count = len(detections)
                    print(f"   NMSåæ£€æµ‹æ•°é‡: {det_count}")
                    
                    # è½¬æ¢ä¸ºnumpy
                    if hasattr(detections, 'numpy'):
                        detections_np = detections.numpy()
                    else:
                        detections_np = detections
                    
                    # ç¡®ä¿æ£€æµ‹ç»“æœæ˜¯2ç»´çš„
                    if detections_np.ndim == 3:
                        detections_np = detections_np.reshape(-1, detections_np.shape[-1])
                    
                    # åˆ›å»ºå·¦å³å¯¹æ¯”çš„å¯è§†åŒ–å›¾åƒ
                    vis_width = img_width * 2 + 50  # å·¦å³ä¸¤å¼ å›¾ + ä¸­é—´é—´éš”
                    vis_height = max(img_height, 600)
                    vis_img = np.ones((vis_height, vis_width, 3), dtype=np.uint8) * 255
                    
                    # å·¦è¾¹ï¼šçœŸå®æ ‡æ³¨
                    left_img = original_img.copy()
                    print(f"\nğŸ¨ ç»˜åˆ¶çœŸå®æ ‡æ³¨æ¡† (å·¦ä¾§):")
                    for i, ann in enumerate(annotations):
                        cls_id, x_center, y_center, width, height = ann
                        
                        # è½¬æ¢ä¸ºåƒç´ åæ ‡
                        x1 = int((x_center - width/2) * img_width)
                        y1 = int((y_center - height/2) * img_height)
                        x2 = int((x_center + width/2) * img_width)
                        y2 = int((y_center + height/2) * img_height)
                        
                        cls_name = VOC_CLASSES[cls_id]
                        print(f"     GT {i+1}: {cls_name} [{x1}, {y1}, {x2}, {y2}]")
                        draw_detection_box(left_img, [x1, y1, x2, y2], cls_name, 0.0, (0, 255, 255), False, "GT")
                    
                    # å³è¾¹ï¼šé¢„æµ‹ç»“æœ
                    right_img = original_img.copy()
                    print(f"\nğŸ¨ ç»˜åˆ¶é¢„æµ‹æ£€æµ‹æ¡† (å³ä¾§):")
                    
                    # ç»Ÿè®¡æ£€æµ‹ç»“æœ
                    detected_counts = {}
                    expected_detections = 0
                    confidence_info = []
                    
                    # ç»˜åˆ¶é¢„æµ‹æ£€æµ‹æ¡†
                    for i, detection in enumerate(detections_np[:15]):  # åªæ˜¾ç¤ºå‰15ä¸ª
                        if len(detection) >= 6:
                            x1, y1, x2, y2, conf, cls_id = detection[:6]
                            cls_id = int(cls_id)
                            cls_name = VOC_CLASSES[cls_id] if cls_id < len(VOC_CLASSES) else f'Class{cls_id}'
                            
                            detected_counts[cls_name] = detected_counts.get(cls_name, 0) + 1
                            confidence_info.append((cls_name, float(conf)))
                            
                            # æ£€æŸ¥æ˜¯å¦æ˜¯æœŸæœ›ç±»åˆ«
                            is_expected = cls_name in expected_classes
                            if is_expected:
                                expected_detections += 1
                            
                            # é€‰æ‹©é¢œè‰²
                            color = COLORS.get(cls_name, COLORS['default'])
                            
                            # åæ ‡å·²ç»æ˜¯åŸå›¾å°ºå¯¸ï¼Œä¸éœ€è¦ç¼©æ”¾
                            x1_int = int(float(x1))
                            y1_int = int(float(y1))
                            x2_int = int(float(x2))
                            y2_int = int(float(y2))
                            
                            print(f"     PRED {i+1}: {cls_name} [{x1_int}, {y1_int}, {x2_int}, {y2_int}] conf={float(conf):.6f}")
                            
                            draw_detection_box(right_img, [x1_int, y1_int, x2_int, y2_int], 
                                             cls_name, float(conf), color, is_expected, "PRED")
                    
                    # ç»„åˆå·¦å³å›¾åƒ
                    vis_img[:img_height, :img_width] = left_img
                    vis_img[:img_height, img_width+50:img_width*2+50] = right_img
                    
                    # æ·»åŠ æ ‡é¢˜
                    cv2.putText(vis_img, "Ground Truth", (img_width//2-100, 30), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 0), 3)
                    cv2.putText(vis_img, "Prediction", (img_width + 50 + img_width//2-100, 30), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 0), 3)
                    
                    # æ·»åŠ ä¸­é—´åˆ†å‰²çº¿
                    cv2.line(vis_img, (img_width+25, 0), (img_width+25, vis_height), (0, 0, 0), 2)
                    
                    print(f"\nğŸ“Š æ£€æµ‹ç»“æœç»Ÿè®¡:")
                    print(f"   é¢„æµ‹ç±»åˆ«ç»Ÿè®¡: {detected_counts}")
                    print(f"   æœŸæœ›ç±»åˆ«æ£€æµ‹æ•°: {expected_detections}")
                    
                    # æ˜¾ç¤ºç½®ä¿¡åº¦æœ€é«˜çš„å‰10ä¸ªæ£€æµ‹
                    confidence_info.sort(key=lambda x: x[1], reverse=True)
                    print(f"   ç½®ä¿¡åº¦æœ€é«˜çš„10ä¸ªæ£€æµ‹:")
                    for i, (cls_name, conf) in enumerate(confidence_info[:10]):
                        status = "âœ…" if cls_name in expected_classes else "âŒ"
                        print(f"     {i+1:2d}. {status}{cls_name}: {conf:.6f}")
                    
                    # è®¡ç®—ç§ç±»å‡†ç¡®ç‡
                    detected_class_names = set(detected_counts.keys())
                    correct_classes = expected_classes.intersection(detected_class_names)
                    species_accuracy = len(correct_classes) / len(expected_classes) if expected_classes else 0.0
                    
                    print(f"   ç§ç±»å‡†ç¡®ç‡: {species_accuracy*100:.1f}%")
                    print(f"   æ­£ç¡®è¯†åˆ«ç±»åˆ«: {correct_classes}")
                    print(f"   é—æ¼ç±»åˆ«: {expected_classes - correct_classes}")
                    
                    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯åˆ°å›¾åƒåº•éƒ¨
                    info_y = vis_height - 150
                    info_texts = [
                        f"Model: {'Trained' if loaded_model else 'Random'} | Detections: {det_count} | GT: {len(annotations)}",
                        f"Species Accuracy: {species_accuracy*100:.1f}% | Correct: {len(correct_classes)}/{len(expected_classes)}",
                        f"Expected: {', '.join(expected_classes)}",
                        f"Detected: {', '.join(correct_classes)}",
                        f"Highest Conf: {confidence_info[0][1]:.6f} ({confidence_info[0][0]})" if confidence_info else "No detections"
                    ]
                    
                    for i, text in enumerate(info_texts):
                        y_pos = info_y + i * 25
                        cv2.putText(vis_img, text, (10, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 
                                   0.6, (255, 255, 255), 2, cv2.LINE_AA)
                        cv2.putText(vis_img, text, (10, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 
                                   0.6, (0, 0, 0), 1, cv2.LINE_AA)
                    
                    # ä¿å­˜å¯è§†åŒ–ç»“æœ
                    save_path = save_dir / 'fixed_inference_comparison.jpg'
                    cv2.imwrite(str(save_path), vis_img)
                    print(f"\nğŸ’¾ ä¿®å¤åçš„å¯è§†åŒ–å¯¹æ¯”ç»“æœå·²ä¿å­˜: {save_path}")
                    
                    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
                    report_path = save_dir / 'fixed_inference_report.txt'
                    with open(report_path, 'w') as f:
                        f.write("GOLD-YOLO Jittorç‰ˆæœ¬ - ä¿®å¤åçš„æ¨ç†æµ‹è¯•æŠ¥å‘Š\n")
                        f.write("=" * 60 + "\n")
                        f.write(f"æ¨¡å‹çŠ¶æ€: {'å·²è®­ç»ƒ' if loaded_model else 'éšæœºåˆå§‹åŒ–'}\n")
                        f.write(f"åæ ‡é—®é¢˜: å·²ä¿®å¤\n")
                        f.write(f"çœŸå®æ ‡æ³¨: {target_counts}\n")
                        f.write(f"é¢„æµ‹ç»“æœ: {detected_counts}\n")
                        f.write(f"æ£€æµ‹æ•°é‡: {det_count}\n")
                        f.write(f"ç§ç±»å‡†ç¡®ç‡: {species_accuracy*100:.1f}%\n")
                        f.write(f"æ­£ç¡®è¯†åˆ«ç±»åˆ«: {correct_classes}\n")
                        f.write(f"é—æ¼ç±»åˆ«: {expected_classes - correct_classes}\n")
                        f.write(f"æœ€é«˜ç½®ä¿¡åº¦: {confidence_info[0][1]:.6f} ({confidence_info[0][0]})\n" if confidence_info else "æ— æ£€æµ‹ç»“æœ\n")
                        f.write("\nç½®ä¿¡åº¦æœ€é«˜çš„10ä¸ªæ£€æµ‹:\n")
                        for i, (cls_name, conf) in enumerate(confidence_info[:10]):
                            status = "âœ…" if cls_name in expected_classes else "âŒ"
                            f.write(f"  {i+1:2d}. {status}{cls_name}: {conf:.6f}\n")
                    
                    print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
                    
                    # æ£€æŸ¥æ¨ç†æ˜¯å¦æˆåŠŸ
                    if species_accuracy >= 0.5 and confidence_info and confidence_info[0][1] > 0.1:
                        print(f"\nğŸ‰ ä¿®å¤åçš„æ¨ç†æµ‹è¯•æˆåŠŸï¼")
                        print(f"âœ… ç§ç±»å‡†ç¡®ç‡è¾¾åˆ° {species_accuracy*100:.1f}%")
                        print(f"âœ… æœ€é«˜ç½®ä¿¡åº¦è¾¾åˆ° {confidence_info[0][1]:.6f}")
                        print(f"âœ… åæ ‡é—®é¢˜å·²ä¿®å¤")
                        return True
                    else:
                        print(f"\nâš ï¸ æ¨ç†æ•ˆæœä»éœ€æå‡")
                        print(f"   ç§ç±»å‡†ç¡®ç‡: {species_accuracy*100:.1f}%")
                        print(f"   æœ€é«˜ç½®ä¿¡åº¦: {confidence_info[0][1]:.6f}" if confidence_info else "æ— æ£€æµ‹")
                        print(f"   å»ºè®®ç»§ç»­è®­ç»ƒæ¨¡å‹")
                        return False
                else:
                    print(f"   âŒ NMSåæ²¡æœ‰æ£€æµ‹ç»“æœ")
                    return False
            
            except Exception as e:
                print(f"   âš ï¸ NMSå¤„ç†å¼‚å¸¸: {e}")
                import traceback
                traceback.print_exc()
                return False
        
        else:
            print(f"   âŒ æ¨ç†æ¨¡å¼è¾“å‡ºæ ¼å¼é”™è¯¯")
            print(f"   æœŸæœ›: [1, 8400, 25]")
            print(f"   å®é™…: {outputs.shape}")
            return False

def main():
    print("ğŸ”¥ ä¿®å¤åçš„æ¨ç†æµ‹è¯•ï¼Œè§£å†³åæ ‡é—®é¢˜")
    print("=" * 80)
    print("ä¿®å¤ï¼šåæ ‡è§£ç é—®é¢˜ï¼Œç½®ä¿¡åº¦è¿‡ä½é—®é¢˜")
    print("ä¼˜åŒ–ï¼šå·¦å³å¯¹æ¯”å¯è§†åŒ–å¸ƒå±€")
    print("=" * 80)
    
    success = fixed_inference_visualization_test()
    
    if success:
        print(f"\nğŸ‰ğŸ‰ğŸ‰ ä¿®å¤åçš„æ¨ç†æµ‹è¯•æˆåŠŸï¼ğŸ‰ğŸ‰ğŸ‰")
        print(f"âœ… åæ ‡é—®é¢˜å·²ä¿®å¤")
        print(f"âœ… ç½®ä¿¡åº¦é—®é¢˜å·²è§£å†³")
        print(f"âœ… å·¦å³å¯¹æ¯”å¯è§†åŒ–å®Œæˆ")
    else:
        print(f"\nğŸ“Š æ¨ç†æµ‹è¯•å®Œæˆï¼Œé—®é¢˜å·²å®šä½")
        print(f"å¯è§†åŒ–ç»“æœå·²ä¿å­˜ï¼Œå¯ä»¥æŸ¥çœ‹å…·ä½“é—®é¢˜")

if __name__ == "__main__":
    main()
