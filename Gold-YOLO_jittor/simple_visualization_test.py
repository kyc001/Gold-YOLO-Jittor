#!/usr/bin/env python3
"""
ç®€åŒ–çš„å¯è§†åŒ–æµ‹è¯•è„šæœ¬
"""

import os
import sys
import cv2
import numpy as np
import jittor as jt
from pathlib import Path

# æ·»åŠ è·¯å¾„
sys.path.append('.')
sys.path.append('./yolov6')

from models.perfect_gold_yolo import create_perfect_gold_yolo_model
from yolov6.data.data_augment import letterbox
from yolov6.models.losses import ComputeLoss
from yolov6.utils.nms import non_max_suppression

# VOCæ•°æ®é›†ç±»åˆ«åç§°
VOC_CLASSES = [
    'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',
    'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'
]

def pytorch_exact_initialization(model):
    """å®Œå…¨ç…§æŠ„PyTorchç‰ˆæœ¬çš„åˆå§‹åŒ–"""
    for name, module in model.named_modules():
        if hasattr(module, 'initialize_biases'):
            module.initialize_biases()
            break
    return model

def simple_visualization_test():
    """ç®€åŒ–çš„å¯è§†åŒ–æµ‹è¯•"""
    print(f"ğŸ”§ ç®€åŒ–çš„å¯è§†åŒ–æµ‹è¯•")
    print("=" * 50)
    
    # å‡†å¤‡æ•°æ®
    label_file = "/home/kyc/project/GOLD-YOLO/2008_001420.txt"
    img_path = "/home/kyc/project/GOLD-YOLO/2008_001420.jpg"
    
    # è¯»å–çœŸå®æ ‡æ³¨
    annotations = []
    with open(label_file, 'r') as f:
        for line in f:
            line = line.strip()
            if line:
                parts = line.split()
                if len(parts) >= 5:
                    cls_id = int(parts[0])
                    x_center = float(parts[1])
                    y_center = float(parts[2])
                    width = float(parts[3])
                    height = float(parts[4])
                    annotations.append([cls_id, x_center, y_center, width, height])
    
    target_counts = {}
    for ann in annotations:
        cls_name = VOC_CLASSES[ann[0]]
        target_counts[cls_name] = target_counts.get(cls_name, 0) + 1
    
    print(f"ğŸ“‹ æœŸæœ›æ£€æµ‹ç»“æœ: {target_counts}")
    print(f"   æ€»ç›®æ ‡æ•°: {len(annotations)}")
    
    # å‡†å¤‡è¾“å…¥
    original_img = cv2.imread(img_path)
    img = letterbox(original_img, new_shape=640, stride=32, auto=False)[0]
    img = img.transpose((2, 0, 1))[::-1]
    img = np.ascontiguousarray(img)
    img = img.astype(np.float32) / 255.0
    img_tensor = jt.array(img).unsqueeze(0)
    
    # å‡†å¤‡æ ‡ç­¾
    targets = []
    for ann in annotations:
        cls_id, x_center, y_center, width, height = ann
        targets.append([0, cls_id, x_center, y_center, width, height])
    targets_tensor = jt.array(targets, dtype=jt.float32).unsqueeze(0)
    
    # åˆ›å»ºæ¨¡å‹
    model = create_perfect_gold_yolo_model()
    model = pytorch_exact_initialization(model)
    model.train()
    
    # åˆ›å»ºæŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    loss_fn = ComputeLoss(
        num_classes=20,
        ori_img_size=640,
        warmup_epoch=4,
        use_dfl=False,
        reg_max=0,
        iou_type='giou',
        loss_weight={'class': 1.0, 'iou': 2.5, 'dfl': 0.5}
    )
    optimizer = jt.optim.AdamW(model.parameters(), lr=0.05)
    
    print(f"\nğŸš€ å¿«é€Ÿè®­ç»ƒ100è½®:")
    
    # è®­ç»ƒå¾ªç¯
    for epoch in range(100):
        # å‰å‘ä¼ æ’­
        outputs = model(img_tensor)
        
        # è®¡ç®—æŸå¤±
        loss, loss_items = loss_fn(outputs, targets_tensor, epoch_num=epoch+1, step_num=1)
        
        # ä¼˜åŒ–
        optimizer.step(loss)
        
        epoch_loss = float(loss.numpy())
        
        # æ¯25è½®æ£€æµ‹ä¸€æ¬¡
        if (epoch + 1) % 25 == 0:
            print(f"\n   Epoch {epoch+1}: Loss {epoch_loss:.6f}")
            
            # æ£€æµ‹æµ‹è¯•
            model.eval()
            with jt.no_grad():
                test_outputs = model(img_tensor)
                
                # æ£€æŸ¥æœŸæœ›ç±»åˆ«çš„åˆ†æ•°
                coords = test_outputs[..., :4]
                objectness = test_outputs[..., 4]
                classes = test_outputs[..., 5:]
                
                expected_classes = [3, 11, 14]  # boat, dog, person
                print(f"     æœŸæœ›ç±»åˆ«åˆ†æ•°:")
                for cls_id in expected_classes:
                    cls_scores = classes[0, :, cls_id]
                    max_score = float(cls_scores.max())
                    print(f"       {VOC_CLASSES[cls_id]}(ç±»åˆ«{cls_id}): æœ€å¤§{max_score:.6f}")
                
                # NMSå¤„ç†
                pred = non_max_suppression(test_outputs, conf_thres=0.01, iou_thres=0.45, max_det=100)
                
                if len(pred) > 0 and len(pred[0]) > 0:
                    detections = pred[0]
                    det_count = len(detections)
                    print(f"     æ£€æµ‹æ•°é‡: {det_count}")
                    
                    # è½¬æ¢ä¸ºnumpy
                    if hasattr(detections, 'numpy'):
                        detections_np = detections.numpy()
                    else:
                        detections_np = detections
                    
                    # ç¡®ä¿æ£€æµ‹ç»“æœæ˜¯2ç»´çš„
                    if detections_np.ndim == 3:
                        detections_np = detections_np.reshape(-1, detections_np.shape[-1])
                    
                    # ç»Ÿè®¡æ£€æµ‹åˆ°çš„ç±»åˆ«
                    detected_counts = {}
                    confidence_info = []
                    
                    for detection in detections_np:
                        if len(detection) >= 6:
                            conf = float(detection[4])
                            cls_id = int(detection[5])
                            cls_name = VOC_CLASSES[cls_id] if cls_id < len(VOC_CLASSES) else f'Class{cls_id}'
                            
                            detected_counts[cls_name] = detected_counts.get(cls_name, 0) + 1
                            confidence_info.append((cls_name, conf))
                    
                    print(f"     æ£€æµ‹ç±»åˆ«: {detected_counts}")
                    
                    # æ˜¾ç¤ºç½®ä¿¡åº¦æœ€é«˜çš„å‰5ä¸ªæ£€æµ‹
                    confidence_info.sort(key=lambda x: x[1], reverse=True)
                    print(f"     ç½®ä¿¡åº¦æœ€é«˜çš„5ä¸ªæ£€æµ‹:")
                    for i, (cls_name, conf) in enumerate(confidence_info[:5]):
                        print(f"       {i+1}. {cls_name}: {conf:.6f}")
                    
                    # æ£€æŸ¥æ˜¯å¦æ£€æµ‹åˆ°æœŸæœ›ç±»åˆ«
                    expected_class_names = set(target_counts.keys())
                    detected_class_names = set(detected_counts.keys())
                    correct_classes = expected_class_names.intersection(detected_class_names)
                    
                    if len(correct_classes) > 0:
                        print(f"     âœ… æ£€æµ‹åˆ°æ­£ç¡®ç±»åˆ«: {correct_classes}")
                        species_accuracy = len(correct_classes) / len(expected_class_names)
                        print(f"     ç§ç±»å‡†ç¡®ç‡: {species_accuracy*100:.1f}%")
                        
                        if species_accuracy >= 0.8:
                            print(f"\nğŸ‰ ç§ç±»è¯†åˆ«æˆåŠŸï¼å¯ä»¥å¼€å§‹200è½®å®Œæ•´è®­ç»ƒï¼")
                            return True
                    else:
                        expected_class_names_list = list(expected_class_names)
                        print(f"     âŒ æœªæ£€æµ‹åˆ°æ­£ç¡®ç±»åˆ«ï¼ŒæœŸæœ›: {expected_class_names_list}")
                else:
                    print(f"     âŒ æ²¡æœ‰æ£€æµ‹ç»“æœ")
            
            model.train()
    
    print(f"\nâš ï¸ 100è½®è®­ç»ƒå®Œæˆ")
    return False

def main():
    print("ğŸ”¥ ç®€åŒ–çš„å¯è§†åŒ–æµ‹è¯•è„šæœ¬")
    print("=" * 70)
    print("åŠŸèƒ½ï¼šæµ‹è¯•æ£€æµ‹ç»“æœï¼Œåˆ†æç½®ä¿¡åº¦å’Œæ•°é‡é—®é¢˜")
    print("=" * 70)
    
    success = simple_visualization_test()
    
    if success:
        print(f"\nğŸ‰ğŸ‰ğŸ‰ æµ‹è¯•æˆåŠŸï¼ğŸ‰ğŸ‰ğŸ‰")
        print(f"âœ… æ£€æµ‹ç»“æœæ­£å¸¸")
        print(f"âœ… ç½®ä¿¡åº¦åˆ†æå®Œæ•´")
        print(f"âœ… å¯ä»¥å¼€å§‹200è½®å®Œæ•´è®­ç»ƒ")
    else:
        print(f"\nâš ï¸ éœ€è¦è¿›ä¸€æ­¥åˆ†æç½®ä¿¡åº¦é—®é¢˜")

if __name__ == "__main__":
    main()
