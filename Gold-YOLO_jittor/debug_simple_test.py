#!/usr/bin/env python3
"""
ç®€å•æµ‹è¯•è®­ç»ƒå‰åçš„å·®å¼‚
"""

import sys
import os
sys.path.insert(0, '/home/kyc/project/GOLD-YOLO/Gold-YOLO_jittor')

import jittor as jt
import numpy as np

# è®¾ç½®Jittor
jt.flags.use_cuda = 1

def simple_test():
    """ç®€å•æµ‹è¯•"""
    
    try:
        from models.yolo import Model
        from configs.gold_yolo_s import get_config
        from models.loss import GoldYOLOLoss
        
        print("ğŸ” ç®€å•æµ‹è¯•è®­ç»ƒå‰åå·®å¼‚")
        print("=" * 60)
        
        # åŠ è½½é…ç½®å’Œæ¨¡å‹
        config = get_config()
        model = Model(config=config, channels=3, num_classes=80)
        criterion = GoldYOLOLoss(num_classes=80)
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        img_tensor = jt.randn(1, 3, 640, 640)
        
        # åˆ›å»ºç›®æ ‡
        batch = {
            'cls': jt.array([[23, 24]]).long(),
            'bboxes': jt.array([[[0.304, 0.317, 0.454, 0.564],
                                 [0.255, 0.157, 0.603, 0.681]]])
        }
        
        def test_model_output(model, label):
            """æµ‹è¯•æ¨¡å‹è¾“å‡º"""
            model.eval()
            with jt.no_grad():
                outputs = model(img_tensor)
            
            print(f"\n{label}:")
            print(f"  è¾“å‡ºå½¢çŠ¶: {outputs.shape}")
            
            # åˆ†æç½®ä¿¡åº¦
            conf = outputs[0, :, 4]
            print(f"  ç½®ä¿¡åº¦èŒƒå›´: [{conf.min().item():.6f}, {conf.max().item():.6f}]")
            print(f"  ç½®ä¿¡åº¦å‡å€¼: {conf.mean().item():.6f}")
            print(f"  ç½®ä¿¡åº¦>0.1: {(conf > 0.1).sum().item()}")
            print(f"  ç½®ä¿¡åº¦>0.3: {(conf > 0.3).sum().item()}")
            print(f"  ç½®ä¿¡åº¦>0.5: {(conf > 0.5).sum().item()}")
            
            # åˆ†æç±»åˆ«é¢„æµ‹
            cls_scores = outputs[0, :, 5:]
            max_cls_scores = jt.max(cls_scores, dim=1)[0]
            max_cls_indices = jt.argmax(cls_scores, dim=1)[0]
            
            print(f"  ç±»åˆ«åˆ†æ•°èŒƒå›´: [{cls_scores.min().item():.6f}, {cls_scores.max().item():.6f}]")
            print(f"  æœ€é«˜ç±»åˆ«åˆ†æ•°: {max_cls_scores.max().item():.6f}")
            
            # ç»Ÿè®¡é¢„æµ‹çš„ç±»åˆ«åˆ†å¸ƒ
            unique_classes, counts = np.unique(max_cls_indices.numpy(), return_counts=True)
            top_classes = unique_classes[np.argsort(counts)[-3:]][::-1]
            top_counts = counts[np.argsort(counts)[-3:]][::-1]
            
            print(f"  é¢„æµ‹æœ€å¤šçš„3ä¸ªç±»åˆ«:")
            for cls_id, count in zip(top_classes, top_counts):
                print(f"    ç±»åˆ«{cls_id}: {count}æ¬¡")
            
            return outputs
        
        # 1. æµ‹è¯•è®­ç»ƒå‰
        initial_outputs = test_model_output(model, "è®­ç»ƒå‰")
        
        # 2. è¿›è¡Œç®€å•è®­ç»ƒ
        print(f"\nğŸ‹ï¸ è¿›è¡Œ10æ¬¡è®­ç»ƒ:")
        model.train()
        optimizer = jt.optim.Adam(model.parameters(), lr=0.001)
        
        for epoch in range(10):
            outputs = model(img_tensor)
            loss, loss_items = criterion(outputs, batch)
            optimizer.step(loss)
            
            if epoch % 2 == 0:
                print(f"  Epoch {epoch}: æŸå¤±={loss.item():.4f}")
        
        # 3. æµ‹è¯•è®­ç»ƒå
        trained_outputs = test_model_output(model, "è®­ç»ƒå")
        
        # 4. å¯¹æ¯”åˆ†æ
        print(f"\nğŸ“Š å¯¹æ¯”åˆ†æ:")
        
        # ç½®ä¿¡åº¦å¯¹æ¯”
        initial_conf = initial_outputs[0, :, 4]
        trained_conf = trained_outputs[0, :, 4]
        
        print(f"  ç½®ä¿¡åº¦å˜åŒ–:")
        print(f"    è®­ç»ƒå‰å‡å€¼: {initial_conf.mean().item():.6f}")
        print(f"    è®­ç»ƒåå‡å€¼: {trained_conf.mean().item():.6f}")
        print(f"    å˜åŒ–: {(trained_conf.mean() - initial_conf.mean()).item():.6f}")
        
        # ç±»åˆ«é¢„æµ‹å¯¹æ¯”
        initial_cls = initial_outputs[0, :, 5:]
        trained_cls = trained_outputs[0, :, 5:]
        
        print(f"  ç±»åˆ«é¢„æµ‹å˜åŒ–:")
        print(f"    è®­ç»ƒå‰æœ€é«˜åˆ†æ•°: {initial_cls.max().item():.6f}")
        print(f"    è®­ç»ƒåæœ€é«˜åˆ†æ•°: {trained_cls.max().item():.6f}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç›®æ ‡ç±»åˆ«23å’Œ24çš„é¢„æµ‹æå‡
        initial_cls23 = initial_cls[:, 23].mean().item()
        initial_cls24 = initial_cls[:, 24].mean().item()
        trained_cls23 = trained_cls[:, 23].mean().item()
        trained_cls24 = trained_cls[:, 24].mean().item()
        
        print(f"  ç›®æ ‡ç±»åˆ«é¢„æµ‹å˜åŒ–:")
        print(f"    ç±»åˆ«23: {initial_cls23:.6f} -> {trained_cls23:.6f} (å˜åŒ–: {trained_cls23-initial_cls23:.6f})")
        print(f"    ç±»åˆ«24: {initial_cls24:.6f} -> {trained_cls24:.6f} (å˜åŒ–: {trained_cls24-initial_cls24:.6f})")
        
        if trained_cls23 > initial_cls23 and trained_cls24 > initial_cls24:
            print("  âœ… ç›®æ ‡ç±»åˆ«é¢„æµ‹æœ‰æå‡ï¼Œæ¨¡å‹åœ¨å­¦ä¹ ï¼")
        else:
            print("  âŒ ç›®æ ‡ç±»åˆ«é¢„æµ‹æ²¡æœ‰æ˜æ˜¾æå‡")
        
        print("\n" + "=" * 60)
        print("âœ… ç®€å•æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    simple_test()
