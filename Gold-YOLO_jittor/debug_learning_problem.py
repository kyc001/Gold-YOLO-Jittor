#!/usr/bin/env python3
"""
æ·±åº¦è¯Šæ–­å­¦ä¹ é—®é¢˜
"""

import sys
import os
sys.path.insert(0, '/home/kyc/project/GOLD-YOLO/Gold-YOLO_jittor')

import jittor as jt
import numpy as np

# è®¾ç½®Jittor
jt.flags.use_cuda = 1

def diagnose_learning_problem():
    """æ·±åº¦è¯Šæ–­å­¦ä¹ é—®é¢˜"""
    
    try:
        from models.yolo import Model
        from configs.gold_yolo_s import get_config
        from models.loss import GoldYOLOLoss
        
        print("ğŸ” æ·±åº¦è¯Šæ–­Gold-YOLOå­¦ä¹ é—®é¢˜")
        print("=" * 60)
        
        # åŠ è½½é…ç½®å’Œæ¨¡å‹
        config = get_config()
        model = Model(config=config, channels=3, num_classes=80)
        criterion = GoldYOLOLoss(num_classes=80)
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        img_tensor = jt.randn(1, 3, 640, 640)
        
        # åˆ›å»ºç²¾ç¡®çš„ç›®æ ‡ - æ¨¡æ‹ŸçœŸå®çš„COCOæ•°æ®
        batch = {
            'cls': jt.array([[23, 24]]).long(),  # çœŸå®ç±»åˆ«
            'bboxes': jt.array([[[0.304, 0.317, 0.454, 0.564],  # çœŸå®è¾¹ç•Œæ¡†
                                 [0.255, 0.157, 0.603, 0.681]]])
        }
        
        print("ğŸ“Š ç›®æ ‡ä¿¡æ¯:")
        print(f"  ç±»åˆ«: {batch['cls'].numpy()}")
        print(f"  è¾¹ç•Œæ¡†: {batch['bboxes'].numpy()}")
        
        # 1. åˆ†æåˆå§‹æ¨¡å‹è¾“å‡º
        print("\nğŸ” åˆ†æåˆå§‹æ¨¡å‹è¾“å‡º:")
        model.eval()
        with jt.no_grad():
            initial_outputs = model(img_tensor)
        
        print(f"  è¾“å‡ºå½¢çŠ¶: {initial_outputs.shape}")
        print(f"  ç½®ä¿¡åº¦èŒƒå›´: [{initial_outputs[0, :, 4].min().item():.6f}, {initial_outputs[0, :, 4].max().item():.6f}]")
        
        # åˆ†æç±»åˆ«é¢„æµ‹
        cls_scores = initial_outputs[0, :, 5:]  # [8400, 80]
        max_cls_scores = jt.max(cls_scores, dim=1)[0]
        max_cls_indices = jt.argmax(cls_scores, dim=1)[0]

        print(f"  ç±»åˆ«åˆ†æ•°èŒƒå›´: [{cls_scores.min().item():.6f}, {cls_scores.max().item():.6f}]")
        print(f"  æœ€é«˜ç±»åˆ«åˆ†æ•°: {max_cls_scores.max().item():.6f}")

        # ç»Ÿè®¡é¢„æµ‹çš„ç±»åˆ«åˆ†å¸ƒ
        unique_classes, counts = np.unique(max_cls_indices.numpy(), return_counts=True)
        top_classes = unique_classes[np.argsort(counts)[-5:]][::-1]
        top_counts = counts[np.argsort(counts)[-5:]][::-1]
        
        print(f"  åˆå§‹é¢„æµ‹æœ€å¤šçš„5ä¸ªç±»åˆ«:")
        for cls_id, count in zip(top_classes, top_counts):
            print(f"    ç±»åˆ«{cls_id}: {count}æ¬¡")
        
        # 2. åˆ†ææŸå¤±è®¡ç®—
        print("\nğŸ” åˆ†ææŸå¤±è®¡ç®—:")
        model.train()
        
        # å‰å‘ä¼ æ’­
        outputs = model(img_tensor)
        print(f"  è®­ç»ƒè¾“å‡ºç±»å‹: {type(outputs)}")
        
        if isinstance(outputs, list) and len(outputs) == 2:
            detection_output, featmaps = outputs
            print(f"  æ£€æµ‹è¾“å‡ºç±»å‹: {type(detection_output)}")
            print(f"  ç‰¹å¾å›¾æ•°é‡: {len(featmaps)}")
            
            if isinstance(detection_output, tuple) and len(detection_output) == 3:
                feats, pred_scores, pred_distri = detection_output
                print(f"  ç‰¹å¾å›¾å½¢çŠ¶: {[f.shape for f in feats]}")
                print(f"  é¢„æµ‹åˆ†æ•°å½¢çŠ¶: {pred_scores.shape}")
                print(f"  é¢„æµ‹åˆ†å¸ƒå½¢çŠ¶: {pred_distri.shape}")
                
                # åˆ†æé¢„æµ‹åˆ†æ•°
                print(f"  é¢„æµ‹åˆ†æ•°èŒƒå›´: [{pred_scores.min().item():.6f}, {pred_scores.max().item():.6f}]")
                print(f"  é¢„æµ‹åˆ†å¸ƒèŒƒå›´: [{pred_distri.min().item():.6f}, {pred_distri.max().item():.6f}]")
        
        # è®¡ç®—æŸå¤±
        loss, loss_items = criterion(outputs, batch)
        print(f"  æŸå¤±å€¼: {loss.item():.6f}")
        print(f"  æŸå¤±åˆ†é‡: {loss_items.numpy()}")
        
        # 3. åˆ†æç›®æ ‡åˆ†é…
        print("\nğŸ” åˆ†æç›®æ ‡åˆ†é…:")
        print("  è·³è¿‡è¯¦ç»†åˆ†æï¼Œä¸“æ³¨äºæ ¸å¿ƒé—®é¢˜")
        
        # 4. è¿›è¡Œä¸€æ­¥è®­ç»ƒå¹¶åˆ†ææ¢¯åº¦
        print("\nğŸ” åˆ†ææ¢¯åº¦ä¼ æ’­:")
        optimizer = jt.optim.Adam(model.parameters(), lr=0.001)
        
        # ä¿å­˜è®­ç»ƒå‰çš„å‚æ•°
        param_before = {}
        for name, param in model.named_parameters():
            if 'detect' in name:  # åªå…³æ³¨æ£€æµ‹å¤´çš„å‚æ•°
                param_before[name] = param.clone()
        
        # æ‰§è¡Œä¸€æ­¥è®­ç»ƒ
        optimizer.step(loss)
        
        # æ£€æŸ¥å‚æ•°å˜åŒ–
        print("  æ£€æµ‹å¤´å‚æ•°å˜åŒ–:")
        param_changes = {}
        for name, param in model.named_parameters():
            if 'detect' in name and name in param_before:
                change = jt.abs(param - param_before[name]).mean().item()
                param_changes[name] = change
                if change > 1e-8:
                    print(f"    {name}: å˜åŒ– {change:.8f}")
        
        if not param_changes or all(change < 1e-8 for change in param_changes.values()):
            print("    âš ï¸ æ£€æµ‹å¤´å‚æ•°å‡ ä¹æ²¡æœ‰å˜åŒ–ï¼")
        else:
            print("    âœ… æ£€æµ‹å¤´å‚æ•°æœ‰æ­£å¸¸å˜åŒ–")
        
        # 5. æµ‹è¯•è®­ç»ƒåçš„è¾“å‡º
        print("\nğŸ” åˆ†æè®­ç»ƒåè¾“å‡º:")
        model.eval()
        with jt.no_grad():
            trained_outputs = model(img_tensor)
        
        # å¯¼å…¥åå¤„ç†å‡½æ•°
        sys.path.append('/home/kyc/project/GOLD-YOLO/Gold-YOLO_jittor/scripts')
        from gold_yolo_sanity_check import strict_post_process
        
        detections = strict_post_process(trained_outputs, conf_thres=0.3, iou_thres=0.5, max_det=20)
        det = detections[0]
        
        print(f"  è®­ç»ƒåæ£€æµ‹æ•°é‡: {det.shape[0]}")
        if det.shape[0] > 0:
            print(f"  æ£€æµ‹ç±»åˆ«: {set(det[:, 5].numpy().astype(int))}")
            print(f"  æ£€æµ‹ç½®ä¿¡åº¦: [{det[:, 4].min().item():.3f}, {det[:, 4].max().item():.3f}]")
        
        print("\n" + "=" * 60)
        print("âœ… å­¦ä¹ é—®é¢˜è¯Šæ–­å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ è¯Šæ–­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    diagnose_learning_problem()
