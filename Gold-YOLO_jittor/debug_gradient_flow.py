#!/usr/bin/env python3
"""
æ·±å…¥è°ƒè¯•æ¢¯åº¦æµé—®é¢˜
åˆ†æä¸ºä»€ä¹ˆå¤§é‡BatchNormå±‚æ²¡æœ‰æ¢¯åº¦
"""

import os
import sys
import cv2
import numpy as np
import jittor as jt
from pathlib import Path
import time

# æ·»åŠ è·¯å¾„
sys.path.append('.')
sys.path.append('./yolov6')

from models.perfect_gold_yolo import create_perfect_gold_yolo_model
from yolov6.data.data_augment import letterbox
from yolov6.models.pytorch_aligned_losses import ComputeLoss  # ä½¿ç”¨100%å¯¹é½PyTorchç‰ˆæœ¬
from yolov6.utils.nms import non_max_suppression

def pytorch_exact_initialization(model):
    """å®Œå…¨ç…§æŠ„PyTorchç‰ˆæœ¬çš„åˆå§‹åŒ–"""
    for module in model.modules():
        if hasattr(module, 'initialize_biases'):
            module.initialize_biases()
            break
    return model

def debug_gradient_flow():
    """æ·±å…¥è°ƒè¯•æ¢¯åº¦æµé—®é¢˜"""
    print(f"ğŸ” æ·±å…¥è°ƒè¯•æ¢¯åº¦æµé—®é¢˜")
    print("=" * 80)
    
    # å‡†å¤‡æ•°æ®
    label_file = "/home/kyc/project/GOLD-YOLO/2008_001420.txt"
    img_path = "/home/kyc/project/GOLD-YOLO/2008_001420.jpg"
    
    # è¯»å–æ•°æ®
    annotations = []
    with open(label_file, 'r') as f:
        for line in f:
            line = line.strip()
            if line:
                parts = line.split()
                if len(parts) >= 5:
                    cls_id = int(parts[0])
                    x_center = float(parts[1])
                    y_center = float(parts[2])
                    width = float(parts[3])
                    height = float(parts[4])
                    annotations.append([cls_id, x_center, y_center, width, height])
    
    original_img = cv2.imread(img_path)
    img = letterbox(original_img, new_shape=500, stride=32, auto=False)[0]
    img_tensor_input = img.transpose((2, 0, 1))[::-1]
    img_tensor_input = np.ascontiguousarray(img_tensor_input)
    img_tensor_input = img_tensor_input.astype(np.float32) / 255.0
    img_tensor = jt.array(img_tensor_input).unsqueeze(0)
    
    targets = []
    for ann in annotations:
        cls_id, x_center, y_center, width, height = ann
        targets.append([0, cls_id, x_center, y_center, width, height])
    targets_tensor = jt.array(targets, dtype=jt.float32).unsqueeze(0)
    
    print(f"ğŸ“Š æ•°æ®å‡†å¤‡å®Œæˆ:")
    print(f"   å›¾åƒå¼ é‡: {img_tensor.shape}")
    print(f"   æ ‡ç­¾å¼ é‡: {targets_tensor.shape}")
    
    # åˆ›å»ºæ¨¡å‹
    print(f"\nğŸ¯ åˆ›å»ºæ¨¡å‹å¹¶åˆ†æç»“æ„:")
    model = create_perfect_gold_yolo_model()
    model = pytorch_exact_initialization(model)
    
    # åˆ›å»º100%å¯¹é½PyTorchç‰ˆæœ¬çš„æŸå¤±å‡½æ•°
    loss_fn = ComputeLoss(
        num_classes=20,
        ori_img_size=500,
        warmup_epoch=4,
        use_dfl=True,   # ä½¿ç”¨100%å¯¹é½PyTorchç‰ˆæœ¬
        reg_max=16,     # ä½¿ç”¨100%å¯¹é½PyTorchç‰ˆæœ¬
        fpn_strides=[8, 16, 32],
        grid_cell_size=5.0,
        grid_cell_offset=0.5,
        loss_weight={'class': 1.0, 'iou': 2.5, 'dfl': 0.5}
    )
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = jt.optim.SGD(model.parameters(), lr=0.02, momentum=0.937, weight_decay=0.0005)
    
    print(f"\nğŸ” åˆ†ææ¨¡å‹å‚æ•°å’Œæ¢¯åº¦:")
    
    # ç»Ÿè®¡æ‰€æœ‰å‚æ•°
    total_params = 0
    params_with_grad = 0
    params_without_grad = 0
    
    print(f"\nğŸ“‹ å‚æ•°è¯¦ç»†åˆ†æ:")
    for name, param in model.named_parameters():
        total_params += 1
        if param.requires_grad:
            params_with_grad += 1
            grad_status = "âœ… éœ€è¦æ¢¯åº¦"
        else:
            params_without_grad += 1
            grad_status = "âŒ ä¸éœ€è¦æ¢¯åº¦"
        
        # åªæ˜¾ç¤ºå…³é”®å±‚
        if 'Inject' in name or 'embedding' in name or 'bn' in name:
            print(f"   {name}: {param.shape} - {grad_status}")
    
    print(f"\nğŸ“Š å‚æ•°ç»Ÿè®¡:")
    print(f"   æ€»å‚æ•°æ•°: {total_params}")
    print(f"   éœ€è¦æ¢¯åº¦: {params_with_grad}")
    print(f"   ä¸éœ€è¦æ¢¯åº¦: {params_without_grad}")
    
    # å‰å‘ä¼ æ’­
    print(f"\nğŸ”„ æ‰§è¡Œå‰å‘ä¼ æ’­:")
    model.train()
    outputs = model(img_tensor)
    
    print(f"   æ¨¡å‹è¾“å‡º:")
    if isinstance(outputs, (list, tuple)):
        for i, output in enumerate(outputs):
            if hasattr(output, 'shape'):
                print(f"     è¾“å‡º{i}: {output.shape}")
            else:
                print(f"     è¾“å‡º{i}: {type(output)} (å¯èƒ½æ˜¯list)")
    else:
        print(f"     è¾“å‡º: {outputs.shape if hasattr(outputs, 'shape') else type(outputs)}")
    
    # è®¡ç®—æŸå¤±
    print(f"\nğŸ’° è®¡ç®—æŸå¤±:")
    try:
        loss, loss_items = loss_fn(outputs, targets_tensor, epoch_num=1, step_num=1)
        print(f"   æŸå¤±å€¼: {float(loss.data.item()):.6f}")
        print(f"   æŸå¤±é¡¹: {[float(item.data.item()) for item in loss_items]}")
    except Exception as e:
        print(f"   âŒ æŸå¤±è®¡ç®—å¤±è´¥: {e}")
        return
    
    # åå‘ä¼ æ’­
    print(f"\nâ¬…ï¸ æ‰§è¡Œåå‘ä¼ æ’­:")
    optimizer.zero_grad()
    
    # æ‰‹åŠ¨è®¾ç½®æ¢¯åº¦è®¡ç®—
    jt.flags.use_cuda = 1
    
    try:
        optimizer.backward(loss)
        print(f"   âœ… åå‘ä¼ æ’­æˆåŠŸ")
    except Exception as e:
        print(f"   âŒ åå‘ä¼ æ’­å¤±è´¥: {e}")
        return
    
    # åˆ†ææ¢¯åº¦
    print(f"\nğŸ” åˆ†ææ¢¯åº¦åˆ†å¸ƒ:")
    
    params_with_actual_grad = 0
    params_without_actual_grad = 0
    zero_grad_params = []
    
    for name, param in model.named_parameters():
        if param.requires_grad:
            try:
                # ä½¿ç”¨Jittoræ­£ç¡®çš„æ¢¯åº¦API
                grad = param.opt_grad(optimizer)
                if grad is not None:
                    grad_norm = float(grad.norm().data.item())
                    if grad_norm > 1e-8:
                        params_with_actual_grad += 1
                        grad_status = f"âœ… æ¢¯åº¦èŒƒæ•°: {grad_norm:.6f}"
                    else:
                        params_without_actual_grad += 1
                        grad_status = f"âš ï¸ æ¢¯åº¦ä¸ºé›¶"
                        zero_grad_params.append(name)
                else:
                    params_without_actual_grad += 1
                    grad_status = f"âŒ æ— æ¢¯åº¦"
                    zero_grad_params.append(name)
            except Exception as e:
                params_without_actual_grad += 1
                grad_status = f"âŒ æ¢¯åº¦è·å–å¤±è´¥: {e}"
                zero_grad_params.append(name)
        else:
            grad_status = f"â– ä¸éœ€è¦æ¢¯åº¦"
        
        # åªæ˜¾ç¤ºå…³é”®å±‚
        if 'Inject' in name or 'embedding' in name or 'bn' in name:
            print(f"   {name}: {grad_status}")
    
    print(f"\nğŸ“Š æ¢¯åº¦ç»Ÿè®¡:")
    print(f"   æœ‰å®é™…æ¢¯åº¦: {params_with_actual_grad}")
    print(f"   æ¢¯åº¦ä¸ºé›¶/æ— æ¢¯åº¦: {params_without_actual_grad}")
    
    if zero_grad_params:
        print(f"\nâš ï¸ æ¢¯åº¦ä¸ºé›¶çš„å‚æ•° (å‰20ä¸ª):")
        for name in zero_grad_params[:20]:
            print(f"     {name}")
        if len(zero_grad_params) > 20:
            print(f"     ... è¿˜æœ‰ {len(zero_grad_params) - 20} ä¸ª")
    
    # åˆ†ææ¨¡å‹ç»“æ„é—®é¢˜
    print(f"\nğŸ—ï¸ åˆ†ææ¨¡å‹ç»“æ„é—®é¢˜:")
    
    # æ£€æŸ¥Injectæ¨¡å—æ˜¯å¦è¢«æ­£ç¡®ä½¿ç”¨
    inject_modules = []
    for name, module in model.named_modules():
        if 'Inject' in name:
            inject_modules.append(name)
    
    print(f"   å‘ç°Injectæ¨¡å—: {len(inject_modules)}ä¸ª")
    for name in inject_modules:
        print(f"     {name}")
    
    # æ£€æŸ¥æ¨¡å‹å‰å‘ä¼ æ’­è·¯å¾„
    print(f"\nğŸ›¤ï¸ æ£€æŸ¥å‰å‘ä¼ æ’­è·¯å¾„:")
    
    # ä½¿ç”¨hookæ¥è·Ÿè¸ªå“ªäº›æ¨¡å—è¢«è°ƒç”¨
    called_modules = []
    
    def forward_hook(module, input, output):
        called_modules.append(module.__class__.__name__)
    
    # æ³¨å†Œhook
    hooks = []
    for module in model.modules():
        if 'Inject' in module.__class__.__name__ or 'embedding' in str(module).lower():
            hook = module.register_forward_hook(forward_hook)
            hooks.append(hook)
    
    # é‡æ–°å‰å‘ä¼ æ’­
    called_modules.clear()
    with jt.no_grad():
        _ = model(img_tensor)
    
    # ç§»é™¤hook
    for hook in hooks:
        hook.remove()
    
    print(f"   è¢«è°ƒç”¨çš„å…³é”®æ¨¡å—: {set(called_modules)}")
    
    # å»ºè®®ä¿®å¤æ–¹æ¡ˆ
    print(f"\nğŸ”§ é—®é¢˜åˆ†æå’Œä¿®å¤å»ºè®®:")
    
    if params_without_actual_grad > params_with_actual_grad:
        print(f"   âŒ å¤§é‡å‚æ•°æ²¡æœ‰æ¢¯åº¦ï¼Œå¯èƒ½åŸå› :")
        print(f"     1. æŸäº›æ¨¡å—æ²¡æœ‰è¢«æ­£ç¡®è¿æ¥åˆ°è®¡ç®—å›¾")
        print(f"     2. æŸå¤±å‡½æ•°æ²¡æœ‰æ­£ç¡®åå‘ä¼ æ’­åˆ°æ‰€æœ‰å‚æ•°")
        print(f"     3. æ¨¡å‹ç»“æ„ä¸­å­˜åœ¨æ–­å¼€çš„åˆ†æ”¯")
        print(f"     4. BatchNormå±‚åœ¨evalæ¨¡å¼ä¸‹è¿è¡Œ")
    
    if 'Inject' not in str(called_modules):
        print(f"   âŒ Injectæ¨¡å—å¯èƒ½æ²¡æœ‰è¢«æ­£ç¡®è°ƒç”¨")
        print(f"     å»ºè®®æ£€æŸ¥neckéƒ¨åˆ†çš„å‰å‘ä¼ æ’­é€»è¾‘")
    
    print(f"\nğŸ’¡ ä¿®å¤å»ºè®®:")
    print(f"   1. ç¡®ä¿æ¨¡å‹åœ¨trainæ¨¡å¼ä¸‹è¿è¡Œ")
    print(f"   2. æ£€æŸ¥neckéƒ¨åˆ†çš„Injectæ¨¡å—è¿æ¥")
    print(f"   3. ä½¿ç”¨æ›´ç®€å•çš„æŸå¤±å‡½æ•°è¿›è¡Œæµ‹è¯•")
    print(f"   4. æ£€æŸ¥æ¨¡å‹åˆå§‹åŒ–æ˜¯å¦æ­£ç¡®")
    
    return {
        'total_params': total_params,
        'params_with_grad': params_with_grad,
        'params_without_grad': params_without_grad,
        'params_with_actual_grad': params_with_actual_grad,
        'params_without_actual_grad': params_without_actual_grad,
        'zero_grad_params': zero_grad_params,
        'inject_modules': inject_modules,
        'called_modules': called_modules
    }

def main():
    print("ğŸ” æ·±å…¥è°ƒè¯•æ¢¯åº¦æµé—®é¢˜")
    print("=" * 80)
    
    result = debug_gradient_flow()
    
    if result:
        print(f"\nğŸ“Š æ¢¯åº¦æµè°ƒè¯•å®Œæˆ!")
        print(f"   å‚æ•°æ€»æ•°: {result['total_params']}")
        print(f"   æœ‰å®é™…æ¢¯åº¦: {result['params_with_actual_grad']}")
        print(f"   æ— å®é™…æ¢¯åº¦: {result['params_without_actual_grad']}")
        print(f"   Injectæ¨¡å—æ•°: {len(result['inject_modules'])}")
        
        if result['params_without_actual_grad'] > result['params_with_actual_grad']:
            print(f"\nâŒ æ¢¯åº¦æµå­˜åœ¨ä¸¥é‡é—®é¢˜ï¼")
            print(f"   éœ€è¦ç«‹å³ä¿®å¤æ¨¡å‹ç»“æ„æˆ–æŸå¤±å‡½æ•°")
        else:
            print(f"\nâœ… æ¢¯åº¦æµåŸºæœ¬æ­£å¸¸")
    else:
        print(f"\nâŒ æ¢¯åº¦æµè°ƒè¯•å¤±è´¥!")

if __name__ == "__main__":
    main()
