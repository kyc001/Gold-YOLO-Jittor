#!/usr/bin/env python3
"""
å•å¼ å›¾ç‰‡è¿‡æ‹Ÿåˆè®­ç»ƒè‡ªæ£€
è¿™æ˜¯éªŒè¯æ¨¡å‹æ˜¯å¦æˆåŠŸçš„æœ€å¯é æ–¹æ³•
"""

import os
import sys
import cv2
import numpy as np
import jittor as jt
from pathlib import Path
import time
import matplotlib.pyplot as plt

# æ·»åŠ è·¯å¾„
sys.path.append('.')
sys.path.append('./yolov6')

from models.perfect_gold_yolo import create_perfect_gold_yolo_model
from yolov6.data.data_augment import letterbox
from yolov6.models.pytorch_aligned_losses import ComputeLoss

def pytorch_exact_initialization(model):
    """å®Œå…¨ç…§æŠ„PyTorchç‰ˆæœ¬çš„åˆå§‹åŒ–"""
    for module in model.modules():
        if hasattr(module, 'initialize_biases'):
            module.initialize_biases()
            break
    return model

def single_image_overfit_test():
    """å•å¼ å›¾ç‰‡è¿‡æ‹Ÿåˆè®­ç»ƒè‡ªæ£€"""
    print(f"ğŸ”¥ å•å¼ å›¾ç‰‡è¿‡æ‹Ÿåˆè®­ç»ƒè‡ªæ£€")
    print("=" * 80)
    print(f"è¿™æ˜¯éªŒè¯æ¨¡å‹æ˜¯å¦æˆåŠŸçš„æœ€å¯é æ–¹æ³•ï¼")
    print("=" * 80)
    
    # å‡†å¤‡æ•°æ®
    label_file = "/home/kyc/project/GOLD-YOLO/2008_001420.txt"
    img_path = "/home/kyc/project/GOLD-YOLO/2008_001420.jpg"
    
    print(f"ğŸ“ æ•°æ®æ–‡ä»¶:")
    print(f"   å›¾åƒ: {img_path}")
    print(f"   æ ‡æ³¨: {label_file}")
    
    # è¯»å–æ ‡æ³¨
    annotations = []
    with open(label_file, 'r') as f:
        for line in f:
            line = line.strip()
            if line:
                parts = line.split()
                if len(parts) >= 5:
                    cls_id = int(parts[0])
                    x_center = float(parts[1])
                    y_center = float(parts[2])
                    width = float(parts[3])
                    height = float(parts[4])
                    annotations.append([cls_id, x_center, y_center, width, height])
    
    print(f"   æ ‡æ³¨æ•°é‡: {len(annotations)}ä¸ªç›®æ ‡")
    
    # è¯»å–å›¾åƒ
    original_img = cv2.imread(img_path)
    img = letterbox(original_img, new_shape=500, stride=32, auto=False)[0]
    img_tensor_input = img.transpose((2, 0, 1))[::-1]
    img_tensor_input = np.ascontiguousarray(img_tensor_input)
    img_tensor_input = img_tensor_input.astype(np.float32) / 255.0
    img_tensor = jt.array(img_tensor_input).unsqueeze(0)
    
    # å‡†å¤‡æ ‡ç­¾
    targets = []
    for ann in annotations:
        cls_id, x_center, y_center, width, height = ann
        targets.append([0, cls_id, x_center, y_center, width, height])
    targets_tensor = jt.array(targets, dtype=jt.float32).unsqueeze(0)
    
    print(f"ğŸ“Š æ•°æ®å‡†å¤‡:")
    print(f"   å›¾åƒå¼ é‡: {img_tensor.shape}")
    print(f"   æ ‡ç­¾å¼ é‡: {targets_tensor.shape}")
    
    # åˆ›å»ºæ¨¡å‹
    print(f"\nğŸ¯ åˆ›å»ºæ¨¡å‹:")
    model = create_perfect_gold_yolo_model()
    model = pytorch_exact_initialization(model)
    model.train()  # è®­ç»ƒæ¨¡å¼
    
    # ç»Ÿè®¡å‚æ•°
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"   æ€»å‚æ•°: {total_params:,} ({total_params/1e6:.2f}M)")
    print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    
    # åˆ›å»ºæŸå¤±å‡½æ•° - 100%å¯¹é½PyTorchç‰ˆæœ¬
    loss_fn = ComputeLoss(
        num_classes=20,
        ori_img_size=500,
        warmup_epoch=0,  # ä¸ä½¿ç”¨warmup
        use_dfl=False,   # å¯¹é½PyTorchç‰ˆæœ¬
        reg_max=0,       # å¯¹é½PyTorchç‰ˆæœ¬
        fpn_strides=[8, 16, 32],
        grid_cell_size=5.0,
        grid_cell_offset=0.5,
        loss_weight={'class': 1.0, 'iou': 2.5, 'dfl': 0.5}
    )
    
    # åˆ›å»ºä¼˜åŒ–å™¨ - ä½¿ç”¨è¾ƒå¤§å­¦ä¹ ç‡è¿›è¡Œè¿‡æ‹Ÿåˆ
    optimizer = jt.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0)
    
    print(f"\nğŸ”¥ å¼€å§‹è¿‡æ‹Ÿåˆè®­ç»ƒ:")
    print(f"   å­¦ä¹ ç‡: 0.1 (è¾ƒå¤§ï¼Œä¾¿äºå¿«é€Ÿè¿‡æ‹Ÿåˆ)")
    print(f"   ä¼˜åŒ–å™¨: SGD")
    print(f"   ç›®æ ‡: æŸå¤±å¿«é€Ÿä¸‹é™åˆ°æ¥è¿‘0")
    
    # è®°å½•è®­ç»ƒè¿‡ç¨‹
    loss_history = []
    loss_items_history = []
    
    # è®­ç»ƒå¾ªç¯
    num_epochs = 100
    print_interval = 10
    
    print(f"\nğŸ“ˆ è®­ç»ƒè¿›åº¦:")
    print(f"   æ€»è½®æ•°: {num_epochs}")
    print(f"   æ‰“å°é—´éš”: æ¯{print_interval}è½®")
    print("-" * 80)
    
    start_time = time.time()
    
    for epoch in range(num_epochs):
        # å‰å‘ä¼ æ’­
        outputs = model(img_tensor)
        
        # è®¡ç®—æŸå¤±
        loss, loss_items = loss_fn(outputs, targets_tensor, epoch_num=epoch, step_num=epoch)
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        optimizer.backward(loss)
        optimizer.step()
        
        # è®°å½•æŸå¤±
        loss_value = float(loss.data.item())
        loss_items_values = [float(item.data.item()) for item in loss_items]
        
        loss_history.append(loss_value)
        loss_items_history.append(loss_items_values)
        
        # æ‰“å°è¿›åº¦
        if (epoch + 1) % print_interval == 0 or epoch == 0:
            elapsed = time.time() - start_time
            print(f"   è½®æ¬¡ {epoch+1:3d}/{num_epochs}: æŸå¤±={loss_value:.6f}, "
                  f"æŸå¤±é¡¹={[f'{x:.4f}' for x in loss_items_values]}, "
                  f"ç”¨æ—¶={elapsed:.1f}s")
    
    total_time = time.time() - start_time
    
    print("-" * 80)
    print(f"âœ… è®­ç»ƒå®Œæˆ! æ€»ç”¨æ—¶: {total_time:.1f}s")
    
    # åˆ†æè®­ç»ƒç»“æœ
    print(f"\nğŸ“Š è®­ç»ƒç»“æœåˆ†æ:")
    
    initial_loss = loss_history[0]
    final_loss = loss_history[-1]
    loss_reduction = (initial_loss - final_loss) / initial_loss * 100
    
    print(f"   åˆå§‹æŸå¤±: {initial_loss:.6f}")
    print(f"   æœ€ç»ˆæŸå¤±: {final_loss:.6f}")
    print(f"   æŸå¤±ä¸‹é™: {loss_reduction:.1f}%")
    
    # åˆ¤æ–­è¿‡æ‹Ÿåˆæ˜¯å¦æˆåŠŸ
    success_criteria = [
        ("æŸå¤±ä¸‹é™è¶…è¿‡90%", loss_reduction > 90),
        ("æœ€ç»ˆæŸå¤±å°äº0.1", final_loss < 0.1),
        ("æŸå¤±æŒç»­ä¸‹é™", loss_history[-1] < loss_history[len(loss_history)//2]),
    ]
    
    print(f"\nğŸ¯ è¿‡æ‹ŸåˆæˆåŠŸæ ‡å‡†:")
    success_count = 0
    for criterion, passed in success_criteria:
        status = "âœ…" if passed else "âŒ"
        print(f"   {status} {criterion}")
        if passed:
            success_count += 1
    
    overall_success = success_count >= 2
    print(f"\n{'ğŸ‰' if overall_success else 'âŒ'} æ€»ä½“è¯„ä¼°: "
          f"{'è¿‡æ‹ŸåˆæˆåŠŸï¼æ¨¡å‹å·¥ä½œæ­£å¸¸' if overall_success else 'è¿‡æ‹Ÿåˆå¤±è´¥ï¼Œæ¨¡å‹å¯èƒ½æœ‰é—®é¢˜'}")
    
    # ä¿å­˜è®­ç»ƒæ›²çº¿
    save_dir = Path("runs/single_image_overfit")
    save_dir.mkdir(parents=True, exist_ok=True)
    
    # ç»˜åˆ¶æŸå¤±æ›²çº¿
    plt.figure(figsize=(12, 8))
    
    plt.subplot(2, 2, 1)
    plt.plot(loss_history)
    plt.title('Total Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.grid(True)
    
    # åˆ†åˆ«ç»˜åˆ¶å„é¡¹æŸå¤±
    loss_items_array = np.array(loss_items_history)
    loss_names = ['IoU Loss', 'DFL Loss', 'Class Loss']
    
    for i in range(min(3, loss_items_array.shape[1])):
        plt.subplot(2, 2, i+2)
        plt.plot(loss_items_array[:, i])
        plt.title(loss_names[i])
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.grid(True)
    
    plt.tight_layout()
    curve_path = save_dir / 'loss_curves.png'
    plt.savefig(curve_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"\nğŸ“ˆ è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {curve_path}")
    
    # ä¿å­˜è®­ç»ƒæ—¥å¿—
    log_path = save_dir / 'training_log.txt'
    with open(log_path, 'w') as f:
        f.write("# å•å¼ å›¾ç‰‡è¿‡æ‹Ÿåˆè®­ç»ƒæ—¥å¿—\n\n")
        f.write(f"æ¨¡å‹å‚æ•°: {total_params:,} ({total_params/1e6:.2f}M)\n")
        f.write(f"è®­ç»ƒè½®æ•°: {num_epochs}\n")
        f.write(f"å­¦ä¹ ç‡: 0.1\n")
        f.write(f"åˆå§‹æŸå¤±: {initial_loss:.6f}\n")
        f.write(f"æœ€ç»ˆæŸå¤±: {final_loss:.6f}\n")
        f.write(f"æŸå¤±ä¸‹é™: {loss_reduction:.1f}%\n")
        f.write(f"è®­ç»ƒæ—¶é—´: {total_time:.1f}s\n")
        f.write(f"è¿‡æ‹ŸåˆæˆåŠŸ: {'æ˜¯' if overall_success else 'å¦'}\n\n")
        
        f.write("è¯¦ç»†æŸå¤±è®°å½•:\n")
        for i, (loss_val, loss_items_val) in enumerate(zip(loss_history, loss_items_history)):
            f.write(f"è½®æ¬¡{i+1:3d}: {loss_val:.6f} {loss_items_val}\n")
    
    print(f"ğŸ“ è®­ç»ƒæ—¥å¿—å·²ä¿å­˜: {log_path}")
    
    return {
        'success': overall_success,
        'initial_loss': initial_loss,
        'final_loss': final_loss,
        'loss_reduction': loss_reduction,
        'loss_history': loss_history,
        'total_time': total_time
    }

def main():
    print("ğŸ”¥ å•å¼ å›¾ç‰‡è¿‡æ‹Ÿåˆè®­ç»ƒè‡ªæ£€")
    print("=" * 80)
    
    try:
        result = single_image_overfit_test()
        
        if result and result['success']:
            print(f"\nğŸ‰ğŸ‰ğŸ‰ æ¨¡å‹éªŒè¯æˆåŠŸï¼")
            print(f"   æŸå¤±ä» {result['initial_loss']:.6f} ä¸‹é™åˆ° {result['final_loss']:.6f}")
            print(f"   ä¸‹é™å¹…åº¦: {result['loss_reduction']:.1f}%")
            print(f"   è®­ç»ƒæ—¶é—´: {result['total_time']:.1f}s")
            print(f"\nâœ… æ¨¡å‹å·¥ä½œæ­£å¸¸ï¼Œå¯ä»¥è¿›è¡Œæ­£å¼è®­ç»ƒï¼")
        else:
            print(f"\nâŒ æ¨¡å‹éªŒè¯å¤±è´¥ï¼")
            print(f"   éœ€è¦æ£€æŸ¥æ¨¡å‹ç»“æ„æˆ–æŸå¤±å‡½æ•°")
            
    except Exception as e:
        print(f"\nâŒ éªŒè¯è¿‡ç¨‹å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
