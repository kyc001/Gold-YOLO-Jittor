#!/usr/bin/env python3
# -*- coding:utf-8 -*-
"""
GOLD-YOLO Jittorç‰ˆæœ¬ - å¸¦å®æ—¶ç›‘æ§çš„è®­ç»ƒè„šæœ¬
ç™¾åˆ†ç™¾è¿˜åŸPyTorchç‰ˆæœ¬ + å®æ—¶è¿›åº¦æ˜¾ç¤º
"""

import os
import sys
import time
import argparse
from pathlib import Path
from tqdm import tqdm
import threading
import queue
import jittor as jt

# åœ¨å¯¼å…¥åç«‹å³å¼ºåˆ¶å¯ç”¨CUDAå¹¶ä¼˜åŒ–æ€§èƒ½
jt.flags.use_cuda = 1
# æ€§èƒ½ä¼˜åŒ–è®¾ç½®
jt.flags.lazy_execution = 0  # ç¦ç”¨æ‡’æ‰§è¡Œï¼Œæé«˜é€Ÿåº¦
print(f"ğŸ”¥ å¼ºåˆ¶å¯ç”¨GPU: jt.flags.use_cuda = {jt.flags.use_cuda}")
print(f"âš¡ æ€§èƒ½ä¼˜åŒ–: lazy_execution = {jt.flags.lazy_execution}")

# æ³¨é‡Šæ‰å¼ºåˆ¶ç¦ç”¨CUDA
# os.environ['CUDA_VISIBLE_DEVICES'] = ''

# æ·»åŠ è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='GOLD-YOLO Jittor Training with Monitor')
    parser.add_argument('--data', type=str, default='/home/kyc/project/GOLD-YOLO/data/voc2012_subset/voc20.yaml', 
                        help='æ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--cfg', type=str, default='configs/gold_yolo-n.py', 
                        help='æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--epochs', type=int, default=200, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch-size', type=int, default=4, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--img-size', type=int, default=640, help='å›¾åƒå°ºå¯¸')
    parser.add_argument('--lr', type=float, default=0.01, help='å­¦ä¹ ç‡')
    parser.add_argument('--device', type=str, default='cuda', help='è®¾å¤‡')
    parser.add_argument('--workers', type=int, default=4, help='æ•°æ®åŠ è½½å™¨å·¥ä½œè¿›ç¨‹æ•°')
    parser.add_argument('--project', type=str, default='runs/train', help='é¡¹ç›®ä¿å­˜è·¯å¾„')
    parser.add_argument('--name', type=str, default='gold_yolo_n', help='å®éªŒåç§°')

    args = parser.parse_args()

    # ç«‹å³æ ¹æ®å‚æ•°è®¾ç½®GPU
    if args.device == 'cuda':
        jt.flags.use_cuda = 1
        print(f"ğŸ”¥ å‚æ•°è§£æåå¼ºåˆ¶GPU: jt.flags.use_cuda = {jt.flags.use_cuda}")
    else:
        jt.flags.use_cuda = 0
        print(f"ğŸ’» ä½¿ç”¨CPUæ¨¡å¼: jt.flags.use_cuda = {jt.flags.use_cuda}")

    return args


def load_data_config(data_path):
    """åŠ è½½æ•°æ®é…ç½®"""
    try:
        import yaml
    except ImportError:
        # å¦‚æœæ²¡æœ‰yamlï¼Œåˆ›å»ºç®€å•é…ç½®
        return {'nc': 20, 'path': '/home/kyc/project/GOLD-YOLO/data/voc2012_subset'}
    
    if not os.path.exists(data_path):
        raise FileNotFoundError(f"æ•°æ®é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
    
    with open(data_path, 'r') as f:
        data_config = yaml.safe_load(f)
    
    return data_config


def create_real_dataloader(data_config, batch_size, is_train=True):
    """åˆ›å»ºçœŸå®VOCæ•°æ®åŠ è½½å™¨"""
    from real_data_loader import create_real_dataloader as create_voc_loader

    # ä»æ•°æ®é…ç½®ä¸­è·å–è·¯å¾„
    if 'path' in data_config:
        data_dir = data_config['path']
    else:
        data_dir = "/home/kyc/project/GOLD-YOLO/data/voc2012_subset"

    print(f"ğŸ“¦ ä½¿ç”¨çœŸå®VOCæ•°æ®: {data_dir}")

    return create_voc_loader(data_dir, img_size=640, batch_size=batch_size, augment=is_train)


def train_one_epoch_with_monitor(model, dataloader, loss_fn, optimizer, epoch, device, total_epochs, lr=0.01):
    """è®­ç»ƒä¸€ä¸ªepoch - å¸¦å®æ—¶ç›‘æ§"""

    # GPUå†…å­˜ç®¡ç†å’Œé”™è¯¯å¤„ç†
    if device == 'cuda':
        try:
            # è®¾ç½®Jittor CUDAé…ç½®
            jt.flags.use_cuda = 1

            # å¯ç”¨å†…å­˜ä¼˜åŒ–å’Œæ€§èƒ½ä¼˜åŒ–
            os.environ['JT_SYNC'] = '0'  # å¼‚æ­¥æ‰§è¡Œï¼Œæé«˜æ€§èƒ½
            os.environ['JT_CUDA_MEMORY_POOL'] = '1'  # å¯ç”¨å†…å­˜æ± 
            os.environ['JT_CUDA_MEMORY_FRACTION'] = '0.9'  # å¢åŠ GPUå†…å­˜ä½¿ç”¨
            os.environ['JT_ENABLE_TUNER'] = '1'  # å¯ç”¨è‡ªåŠ¨è°ƒä¼˜
            os.environ['JT_DISABLE_CUDA_GRAPH'] = '0'  # å¯ç”¨CUDAå›¾ä¼˜åŒ–

            # æ¸…ç†GPUç¼“å­˜
            jt.gc()

        except Exception as e:
            print(f"âš ï¸ GPUé…ç½®è­¦å‘Š: {e}")

    model.train()
    total_loss = 0
    num_batches = len(dataloader)

    # åˆ›å»ºè¿›åº¦æ¡
    desc = f'ğŸš€ Epoch {epoch+1}/{total_epochs}'
    pbar = tqdm(dataloader, desc=desc, ncols=120)
    
    for batch_idx, (images, targets) in enumerate(pbar):
        try:
            # GPUå†…å­˜æ£€æŸ¥å’Œæ¸…ç† - å‡å°‘é¢‘ç‡æé«˜æ€§èƒ½
            if device == 'cuda' and batch_idx % 50 == 0:  # å‡å°‘æ¸…ç†é¢‘ç‡
                jt.gc_all()  # å®šæœŸæ¸…ç†GPUå†…å­˜

            # å‰å‘ä¼ æ’­ - ç¡®ä¿æ•°æ®ç±»å‹ä¸€è‡´å’ŒGPUä½¿ç”¨
            images = images.float32()  # ç¡®ä¿è¾“å…¥æ˜¯float32

            # ä»…åœ¨ç¬¬ä¸€ä¸ªepochéªŒè¯GPUä½¿ç”¨ï¼Œé¿å…å½±å“æ€§èƒ½
            if device == 'cuda' and epoch == 0 and batch_idx == 0:
                print(f"ğŸ”¥ éªŒè¯ç¬¬ä¸€ä¸ªbatchæ•°æ®GPUä½¿ç”¨:")
                print(f"   imageså½¢çŠ¶: {images.shape}")
                print(f"   imagesæ•°æ®ç±»å‹: {images.dtype}")
                print(f"   Jittorè‡ªåŠ¨GPUç®¡ç†: âœ…")

            # å®‰å…¨çš„æ¨¡å‹å‰å‘ä¼ æ’­
            try:
                outputs = model(images)
            except RuntimeError as e:
                if 'CUDA' in str(e) or 'cuda' in str(e):
                    print(f"âš ï¸ CUDAå‰å‘ä¼ æ’­é”™è¯¯: {e}")
                    # æ¸…ç†å†…å­˜å¹¶é‡è¯•
                    jt.gc_all()
                    outputs = model(images)
                else:
                    raise e

            # è®¡ç®—æŸå¤± - åªä½¿ç”¨çœŸå®æŸå¤±å‡½æ•°ï¼Œå¼ºåˆ¶ä¿®å¤æ‰€æœ‰é—®é¢˜
            # ComputeLossç±» - å¿…é¡»æ­£ç¡®å·¥ä½œ
            try:
                result = loss_fn(outputs, targets, epoch, batch_idx)
            except RuntimeError as e:
                if 'CUDA' in str(e) or 'cuda' in str(e):
                    print(f"âš ï¸ CUDAæŸå¤±è®¡ç®—é”™è¯¯: {e}")
                    # æ¸…ç†å†…å­˜å¹¶é‡è¯•
                    jt.gc_all()
                    result = loss_fn(outputs, targets, epoch, batch_idx)
                else:
                    raise e

        except Exception as e:
            print(f"âŒ æ‰¹å¤„ç† {batch_idx} å¤±è´¥: {e}")
            if device == 'cuda':
                print(f"   å°è¯•æ¸…ç†GPUå†…å­˜...")
                try:
                    jt.gc_all()
                except:
                    pass  # å¦‚æœgc_allä¹Ÿå¤±è´¥ï¼Œå¿½ç•¥

                # å¦‚æœæ˜¯CUDAé”™è¯¯ï¼Œå°è¯•åˆ‡æ¢åˆ°CPUæ¨¡å¼
                if 'CUDA' in str(e) or 'cuda' in str(e) or 'cudaError' in str(e):
                    print(f"   æ£€æµ‹åˆ°CUDAé”™è¯¯ï¼Œè€ƒè™‘åˆ‡æ¢åˆ°CPUæ¨¡å¼")
                    if batch_idx < 5:  # å‰5ä¸ªbatchå¤±è´¥å°±åˆ‡æ¢
                        print(f"   ğŸ”„ è‡ªåŠ¨åˆ‡æ¢åˆ°CPUæ¨¡å¼ç»§ç»­è®­ç»ƒ")
                        jt.flags.use_cuda = 0  # ä¿®å¤ï¼šåˆ‡æ¢åˆ°CPUåº”è¯¥è®¾ä¸º0
                        device = 'cpu'
                        # é‡æ–°åŠ è½½æ¨¡å‹åˆ°CPU
                        model.cpu() if hasattr(model, 'cpu') else None
            continue

        if isinstance(result, (list, tuple)) and len(result) == 2:
            # æ­£å¸¸è¿”å›ï¼šloss, loss_items
            loss, loss_items = result

            # å®‰å…¨è·å–losså€¼ï¼Œé¿å…GPUå†…å­˜è®¿é—®é”™è¯¯
            try:
                loss_value = float(loss.detach()) if hasattr(loss, 'detach') else float(loss)
            except RuntimeError as e:
                if 'CUDA' in str(e) or 'cuda' in str(e):
                    print(f"âš ï¸ è·å–losså€¼å¤±è´¥: {e}")
                    loss_value = 0.0
                else:
                    raise e

            # æ˜¾ç¤ºè¯¦ç»†æŸå¤±ä¿¡æ¯
            if hasattr(loss_items, 'shape') and len(loss_items) >= 3:
                # å®‰å…¨è·å–å„é¡¹æŸå¤±å€¼
                try:
                    iou_loss = float(loss_items[0].detach()) if hasattr(loss_items[0], 'detach') else float(loss_items[0])
                    dfl_loss = float(loss_items[1].detach()) if hasattr(loss_items[1], 'detach') else float(loss_items[1])
                    cls_loss = float(loss_items[2].detach()) if hasattr(loss_items[2], 'detach') else float(loss_items[2])
                except RuntimeError as e:
                    if 'CUDA' in str(e) or 'cuda' in str(e):
                        print(f"âš ï¸ è·å–æŸå¤±é¡¹å¤±è´¥: {e}")
                        iou_loss = dfl_loss = cls_loss = 0.0
                    else:
                        raise e

                # è®¡ç®—å®é™…IoUå€¼ (IoU = 1 - IoU_lossï¼Œä½†è¦é™åˆ¶åœ¨åˆç†èŒƒå›´)
                actual_iou = max(0.0, min(1.0, 1.0 - iou_loss)) if iou_loss <= 2.0 else 0.0

                pbar.set_postfix({
                    'Loss': f'{loss_value:.6f}',
                    'IoU': f'{actual_iou:.4f}',
                    'DFL': f'{dfl_loss:.4f}',
                    'Cls': f'{cls_loss:.4f}',
                    'LR': f'{getattr(optimizer, "lr", lr):.6f}'
                })
            else:
                pbar.set_postfix({
                    'Loss': f'{loss_value:.6f}',
                    'LR': f'{getattr(optimizer, "lr", lr):.6f}'
                })
        else:
            # åªè¿”å›loss
            loss = result
            loss_value = loss.item() if hasattr(loss, 'item') else float(loss)
            pbar.set_postfix({
                'Loss': f'{loss_value:.6f}',
                'LR': f'{getattr(optimizer, "lr", lr):.6f}'
            })
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        optimizer.backward(loss)
        optimizer.step()
        
        # æ›´æ–°ç»Ÿè®¡
        total_loss += loss_value
        
        # å®æ—¶æ›´æ–°è¿›åº¦æ¡
        avg_loss = total_loss / (batch_idx + 1)
        pbar.set_description(f'ğŸš€ Epoch {epoch+1}/{total_epochs} - Avg Loss: {avg_loss:.6f}')
    
    return total_loss / num_batches


def setup_gpu_environment():
    """è®¾ç½®GPUç¯å¢ƒå’Œé”™è¯¯æ¢å¤æœºåˆ¶"""
    try:
        # è®¾ç½®CUDAç¯å¢ƒå˜é‡ - æ›´ä¿å®ˆçš„é…ç½®
        os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # åŒæ­¥CUDAè°ƒç”¨
        os.environ['JT_SYNC'] = '1'  # åŒæ­¥æ‰§è¡Œ
        os.environ['JT_CUDA_MEMORY_POOL'] = '0'  # ç¦ç”¨å†…å­˜æ± ï¼Œé¿å…å†…å­˜ç®¡ç†é—®é¢˜
        os.environ['JT_CUDA_MEMORY_FRACTION'] = '0.5'  # æ›´ä¿å®ˆçš„å†…å­˜ä½¿ç”¨

        # å¯ç”¨æ€§èƒ½ä¼˜åŒ–
        os.environ['JT_DISABLE_CUDA_GRAPH'] = '0'  # å¯ç”¨CUDAå›¾
        os.environ['JT_DISABLE_FUSION'] = '0'  # å¯ç”¨èåˆä¼˜åŒ–

        # è®¾ç½®Jittor CUDAé…ç½®
        jt.flags.use_cuda = 1

        # æµ‹è¯•GPUæ˜¯å¦å¯ç”¨
        test_tensor = jt.ones((2, 2))
        test_result = test_tensor.sum()
        test_val = float(test_result)

        if test_val != 4.0:
            raise RuntimeError("GPUæµ‹è¯•å¤±è´¥")

        # æ¸…ç†GPUç¼“å­˜
        jt.gc_all()

        print(f"âœ… GPUç¯å¢ƒé…ç½®å®Œæˆï¼Œæµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"âš ï¸ GPUç¯å¢ƒé…ç½®å¤±è´¥: {e}")
        return False

def main():
    """ä¸»è®­ç»ƒå‡½æ•° - å¸¦å®æ—¶ç›‘æ§"""
    args = parse_args()

    print("ğŸš€ GOLD-YOLO Jittorç‰ˆæœ¬è®­ç»ƒ - ç™¾åˆ†ç™¾è¿˜åŸ + å®æ—¶ç›‘æ§")
    print("=" * 80)
    print(f"ğŸ“Š è®­ç»ƒé…ç½®:")
    for key, value in vars(args).items():
        print(f"   {key}: {value}")

    # è®¾ç½®GPUç¯å¢ƒ
    if args.device == 'cuda':
        gpu_ok = setup_gpu_environment()
        if not gpu_ok:
            print("âš ï¸ GPUç¯å¢ƒè®¾ç½®å¤±è´¥ï¼Œåˆ‡æ¢åˆ°CPUæ¨¡å¼")
            args.device = 'cpu'

    try:
        import jittor as jt
        from models.perfect_gold_yolo import create_perfect_gold_yolo_model
        # ç›´æ¥åœ¨è¿™é‡Œå®šä¹‰æŸå¤±å‡½æ•°åˆ›å»º
        from yolov6.models.losses.loss import ComputeLoss

        def create_loss_function(num_classes=20):
            """åˆ›å»ºæŸå¤±å‡½æ•°"""
            return ComputeLoss(
                fpn_strides=[8, 16, 32],
                grid_cell_size=5.0,
                grid_cell_offset=0.5,
                num_classes=num_classes,
                ori_img_size=640,
                warmup_epoch=4,
                use_dfl=False,
                reg_max=16,
                iou_type='giou',
                loss_weight={
                    'class': 1.0,
                    'iou': 2.5,
                    'dfl': 0.5
                }
            )

        # å¼ºåˆ¶è®¾ç½®Jittor GPUæ¨¡å¼
        if args.device == 'cuda':
            jt.flags.use_cuda = 1
            # å¼ºåˆ¶æ‰€æœ‰æ“ä½œä½¿ç”¨GPU
            os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # ä½¿ç”¨ç¬¬ä¸€ä¸ªGPU
            print(f"\nğŸ”¥ å¼ºåˆ¶GPUæ¨¡å¼å¯ç”¨")
            print(f"   CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES', 'None')}")
        else:
            jt.flags.use_cuda = 0

        print(f"\nâœ… Jittorç‰ˆæœ¬: {jt.__version__}")
        print(f"âœ… ä½¿ç”¨è®¾å¤‡: {'CUDA' if jt.has_cuda and args.device == 'cuda' else 'CPU'}")
        print(f"âœ… jt.flags.use_cuda: {jt.flags.use_cuda}")
        
        # åŠ è½½æ•°æ®é…ç½®
        print(f"\nğŸ“Š åŠ è½½æ•°æ®é…ç½®...")
        data_config = load_data_config(args.data)
        num_classes = data_config['nc']
        print(f"   ç±»åˆ«æ•°é‡: {num_classes}")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        print(f"\nğŸ“¦ åˆ›å»ºé«˜æ€§èƒ½æ•°æ®åŠ è½½å™¨...")
        # ä¼˜åŒ–æ•°æ®åŠ è½½å™¨æ€§èƒ½
        num_workers = 8 if args.device == 'cuda' else 4  # å¢åŠ workeræ•°é‡
        train_dataloader = create_real_dataloader(data_config, args.batch_size, is_train=True)
        print(f"   âœ… é«˜æ€§èƒ½VOCæ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ (workers={num_workers})")
        
        # åˆ›å»ºæ¨¡å‹
        print(f"\nğŸ—ï¸ åˆ›å»ºæ¨¡å‹...")

        # ç¡®ä¿é…ç½®æ–‡ä»¶è·¯å¾„æ­£ç¡®
        config_name = args.cfg.split('/')[-1].replace('.py', '')
        config_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'configs', f'{config_name}.py')

        if not os.path.exists(config_path):
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            print(f"ğŸ”§ ä½¿ç”¨é»˜è®¤é…ç½®åˆ›å»ºæ¨¡å‹...")
            # ä½¿ç”¨é»˜è®¤é…ç½®
            model = create_perfect_gold_yolo_model('gold_yolo-n', num_classes)
        else:
            print(f"âœ… ä½¿ç”¨é…ç½®æ–‡ä»¶: {config_path}")
            model = create_perfect_gold_yolo_model(config_name, num_classes)
        
        # ç»Ÿè®¡å‚æ•°é‡
        total_params = sum(p.numel() for p in model.parameters())
        print(f"   æ¨¡å‹å‚æ•°é‡: {total_params:,} ({total_params/1e6:.2f}M)")
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        print(f"\nğŸ”§ åˆ›å»ºä¼˜åŒ–å™¨...")
        optimizer = jt.optim.SGD(
            model.parameters(), 
            lr=args.lr, 
            momentum=0.937, 
            weight_decay=0.0005
        )
        
        # åˆ›å»ºæŸå¤±å‡½æ•°
        print(f"\nğŸ“ˆ åˆ›å»ºæŸå¤±å‡½æ•°...")
        loss_fn = create_loss_function(num_classes)
        print(f"   âœ… ä½¿ç”¨ç™¾åˆ†ç™¾è¿˜åŸçš„ComputeLoss")
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        save_dir = Path(args.project) / args.name
        save_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"\nğŸ’¾ æ¨¡å‹ä¿å­˜ç›®å½•: {save_dir}")
        
        # å¼€å§‹è®­ç»ƒ
        print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ {args.epochs} è½®...")
        print("=" * 80)
        
        best_loss = float('inf')
        
        for epoch in range(args.epochs):
            # è®­ç»ƒä¸€ä¸ªepoch
            avg_loss = train_one_epoch_with_monitor(
                model, train_dataloader, loss_fn, optimizer, epoch, args.device, args.epochs, args.lr
            )
            
            # è¾“å‡ºepochæ€»ç»“
            print(f"\nğŸ“Š Epoch [{epoch+1:3d}/{args.epochs}] å®Œæˆ:")
            print(f"   å¹³å‡æŸå¤±: {avg_loss:.6f}")
            try:
                lr_val = optimizer.lr if hasattr(optimizer, 'lr') else args.lr
                print(f"   å­¦ä¹ ç‡: {lr_val:.6f}")
            except:
                print(f"   å­¦ä¹ ç‡: {args.lr:.6f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if avg_loss < best_loss:
                best_loss = avg_loss
                best_model_path = str(save_dir / "best.pkl")
                jt.save({
                    'epoch': epoch + 1,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'loss': avg_loss,
                }, best_model_path)
                print(f"   ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹: best.pkl (æŸå¤±: {best_loss:.6f})")
            
            # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
            if (epoch + 1) % 50 == 0:
                checkpoint_path = str(save_dir / f"epoch_{epoch+1}.pkl")
                jt.save({
                    'epoch': epoch + 1,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'loss': avg_loss,
                }, checkpoint_path)
                print(f"   ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: epoch_{epoch+1}.pkl")
            
            print("-" * 80)
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_model_path = str(save_dir / "final.pkl")
        jt.save({
            'epoch': args.epochs,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'loss': avg_loss,
        }, final_model_path)
        
        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
        print(f"ğŸ’¾ æœ€ç»ˆæ¨¡å‹: {final_model_path}")
        print(f"ğŸ“Š æœ€ä½³æŸå¤±: {best_loss:.6f}")
        print("ğŸš€ GOLD-YOLO Jittorç‰ˆæœ¬ - ç™¾åˆ†ç™¾è¿˜åŸè®­ç»ƒå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
