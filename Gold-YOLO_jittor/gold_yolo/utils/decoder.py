#!/usr/bin/env python3
# -*- coding:utf-8 -*-
"""
å®Œæ•´çš„YOLOè§£ç ç®—æ³•å®ç°
æ–°èŠ½ç¬¬äºŒé˜¶æ®µï¼šæ»¡è¡€YOLOè§£ç ï¼Œä¸ç®€åŒ–ä¸å¦¥å
"""

import numpy as np
import jittor as jt
import jittor.nn as nn
from typing import List, Tuple, Dict, Any

class FullYOLODecoder:
    """å®Œæ•´çš„YOLOè§£ç å™¨ - æ»¡è¡€å®ç°"""
    
    def __init__(self, 
                 input_size: int = 640,
                 num_classes: int = 80,
                 strides: List[int] = [8, 16, 32],
                 anchor_sizes: List[List[float]] = None):
        """
        åˆå§‹åŒ–å®Œæ•´YOLOè§£ç å™¨
        
        Args:
            input_size: è¾“å…¥å›¾åƒå°ºå¯¸
            num_classes: ç±»åˆ«æ•°é‡
            strides: ç‰¹å¾å›¾æ­¥é•¿
            anchor_sizes: anchorå°ºå¯¸é…ç½®
        """
        self.input_size = input_size
        self.num_classes = num_classes
        self.strides = strides
        
        # é»˜è®¤anchoré…ç½® (Gold-YOLOé£æ ¼)
        if anchor_sizes is None:
            self.anchor_sizes = [
                [[10, 13], [16, 30], [33, 23]],      # P3/8
                [[30, 61], [62, 45], [59, 119]],     # P4/16  
                [[116, 90], [156, 198], [373, 326]]  # P5/32
            ]
        else:
            self.anchor_sizes = anchor_sizes
        
        # ç”Ÿæˆanchorç½‘æ ¼
        self.anchor_grids = self._generate_anchor_grids()
        
        print(f"ğŸ¯ å®Œæ•´YOLOè§£ç å™¨åˆå§‹åŒ–")
        print(f"   è¾“å…¥å°ºå¯¸: {input_size}")
        print(f"   ç±»åˆ«æ•°: {num_classes}")
        print(f"   æ­¥é•¿: {strides}")
        print(f"   æ€»anchoræ•°: {sum(len(grid) for grid in self.anchor_grids)}")
    
    def _generate_anchor_grids(self) -> List[np.ndarray]:
        """ç”Ÿæˆanchorç½‘æ ¼ç‚¹"""
        anchor_grids = []
        
        for level, stride in enumerate(self.strides):
            grid_size = self.input_size // stride
            anchors = self.anchor_sizes[level]
            
            # ç”Ÿæˆç½‘æ ¼åæ ‡
            grid_y, grid_x = np.meshgrid(
                np.arange(grid_size), 
                np.arange(grid_size), 
                indexing='ij'
            )
            
            # ä¸ºæ¯ä¸ªanchorç”Ÿæˆç½‘æ ¼ç‚¹
            level_anchors = []
            for anchor_w, anchor_h in anchors:
                for i in range(grid_size):
                    for j in range(grid_size):
                        # anchorä¸­å¿ƒç‚¹åæ ‡
                        cx = (j + 0.5) * stride
                        cy = (i + 0.5) * stride
                        
                        level_anchors.append([cx, cy, anchor_w, anchor_h, stride])
            
            anchor_grids.append(np.array(level_anchors))
        
        return anchor_grids
    
    def _decode_bbox_predictions(self, 
                                reg_pred: jt.Var, 
                                anchor_grids: List[np.ndarray]) -> jt.Var:
        """
        è§£ç è¾¹ç•Œæ¡†é¢„æµ‹
        
        Args:
            reg_pred: å›å½’é¢„æµ‹ [batch, num_anchors, reg_dim]
            anchor_grids: anchorç½‘æ ¼ç‚¹
            
        Returns:
            decoded_boxes: è§£ç åçš„è¾¹ç•Œæ¡† [batch, num_anchors, 4] (x1,y1,x2,y2)
        """
        batch_size = reg_pred.shape[0]
        total_anchors = reg_pred.shape[1]
        
        # åˆå¹¶æ‰€æœ‰anchor
        all_anchors = np.concatenate(anchor_grids, axis=0)
        anchor_tensor = jt.array(all_anchors[:total_anchors])  # [num_anchors, 5]
        
        # æå–anchorä¿¡æ¯
        anchor_cx = anchor_tensor[:, 0]  # ä¸­å¿ƒx
        anchor_cy = anchor_tensor[:, 1]  # ä¸­å¿ƒy
        anchor_w = anchor_tensor[:, 2]   # å®½åº¦
        anchor_h = anchor_tensor[:, 3]   # é«˜åº¦
        
        # Gold-YOLOå›å½’æ ¼å¼è§£ç 
        if reg_pred.shape[2] >= 68:  # DFL + bbox
            # å‰4ä¸ªæ˜¯è¾¹ç•Œæ¡†åç§»
            dx = reg_pred[:, :, 0]  # xåç§»
            dy = reg_pred[:, :, 1]  # yåç§»
            dw = reg_pred[:, :, 2]  # å®½åº¦ç¼©æ”¾
            dh = reg_pred[:, :, 3]  # é«˜åº¦ç¼©æ”¾
            
            # è§£ç ä¸­å¿ƒç‚¹
            pred_cx = anchor_cx + dx * anchor_w
            pred_cy = anchor_cy + dy * anchor_h
            
            # è§£ç å®½é«˜
            pred_w = anchor_w * jt.exp(dw)
            pred_h = anchor_h * jt.exp(dh)
            
        else:  # ç®€åŒ–æ ¼å¼
            # ç›´æ¥ä½¿ç”¨å‰4ä¸ªç»´åº¦
            dx = reg_pred[:, :, 0] * 0.1  # ç¼©æ”¾å› å­
            dy = reg_pred[:, :, 1] * 0.1
            dw = reg_pred[:, :, 2] * 0.2
            dh = reg_pred[:, :, 3] * 0.2
            
            pred_cx = anchor_cx + dx * anchor_w
            pred_cy = anchor_cy + dy * anchor_h
            pred_w = anchor_w * (1 + dw)
            pred_h = anchor_h * (1 + dh)
        
        # è½¬æ¢ä¸ºx1,y1,x2,y2æ ¼å¼
        x1 = pred_cx - pred_w / 2
        y1 = pred_cy - pred_h / 2
        x2 = pred_cx + pred_w / 2
        y2 = pred_cy + pred_h / 2
        
        # é™åˆ¶åœ¨å›¾åƒèŒƒå›´å†…
        x1 = jt.clamp(x1, 0, self.input_size)
        y1 = jt.clamp(y1, 0, self.input_size)
        x2 = jt.clamp(x2, 0, self.input_size)
        y2 = jt.clamp(y2, 0, self.input_size)
        
        # ç»„åˆæˆè¾¹ç•Œæ¡†
        decoded_boxes = jt.stack([x1, y1, x2, y2], dim=-1)
        
        return decoded_boxes
    
    def _apply_nms(self, 
                   boxes: np.ndarray, 
                   scores: np.ndarray, 
                   class_ids: np.ndarray,
                   iou_threshold: float = 0.5) -> List[int]:
        """
        åº”ç”¨éæå¤§å€¼æŠ‘åˆ¶
        
        Args:
            boxes: è¾¹ç•Œæ¡† [N, 4]
            scores: ç½®ä¿¡åº¦åˆ†æ•° [N]
            class_ids: ç±»åˆ«ID [N]
            iou_threshold: IoUé˜ˆå€¼
            
        Returns:
            keep_indices: ä¿ç•™çš„ç´¢å¼•åˆ—è¡¨
        """
        if len(boxes) == 0:
            return []
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        order = np.argsort(scores)[::-1]
        
        keep = []
        while len(order) > 0:
            # ä¿ç•™ç½®ä¿¡åº¦æœ€é«˜çš„
            i = order[0]
            keep.append(i)
            
            if len(order) == 1:
                break
            
            # è®¡ç®—IoU
            ious = self._calculate_iou_batch(boxes[i:i+1], boxes[order[1:]])
            
            # è¿‡æ»¤é«˜IoUçš„åŒç±»åˆ«æ¡†
            mask = np.ones(len(order) - 1, dtype=bool)
            for j, idx in enumerate(order[1:]):
                if class_ids[i] == class_ids[idx] and ious[j] > iou_threshold:
                    mask[j] = False
            
            order = order[1:][mask]
        
        return keep
    
    def _calculate_iou_batch(self, boxes1: np.ndarray, boxes2: np.ndarray) -> np.ndarray:
        """æ‰¹é‡è®¡ç®—IoU"""
        # boxes1: [1, 4], boxes2: [N, 4]
        x1_1, y1_1, x2_1, y2_1 = boxes1[0]
        x1_2, y1_2, x2_2, y2_2 = boxes2.T
        
        # è®¡ç®—äº¤é›†
        x1_i = np.maximum(x1_1, x1_2)
        y1_i = np.maximum(y1_1, y1_2)
        x2_i = np.minimum(x2_1, x2_2)
        y2_i = np.minimum(y2_1, y2_2)
        
        intersection = np.maximum(0, x2_i - x1_i) * np.maximum(0, y2_i - y1_i)
        
        # è®¡ç®—å¹¶é›†
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        union = area1 + area2 - intersection
        
        return intersection / np.maximum(union, 1e-8)
    
    def decode_predictions(self, 
                          cls_pred: jt.Var, 
                          reg_pred: jt.Var,
                          conf_threshold: float = 0.3,
                          nms_threshold: float = 0.5,
                          max_detections: int = 100) -> List[Dict[str, Any]]:
        """
        å®Œæ•´è§£ç YOLOé¢„æµ‹ç»“æœ
        
        Args:
            cls_pred: åˆ†ç±»é¢„æµ‹ [batch, num_anchors, num_classes]
            reg_pred: å›å½’é¢„æµ‹ [batch, num_anchors, reg_dim]
            conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            nms_threshold: NMS IoUé˜ˆå€¼
            max_detections: æœ€å¤§æ£€æµ‹æ•°é‡
            
        Returns:
            detections: æ£€æµ‹ç»“æœåˆ—è¡¨
        """
        batch_size = cls_pred.shape[0]
        
        # åº”ç”¨sigmoidæ¿€æ´»
        cls_scores = jt.sigmoid(cls_pred)  # [batch, num_anchors, num_classes]
        
        # è§£ç è¾¹ç•Œæ¡†
        decoded_boxes = self._decode_bbox_predictions(reg_pred, self.anchor_grids)
        
        batch_detections = []
        
        for b in range(batch_size):
            # è·å–å½“å‰æ‰¹æ¬¡çš„é¢„æµ‹
            batch_cls_scores = cls_scores[b].numpy()  # [num_anchors, num_classes]
            batch_boxes = decoded_boxes[b].numpy()   # [num_anchors, 4]
            
            # è·å–æœ€é«˜ç½®ä¿¡åº¦å’Œå¯¹åº”ç±»åˆ«
            max_scores = np.max(batch_cls_scores, axis=1)  # [num_anchors]
            max_classes = np.argmax(batch_cls_scores, axis=1)  # [num_anchors]
            
            # è¿‡æ»¤ä½ç½®ä¿¡åº¦é¢„æµ‹
            valid_mask = max_scores > conf_threshold
            if not np.any(valid_mask):
                batch_detections.append([])
                continue
            
            valid_boxes = batch_boxes[valid_mask]
            valid_scores = max_scores[valid_mask]
            valid_classes = max_classes[valid_mask]
            
            # åº”ç”¨NMS
            keep_indices = self._apply_nms(
                valid_boxes, valid_scores, valid_classes, nms_threshold
            )
            
            # æ„å»ºæ£€æµ‹ç»“æœ
            detections = []
            for idx in keep_indices[:max_detections]:
                x1, y1, x2, y2 = valid_boxes[idx]
                
                # ç¡®ä¿è¾¹ç•Œæ¡†æœ‰æ•ˆ
                if x2 > x1 and y2 > y1:
                    detections.append({
                        'bbox': [float(x1), float(y1), float(x2), float(y2)],
                        'confidence': float(valid_scores[idx]),
                        'class_id': int(valid_classes[idx]),
                        'class_name': self._get_class_name(int(valid_classes[idx]))
                    })
            
            batch_detections.append(detections)
        
        return batch_detections
    
    def _get_class_name(self, class_id: int) -> str:
        """è·å–ç±»åˆ«åç§°"""
        # COCOç±»åˆ«åç§°
        coco_classes = [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',
            'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
            'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
            'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',
            'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
            'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
            'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',
            'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',
            'hair drier', 'toothbrush'
        ]
        
        if 0 <= class_id < len(coco_classes):
            return coco_classes[class_id]
        else:
            return f"unknown_{class_id}"


class DistributionFocalLoss(nn.Module):
    """åˆ†å¸ƒç„¦ç‚¹æŸå¤± - Gold-YOLOçš„DFLå®ç°"""
    
    def __init__(self, reg_max: int = 16):
        super().__init__()
        self.reg_max = reg_max
    
    def execute(self, pred_dist: jt.Var, target: jt.Var) -> jt.Var:
        """
        è®¡ç®—DFLæŸå¤±
        
        Args:
            pred_dist: é¢„æµ‹åˆ†å¸ƒ [N, 4, reg_max+1]
            target: ç›®æ ‡è·ç¦» [N, 4]
        """
        # å°†è¿ç»­ç›®æ ‡è½¬æ¢ä¸ºç¦»æ•£åˆ†å¸ƒ
        target_left = jt.floor(target).long()
        target_right = target_left + 1
        weight_left = target_right.float() - target
        weight_right = target - target_left.float()
        
        # é™åˆ¶èŒƒå›´
        target_left = jt.clamp(target_left, 0, self.reg_max)
        target_right = jt.clamp(target_right, 0, self.reg_max)
        
        # è®¡ç®—äº¤å‰ç†µæŸå¤±
        loss_left = nn.cross_entropy_loss(
            pred_dist.view(-1, self.reg_max + 1),
            target_left.view(-1),
            reduction='none'
        )
        loss_right = nn.cross_entropy_loss(
            pred_dist.view(-1, self.reg_max + 1),
            target_right.view(-1),
            reduction='none'
        )
        
        # åŠ æƒå¹³å‡
        loss = (loss_left * weight_left.view(-1) + 
                loss_right * weight_right.view(-1))
        
        return loss.mean()


def test_full_decoder():
    """æµ‹è¯•å®Œæ•´è§£ç å™¨"""
    print("ğŸ§ª æµ‹è¯•å®Œæ•´YOLOè§£ç å™¨")
    
    # åˆ›å»ºè§£ç å™¨
    decoder = FullYOLODecoder(
        input_size=640,
        num_classes=80,
        strides=[8, 16, 32]
    )
    
    # æ¨¡æ‹Ÿé¢„æµ‹ç»“æœ
    batch_size = 2
    num_anchors = 525  # 8400 / 16 çš„ç®€åŒ–ç‰ˆæœ¬
    
    cls_pred = jt.randn(batch_size, num_anchors, 80)
    reg_pred = jt.randn(batch_size, num_anchors, 68)
    
    print(f"è¾“å…¥å½¢çŠ¶:")
    print(f"  åˆ†ç±»é¢„æµ‹: {cls_pred.shape}")
    print(f"  å›å½’é¢„æµ‹: {reg_pred.shape}")
    
    # è§£ç é¢„æµ‹
    import time
    start_time = time.time()
    detections = decoder.decode_predictions(
        cls_pred, reg_pred,
        conf_threshold=0.3,
        nms_threshold=0.5,
        max_detections=50
    )
    decode_time = time.time() - start_time
    
    print(f"\nè§£ç ç»“æœ:")
    print(f"  è§£ç æ—¶é—´: {decode_time*1000:.2f} ms")
    print(f"  æ‰¹æ¬¡æ•°: {len(detections)}")
    
    for b, batch_dets in enumerate(detections):
        print(f"  æ‰¹æ¬¡{b}: {len(batch_dets)}ä¸ªæ£€æµ‹")
        for i, det in enumerate(batch_dets[:3]):  # æ˜¾ç¤ºå‰3ä¸ª
            print(f"    {i+1}. {det['class_name']}: {det['confidence']:.3f}")
    
    print("âœ… å®Œæ•´è§£ç å™¨æµ‹è¯•é€šè¿‡")


if __name__ == "__main__":
    test_full_decoder()
