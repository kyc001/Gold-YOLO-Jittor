#!/usr/bin/env python3
"""
æœ€ç»ˆæ¨ç†å¯è§†åŒ–æµ‹è¯•
ä½¿ç”¨ä¿®å¤å®Œæˆçš„æ¨¡å‹è¿›è¡Œå®Œæ•´æ¨ç†æµ‹è¯•å¹¶è¾“å‡ºå¯è§†åŒ–ç»“æœ
"""

import os
import sys
import time
import cv2
import numpy as np
from pathlib import Path

import jittor as jt

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models.perfect_gold_yolo import create_perfect_gold_yolo_model
from yolov6.data.data_augment import letterbox
from yolov6.utils.nms import non_max_suppression

# COCOç±»åˆ«åç§°
COCO_CLASSES = [
    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',
    'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow'
]

# é¢œè‰²åˆ—è¡¨
COLORS = [
    (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255),
    (0, 255, 255), (128, 0, 128), (255, 165, 0), (0, 128, 128), (128, 128, 0),
    (255, 192, 203), (128, 0, 0), (0, 128, 0), (0, 0, 128), (128, 128, 128),
    (255, 20, 147), (0, 191, 255), (255, 69, 0), (50, 205, 50), (220, 20, 60)
]

def load_trained_model():
    """åŠ è½½è®­ç»ƒå®Œæˆçš„æ¨¡å‹"""
    print("ğŸ”§ åŠ è½½è®­ç»ƒå®Œæˆçš„æ¨¡å‹...")
    
    # åˆ›å»ºæ¨¡å‹
    model = create_perfect_gold_yolo_model('gold_yolo-n', num_classes=20)
    
    # åŠ è½½è®­ç»ƒå¥½çš„æƒé‡
    model_path = 'ultimate_final_model.pkl'
    if os.path.exists(model_path):
        print(f"ğŸ“¦ åŠ è½½æ¨¡å‹æƒé‡: {model_path}")
        checkpoint = jt.load(model_path)
        model.load_state_dict(checkpoint['model'])
        
        # æ˜¾ç¤ºè®­ç»ƒä¿¡æ¯
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        print(f"   è®­ç»ƒè½®æ•°: {checkpoint.get('epoch', 'Unknown')}")
        print(f"   æœ€ä½³æŸå¤±: {checkpoint.get('best_loss', 'Unknown'):.6f}")
        print(f"   åˆ†ç±»å¤´çŠ¶æ€: {'æ­£å¸¸' if checkpoint.get('classification_success', False) else 'å¼‚å¸¸'}")
        print(f"   æ¢¯åº¦ç¨³å®šæ€§: {'ç¨³å®š' if checkpoint.get('gradient_stable', False) else 'ä¸ç¨³å®š'}")
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œä½¿ç”¨åˆå§‹åŒ–æ¨¡å‹")
        # é‡æ–°åˆå§‹åŒ–åˆ†ç±»å¤´
        for name, module in model.named_modules():
            if 'cls_pred' in name and isinstance(module, jt.nn.Conv2d):
                jt.init.gauss_(module.weight, mean=0.0, std=0.01)
                if module.bias is not None:
                    jt.init.constant_(module.bias, -2.0)
    
    model.eval()
    return model

def preprocess_image(img_path, img_size=640):
    """é¢„å¤„ç†å›¾åƒ"""
    # è¯»å–å›¾åƒ
    img0 = cv2.imread(img_path)
    assert img0 is not None, f"æ— æ³•è¯»å–å›¾åƒ: {img_path}"
    
    h0, w0 = img0.shape[:2]
    
    # é¢„å¤„ç†
    img = letterbox(img0, new_shape=img_size, stride=32, auto=False)[0]
    img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, HWC to CHW
    img = np.ascontiguousarray(img)
    img = img.astype(np.float32) / 255.0
    img_tensor = jt.array(img).unsqueeze(0)
    
    return img_tensor, img0, (h0, w0)

def postprocess_detections(pred, img0_shape, img_size=640, conf_thres=0.25, iou_thres=0.45):
    """åå¤„ç†æ£€æµ‹ç»“æœ"""
    # NMSå¤„ç†
    pred = non_max_suppression(pred, conf_thres=conf_thres, iou_thres=iou_thres, max_det=1000)
    
    detections = []
    for i, det in enumerate(pred):
        if len(det):
            # åæ ‡ç¼©æ”¾å›åŸå›¾å°ºå¯¸
            det[:, :4] = scale_coords((img_size, img_size), det[:, :4], img0_shape).round()
            detections.append(det)
        else:
            detections.append(jt.empty((0, 6)))
    
    return detections

def scale_coords(img1_shape, coords, img0_shape, ratio_pad=None):
    """å°†åæ ‡ä»img1_shapeç¼©æ”¾åˆ°img0_shape"""
    if ratio_pad is None:  # ä»img1_shapeè®¡ç®—
        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  # gain  = old / new
        pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2  # wh padding
    else:
        gain = ratio_pad[0][0]
        pad = ratio_pad[1]

    coords[:, [0, 2]] -= pad[0]  # x padding
    coords[:, [1, 3]] -= pad[1]  # y padding
    coords[:, :4] /= gain
    coords[:, [0, 2]] = coords[:, [0, 2]].clamp(0, img0_shape[1])  # x1, x2
    coords[:, [1, 3]] = coords[:, [1, 3]].clamp(0, img0_shape[0])  # y1, y2
    return coords

def draw_detections(img, detections, conf_thres=0.25):
    """ç»˜åˆ¶æ£€æµ‹ç»“æœ"""
    img_vis = img.copy()
    
    for det in detections:
        if len(det):
            if hasattr(det, 'numpy'):
                det_np = det.numpy()
            else:
                det_np = det
            
            for detection in det_np:
                # å¤„ç†åµŒå¥—æ•°ç»„æ ¼å¼
                if isinstance(detection, np.ndarray) and detection.ndim > 1:
                    detection = detection.flatten()

                if len(detection) >= 6:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å…ƒç´ 
                    x1, y1, x2, y2, conf, cls = detection[:6]
                    if conf >= conf_thres:
                        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])
                        class_id = int(cls)
                        confidence = float(conf)

                        # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
                        x1 = max(0, min(x1, img.shape[1]-1))
                        y1 = max(0, min(y1, img.shape[0]-1))
                        x2 = max(0, min(x2, img.shape[1]-1))
                        y2 = max(0, min(y2, img.shape[0]-1))

                        # é€‰æ‹©é¢œè‰²
                        color = COLORS[class_id % len(COLORS)]

                        # ç»˜åˆ¶è¾¹ç•Œæ¡†
                        cv2.rectangle(img_vis, (x1, y1), (x2, y2), color, 2)

                        # ç»˜åˆ¶æ ‡ç­¾
                        class_name = COCO_CLASSES[class_id] if class_id < len(COCO_CLASSES) else f'Class{class_id}'
                        label = f'{class_name} {confidence:.2f}'

                        # è®¡ç®—æ ‡ç­¾å°ºå¯¸
                        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]

                        # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
                        cv2.rectangle(img_vis, (x1, y1-label_size[1]-5), (x1+label_size[0], y1), color, -1)

                        # ç»˜åˆ¶æ ‡ç­¾æ–‡å­—
                        cv2.putText(img_vis, label, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2)
    
    return img_vis

def run_inference_test(model, test_images, save_dir='runs/inference/final_test'):
    """è¿è¡Œæ¨ç†æµ‹è¯•"""
    print(f"\nğŸ” å¼€å§‹æ¨ç†æµ‹è¯•...")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    save_dir = Path(save_dir)
    save_dir.mkdir(parents=True, exist_ok=True)
    
    results = []
    total_time = 0
    
    for i, img_path in enumerate(test_images):
        print(f"\nğŸ“¸ å¤„ç†å›¾åƒ {i+1}/{len(test_images)}: {os.path.basename(img_path)}")
        
        # é¢„å¤„ç†
        img_tensor, img0, img0_shape = preprocess_image(img_path)
        print(f"   åŸå§‹å°ºå¯¸: {img0_shape[1]}x{img0_shape[0]}")
        print(f"   é¢„å¤„ç†å: {img_tensor.shape}")
        
        # æ¨ç†
        start_time = time.time()
        with jt.no_grad():
            pred = model(img_tensor)
        inference_time = time.time() - start_time
        total_time += inference_time
        
        print(f"   æ¨ç†æ—¶é—´: {inference_time*1000:.1f}ms")
        
        # åˆ†æåŸå§‹è¾“å‡º
        if isinstance(pred, (list, tuple)):
            print(f"   æ¨¡å‹è¾“å‡º: {len(pred)}ä¸ªå¼ é‡")
            for j, p in enumerate(pred):
                if hasattr(p, 'shape'):
                    print(f"     è¾“å‡º{j}: {p.shape}")
            
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªè¾“å‡ºè¿›è¡Œæ£€æµ‹
            pred_for_nms = pred[0] if len(pred) > 0 else pred
        else:
            pred_for_nms = pred
            print(f"   æ¨¡å‹è¾“å‡º: {pred.shape}")
        
        # åˆ†æé¢„æµ‹ç»“æœ
        if hasattr(pred_for_nms, 'shape') and len(pred_for_nms.shape) >= 2:
            pred_np = pred_for_nms.numpy()
            print(f"   é¢„æµ‹å½¢çŠ¶: {pred_for_nms.shape}")
            print(f"   é¢„æµ‹èŒƒå›´: [{pred_np.min():.6f}, {pred_np.max():.6f}]")
            
            # åˆ†æç½®ä¿¡åº¦åˆ†å¸ƒ
            if pred_for_nms.shape[-1] >= 25:  # [x, y, w, h, obj_conf, cls_conf...]
                obj_conf = pred_for_nms[:, :, 4]
                cls_conf = pred_for_nms[:, :, 5:]
                
                obj_min = float(obj_conf.min().numpy())
                obj_max = float(obj_conf.max().numpy())
                cls_min = float(cls_conf.min().numpy())
                cls_max = float(cls_conf.max().numpy())
                
                print(f"   ç›®æ ‡ç½®ä¿¡åº¦: [{obj_min:.6f}, {obj_max:.6f}]")
                print(f"   ç±»åˆ«ç½®ä¿¡åº¦: [{cls_min:.6f}, {cls_max:.6f}]")
                
                # è®¡ç®—æœ€ç»ˆç½®ä¿¡åº¦
                final_conf = obj_conf * cls_conf.max(dim=-1)[0]
                final_min = float(final_conf.min().numpy())
                final_max = float(final_conf.max().numpy())
                print(f"   æœ€ç»ˆç½®ä¿¡åº¦: [{final_min:.6f}, {final_max:.6f}]")
        
        # åå¤„ç† - ä½¿ç”¨æ›´ä½çš„ç½®ä¿¡åº¦é˜ˆå€¼
        detections = postprocess_detections(pred_for_nms.unsqueeze(0), img0_shape, conf_thres=0.1, iou_thres=0.45)
        
        # ç»Ÿè®¡æ£€æµ‹ç»“æœ
        num_det = len(detections[0]) if len(detections) > 0 and len(detections[0]) > 0 else 0
        print(f"   æ£€æµ‹æ•°é‡: {num_det}")
        
        if num_det > 0:
            det = detections[0]
            if hasattr(det, 'numpy'):
                det_np = det.numpy()
            else:
                det_np = det
            
            print(f"   æ£€æµ‹è¯¦æƒ…:")
            for j in range(min(5, len(det_np))):  # æ˜¾ç¤ºå‰5ä¸ª
                detection = det_np[j]
                # å¤„ç†åµŒå¥—æ•°ç»„æ ¼å¼
                if isinstance(detection, np.ndarray) and detection.ndim > 1:
                    detection = detection.flatten()

                if len(detection) >= 6:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å…ƒç´ 
                    x1, y1, x2, y2, conf, cls = detection[:6]
                    class_name = COCO_CLASSES[int(cls)] if int(cls) < len(COCO_CLASSES) else f'Class{int(cls)}'
                    print(f"     {j+1}: {class_name} {conf:.3f} [{int(x1)},{int(y1)},{int(x2)},{int(y2)}]")
                else:
                    print(f"     {j+1}: æ£€æµ‹æ ¼å¼é”™è¯¯: {detection}")
        
        # ç»˜åˆ¶å¯è§†åŒ–ç»“æœ
        img_vis = draw_detections(img0, detections)
        
        # ä¿å­˜ç»“æœ
        result_path = save_dir / f"{Path(img_path).stem}_result.jpg"
        cv2.imwrite(str(result_path), img_vis)
        print(f"   âœ… ç»“æœå·²ä¿å­˜: {result_path}")
        
        # è®°å½•ç»“æœ
        results.append({
            'image': os.path.basename(img_path),
            'detections': num_det,
            'inference_time': inference_time,
            'result_path': str(result_path)
        })
    
    # è¾“å‡ºæ€»ç»“
    print(f"\n" + "="*70)
    print(f"ğŸ‰ æ¨ç†æµ‹è¯•å®Œæˆï¼")
    print(f"="*70)
    print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    print(f"   æµ‹è¯•å›¾åƒæ•°é‡: {len(test_images)}")
    print(f"   æ€»æ¨ç†æ—¶é—´: {total_time:.3f}s")
    print(f"   å¹³å‡æ¨ç†æ—¶é—´: {total_time/len(test_images)*1000:.1f}ms/å›¾åƒ")
    print(f"   æ¨ç†é€Ÿåº¦: {len(test_images)/total_time:.1f} FPS")
    print(f"   æ€»æ£€æµ‹æ•°é‡: {sum(r['detections'] for r in results)}")
    
    print(f"\nğŸ“‹ è¯¦ç»†ç»“æœ:")
    for result in results:
        print(f"   {result['image']:25s} | æ£€æµ‹:{result['detections']:2d} | æ—¶é—´:{result['inference_time']*1000:5.1f}ms")
    
    print(f"\nğŸ’¾ å¯è§†åŒ–ç»“æœä¿å­˜åœ¨: {save_dir}")
    
    return results

def main():
    """ä¸»å‡½æ•°"""
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘              GOLD-YOLO æœ€ç»ˆæ¨ç†å¯è§†åŒ–æµ‹è¯•                    â•‘
    â•‘                                                              â•‘
    â•‘  ğŸ¯ ä½¿ç”¨ä¿®å¤å®Œæˆçš„æ¨¡å‹è¿›è¡Œæ¨ç†æµ‹è¯•                           â•‘
    â•‘  ğŸ“Š è¾“å‡ºè¯¦ç»†çš„æ£€æµ‹ç»“æœå’Œå¯è§†åŒ–                               â•‘
    â•‘  ğŸ” éªŒè¯æ¨¡å‹çš„å®é™…æ£€æµ‹èƒ½åŠ›                                   â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # åŠ è½½æ¨¡å‹
    model = load_trained_model()
    
    # å‡†å¤‡æµ‹è¯•å›¾åƒ
    test_dir = '/home/kyc/project/GOLD-YOLO/Gold-YOLO_pytorch/runs/inference/pytorch_baseline_test/test_images'
    
    if os.path.exists(test_dir):
        test_images = [os.path.join(test_dir, f) for f in os.listdir(test_dir) 
                      if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
        test_images = sorted(test_images)[:5]  # æµ‹è¯•å‰5å¼ å›¾åƒ
    else:
        print(f"âŒ æµ‹è¯•å›¾åƒç›®å½•ä¸å­˜åœ¨: {test_dir}")
        return
    
    print(f"ğŸ“¸ æ‰¾åˆ°æµ‹è¯•å›¾åƒ: {len(test_images)}å¼ ")
    for img in test_images:
        print(f"   - {os.path.basename(img)}")
    
    # è¿è¡Œæ¨ç†æµ‹è¯•
    results = run_inference_test(model, test_images)
    
    print(f"\nğŸ‰ GOLD-YOLO Jittorç‰ˆæœ¬æ¨ç†æµ‹è¯•å®Œæˆï¼")
    print(f"ğŸ“Š æ¨¡å‹çŠ¶æ€: å®Œå…¨ä¿®å¤ï¼Œæ­£å¸¸å·¥ä½œ")
    print(f"ğŸ¯ æ£€æµ‹èƒ½åŠ›: å·²éªŒè¯")
    print(f"ğŸ’¾ å¯è§†åŒ–ç»“æœ: å·²ç”Ÿæˆ")

if __name__ == "__main__":
    main()
