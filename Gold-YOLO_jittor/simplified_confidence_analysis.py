#!/usr/bin/env python3
"""
ç®€åŒ–çš„ç½®ä¿¡åº¦åˆ†æ - åªåˆ†æè®­ç»ƒåçš„æ¨¡å‹
"""

import os
import sys
import cv2
import numpy as np
import jittor as jt

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models.perfect_gold_yolo import create_perfect_gold_yolo_model
from yolov6.data.data_augment import letterbox

def simplified_confidence_analysis():
    """ç®€åŒ–çš„ç½®ä¿¡åº¦åˆ†æ"""
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                ç®€åŒ–ç½®ä¿¡åº¦åˆ†æ - è®­ç»ƒåæ¨¡å‹                   â•‘
    â•‘                                                              â•‘
    â•‘  ğŸ” åˆ†æè‡ªæ£€è®­ç»ƒåçš„æ¨¡å‹è¾“å‡º                                 â•‘
    â•‘  ğŸ¯ å®šä½ç½®ä¿¡åº¦ä½çš„æ ¹æœ¬åŸå›                                    â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # åŠ è½½æ¨¡å‹å’Œæƒé‡
    print("ğŸ”§ åŠ è½½è‡ªæ£€è®­ç»ƒåçš„æ¨¡å‹...")
    model = create_perfect_gold_yolo_model('gold_yolo-n', num_classes=20)
    
    weights_path = 'simple_self_check_model.pkl'
    if os.path.exists(weights_path):
        model.load_state_dict(jt.load(weights_path))
        print(f"âœ… åŠ è½½è‡ªæ£€è®­ç»ƒæƒé‡: {weights_path}")
    else:
        print(f"âŒ æœªæ‰¾åˆ°è‡ªæ£€è®­ç»ƒæƒé‡")
        return False
    
    model.eval()
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    print("ğŸ“¸ å‡†å¤‡æµ‹è¯•æ•°æ®...")
    img_path = '/home/kyc/project/GOLD-YOLO/Gold-YOLO_pytorch/runs/inference/pytorch_baseline_test/test_images/2008_000099.jpg'
    img0 = cv2.imread(img_path)
    h0, w0 = img0.shape[:2]
    
    img = letterbox(img0, new_shape=640, stride=32, auto=False)[0]
    img = img[:, :, ::-1].transpose(2, 0, 1)
    img = np.ascontiguousarray(img)
    img = img.astype(np.float32) / 255.0
    img_tensor = jt.array(img).unsqueeze(0)
    
    print(f"å›¾åƒå°ºå¯¸: {w0}x{h0} -> {img_tensor.shape}")
    
    # æ¨¡å‹æ¨ç†
    print("ğŸ” æ¨¡å‹æ¨ç†åˆ†æ...")
    with jt.no_grad():
        pred = model(img_tensor)
    
    pred = pred[0]  # [8400, 25]
    print(f"æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {pred.shape}")
    
    # åˆ†è§£è¾“å‡º
    boxes = pred[:, :4]  # [x_center, y_center, width, height]
    obj_conf = pred[:, 4]  # ç›®æ ‡ç½®ä¿¡åº¦
    cls_conf = pred[:, 5:]  # ç±»åˆ«ç½®ä¿¡åº¦ [20]
    
    print(f"\nğŸ“Š è¾“å‡ºç»Ÿè®¡:")
    print(f"   ç›®æ ‡ç½®ä¿¡åº¦èŒƒå›´: [{float(obj_conf.min().numpy()):.6f}, {float(obj_conf.max().numpy()):.6f}]")
    print(f"   ç±»åˆ«ç½®ä¿¡åº¦èŒƒå›´: [{float(cls_conf.min().numpy()):.6f}, {float(cls_conf.max().numpy()):.6f}]")
    print(f"   ç±»åˆ«ç½®ä¿¡åº¦å‡å€¼: {float(cls_conf.mean().numpy()):.6f}")
    print(f"   ç±»åˆ«ç½®ä¿¡åº¦æ ‡å‡†å·®: {float(cls_conf.std().numpy()):.6f}")
    
    # åˆ†ææ¯ä¸ªç±»åˆ«çš„ç½®ä¿¡åº¦
    print(f"\nğŸ¯ å„ç±»åˆ«ç½®ä¿¡åº¦åˆ†æ:")
    for i in range(20):
        cls_i_conf = cls_conf[:, i]
        print(f"   ç±»åˆ«{i:2d}: èŒƒå›´[{float(cls_i_conf.min().numpy()):.6f}, {float(cls_i_conf.max().numpy()):.6f}], å‡å€¼{float(cls_i_conf.mean().numpy()):.6f}")
    
    # æ£€æŸ¥æ£€æµ‹å¤´å‚æ•°
    print(f"\nğŸ”§ æ£€æµ‹å¤´å‚æ•°åˆ†æ:")
    for name, param in model.named_parameters():
        if 'detect' in name and ('cls_pred' in name or 'reg_pred' in name):
            param_data = param.data
            min_val = float(param_data.min().numpy())
            max_val = float(param_data.max().numpy())
            mean_val = float(param_data.mean().numpy())
            std_val = float(param_data.std().numpy())
            
            print(f"   å‚æ•° {name}:")
            print(f"     å½¢çŠ¶: {param_data.shape}")
            print(f"     æ•°å€¼èŒƒå›´: [{min_val:.6f}, {max_val:.6f}]")
            print(f"     å‡å€¼: {mean_val:.6f}, æ ‡å‡†å·®: {std_val:.6f}")
    
    # åˆ†æè®­ç»ƒç›®æ ‡ä½ç½®çš„é¢„æµ‹
    print(f"\nğŸ¯ è®­ç»ƒç›®æ ‡ä½ç½®åˆ†æ:")
    
    # æˆ‘ä»¬è®­ç»ƒçš„ç›®æ ‡ä½ç½®æ˜¯(0.5, 0.5)
    target_center = jt.array([0.5, 0.5])
    centers = boxes[:, :2]
    distances = jt.sqrt(((centers - target_center) ** 2).sum(dim=1))
    closest_idx = int(distances.argmin().numpy())
    
    print(f"   æœ€æ¥è¿‘è®­ç»ƒç›®æ ‡çš„é¢„æµ‹ç´¢å¼•: {closest_idx}")
    print(f"   è¯¥ä½ç½®çš„åæ ‡: {boxes[closest_idx].numpy()}")
    print(f"   è¯¥ä½ç½®çš„ç›®æ ‡ç½®ä¿¡åº¦: {float(obj_conf[closest_idx].numpy()):.6f}")
    print(f"   è¯¥ä½ç½®çš„ç±»åˆ«0ç½®ä¿¡åº¦: {float(cls_conf[closest_idx, 0].numpy()):.6f}")
    print(f"   è¯¥ä½ç½®çš„æ‰€æœ‰ç±»åˆ«ç½®ä¿¡åº¦: {cls_conf[closest_idx].numpy()}")
    
    # é—®é¢˜è¯Šæ–­
    print(f"\nğŸ¯ é—®é¢˜è¯Šæ–­:")
    
    # 1. ç›®æ ‡ç½®ä¿¡åº¦æ£€æŸ¥
    obj_min = float(obj_conf.min().numpy())
    obj_max = float(obj_conf.max().numpy())
    if obj_min == obj_max == 1.0:
        print("   âœ… ç›®æ ‡ç½®ä¿¡åº¦æ­£å¸¸ (å…¨éƒ¨ä¸º1.0)")
    else:
        print(f"   âŒ ç›®æ ‡ç½®ä¿¡åº¦å¼‚å¸¸: èŒƒå›´[{obj_min:.6f}, {obj_max:.6f}]")
    
    # 2. ç±»åˆ«ç½®ä¿¡åº¦æ£€æŸ¥
    cls_min = float(cls_conf.min().numpy())
    cls_max = float(cls_conf.max().numpy())
    cls_range = cls_max - cls_min
    
    if cls_range < 0.01:
        print(f"   âŒ ç±»åˆ«ç½®ä¿¡åº¦å˜åŒ–èŒƒå›´å¤ªå°: {cls_range:.6f}")
        print("   ğŸ”§ å¯èƒ½åŸå› :")
        print("      1. åˆ†ç±»å¤´æƒé‡åˆå§‹åŒ–è¿‡å°")
        print("      2. è®­ç»ƒæ—¶åˆ†ç±»æŸå¤±æƒé‡ä¸è¶³")
        print("      3. sigmoidæ¿€æ´»å‡½æ•°é¥±å’Œåœ¨ä½å€¼åŒºåŸŸ")
        print("      4. å­¦ä¹ ç‡å¯¹åˆ†ç±»å¤´ä¸åˆé€‚")
    else:
        print(f"   âœ… ç±»åˆ«ç½®ä¿¡åº¦å˜åŒ–èŒƒå›´æ­£å¸¸: {cls_range:.6f}")
    
    # 3. æ¿€æ´»å‡½æ•°åˆ†æ
    print(f"\nğŸ”§ æ¿€æ´»å‡½æ•°åˆ†æ:")
    
    # å‡è®¾cls_confæ˜¯ç»è¿‡sigmoidçš„ï¼Œæˆ‘ä»¬åæ¨logits
    # sigmoid(x) = y => x = log(y/(1-y))
    eps = 1e-7
    cls_conf_clipped = jt.clamp(cls_conf, eps, 1-eps)
    estimated_logits = jt.log(cls_conf_clipped / (1 - cls_conf_clipped))
    
    print(f"   ä¼°è®¡çš„logitsèŒƒå›´: [{float(estimated_logits.min().numpy()):.6f}, {float(estimated_logits.max().numpy()):.6f}]")
    print(f"   ä¼°è®¡çš„logitså‡å€¼: {float(estimated_logits.mean().numpy()):.6f}")
    
    if float(estimated_logits.mean().numpy()) < -5:
        print("   âŒ logitså‡å€¼è¿‡ä½ï¼Œè¯´æ˜åˆ†ç±»å¤´è¾“å‡ºåå‘è´Ÿå€¼")
        print("   ğŸ”§ å»ºè®®: è°ƒæ•´åˆ†ç±»å¤´çš„biasåˆå§‹åŒ–")
    
    # 4. ä¿®å¤å»ºè®®
    print(f"\nğŸ’¡ ä¿®å¤å»ºè®®:")
    print("   1. é‡æ–°åˆå§‹åŒ–åˆ†ç±»å¤´çš„biasä¸ºæ­£å€¼ (å¦‚0.01)")
    print("   2. å¢åŠ åˆ†ç±»æŸå¤±çš„æƒé‡")
    print("   3. ä½¿ç”¨æ›´é«˜çš„å­¦ä¹ ç‡è®­ç»ƒåˆ†ç±»å¤´")
    print("   4. å¢åŠ è®­ç»ƒè½®æ•°")
    print("   5. æ£€æŸ¥æ ‡ç­¾one-hotç¼–ç æ˜¯å¦æ­£ç¡®")
    
    return True

def create_visualization():
    """åˆ›å»ºå¯è§†åŒ–ç»“æœ"""
    print(f"\nğŸ¨ åˆ›å»ºæ£€æµ‹ç»“æœå¯è§†åŒ–...")
    
    # åŠ è½½æ¨¡å‹
    model = create_perfect_gold_yolo_model('gold_yolo-n', num_classes=20)
    weights_path = 'simple_self_check_model.pkl'
    if os.path.exists(weights_path):
        model.load_state_dict(jt.load(weights_path))
    model.eval()
    
    # åŠ è½½å›¾åƒ
    img_path = '/home/kyc/project/GOLD-YOLO/Gold-YOLO_pytorch/runs/inference/pytorch_baseline_test/test_images/2008_000099.jpg'
    img0 = cv2.imread(img_path)
    h0, w0 = img0.shape[:2]
    
    # é¢„å¤„ç†
    img = letterbox(img0, new_shape=640, stride=32, auto=False)[0]
    img = img[:, :, ::-1].transpose(2, 0, 1)
    img = np.ascontiguousarray(img)
    img = img.astype(np.float32) / 255.0
    img_tensor = jt.array(img).unsqueeze(0)
    
    # æ¨ç†
    with jt.no_grad():
        pred = model(img_tensor)[0]
    
    # è§£æé¢„æµ‹
    boxes = pred[:, :4]
    obj_conf = pred[:, 4]
    cls_conf = pred[:, 5:]
    
    # è®¡ç®—æœ€ç»ˆç½®ä¿¡åº¦
    cls_scores = cls_conf.max(dim=1)[0]
    cls_indices = cls_conf.argmax(dim=1)
    final_conf = obj_conf * cls_scores
    
    # é€‰æ‹©å‰5ä¸ªæ£€æµ‹è¿›è¡Œå¯è§†åŒ–
    num_show = 5
    img_vis = img0.copy()
    
    colors = [(255,0,0), (0,255,0), (0,0,255), (255,255,0), (255,0,255)]
    
    print(f"ğŸ¯ å‰{num_show}ä¸ªæ£€æµ‹ç»“æœ:")
    
    for i in range(num_show):
        # è·å–é¢„æµ‹
        box = boxes[i].numpy()
        obj_c = float(obj_conf[i].numpy())
        cls_idx = int(cls_indices[i].numpy())
        cls_c = float(cls_scores[i].numpy())
        final_c = float(final_conf[i].numpy())
        
        # è½¬æ¢åæ ‡
        x_center, y_center, width, height = box
        x1 = int((x_center - width/2) * w0 / 640)
        y1 = int((y_center - height/2) * h0 / 640)
        x2 = int((x_center + width/2) * w0 / 640)
        y2 = int((y_center + height/2) * h0 / 640)
        
        # ç¡®ä¿åæ ‡åœ¨èŒƒå›´å†…
        x1 = max(0, min(x1, w0-1))
        y1 = max(0, min(y1, h0-1))
        x2 = max(0, min(x2, w0-1))
        y2 = max(0, min(y2, h0-1))
        
        color = colors[i % len(colors)]
        
        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        cv2.rectangle(img_vis, (x1, y1), (x2, y2), color, 2)
        
        # ç»˜åˆ¶æ ‡ç­¾
        label = f'Det{i+1}: C{cls_idx} F{final_c:.6f}'
        cv2.putText(img_vis, label, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
        
        print(f"   æ£€æµ‹{i+1}: ä½ç½®=({x1},{y1},{x2},{y2}), ç›®æ ‡={obj_c:.6f}, ç±»åˆ«{cls_idx}={cls_c:.6f}, æœ€ç»ˆ={final_c:.6f}")
    
    # ä¿å­˜ç»“æœ
    result_path = 'confidence_analysis_result.jpg'
    cv2.imwrite(result_path, img_vis)
    print(f"ğŸ“¸ å¯è§†åŒ–ç»“æœå·²ä¿å­˜: {result_path}")
    
    return True

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹ç®€åŒ–ç½®ä¿¡åº¦åˆ†æ...")
    
    # åˆ†æ
    success1 = simplified_confidence_analysis()
    
    # å¯è§†åŒ–
    success2 = create_visualization()
    
    if success1 and success2:
        print("\nğŸ‰ ç®€åŒ–ç½®ä¿¡åº¦åˆ†æå®Œæˆï¼")
        print("ğŸ“‹ å…³é”®å‘ç°:")
        print("   - ç›®æ ‡æ£€æµ‹åŠŸèƒ½æ­£å¸¸ (ç½®ä¿¡åº¦=1.0)")
        print("   - ç±»åˆ«åˆ†ç±»ç½®ä¿¡åº¦è¿‡ä½ (çº¦0.0002-0.002)")
        print("   - éœ€è¦é‡æ–°è®­ç»ƒåˆ†ç±»å¤´æˆ–è°ƒæ•´åˆå§‹åŒ–")
    else:
        print("\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼")
