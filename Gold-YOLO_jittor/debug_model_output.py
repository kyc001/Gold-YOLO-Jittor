#!/usr/bin/env python3
"""
è°ƒè¯•æ¨¡å‹è¾“å‡º
"""

import os
import sys
import cv2
import numpy as np
import jittor as jt

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models.perfect_gold_yolo import create_perfect_gold_yolo_model
from yolov6.data.data_augment import letterbox

def debug_model_output():
    """è°ƒè¯•æ¨¡å‹è¾“å‡º"""
    print("ğŸ”§ è°ƒè¯•æ¨¡å‹è¾“å‡º...")
    
    # åˆ›å»ºæ¨¡å‹
    print("ğŸ“¦ åˆ›å»ºæ¨¡å‹...")
    model = create_perfect_gold_yolo_model('gold_yolo-n', num_classes=20)
    
    # åŠ è½½æƒé‡
    weights_path = '/home/kyc/project/GOLD-YOLO/runs/train/pytorch_aligned_stable/epoch_100.pkl'
    print(f"ğŸ’¾ åŠ è½½æƒé‡: {weights_path}")
    
    if os.path.exists(weights_path):
        checkpoint = jt.load(weights_path)
        if isinstance(checkpoint, dict):
            if 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
                print(f"âœ… æˆåŠŸåŠ è½½æƒé‡ (epoch: {checkpoint.get('epoch', 'unknown')})")
            elif 'model' in checkpoint:
                model.load_state_dict(checkpoint['model'])
                print(f"âœ… æˆåŠŸåŠ è½½æƒé‡ (epoch: {checkpoint.get('epoch', 'unknown')})")
            else:
                model.load_state_dict(checkpoint)
                print(f"âœ… æˆåŠŸåŠ è½½æƒé‡")
        else:
            model.load_state_dict(checkpoint)
            print(f"âœ… æˆåŠŸåŠ è½½æƒé‡")
    else:
        print(f"âŒ æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {weights_path}")
        return False
    
    model.eval()
    
    # åŠ è½½æµ‹è¯•å›¾åƒ
    img_path = '/home/kyc/project/GOLD-YOLO/Gold-YOLO_pytorch/runs/inference/pytorch_baseline_test/test_images/2008_000099.jpg'
    print(f"ğŸ“¸ åŠ è½½æµ‹è¯•å›¾åƒ: {img_path}")
    
    img0 = cv2.imread(img_path)
    print(f"åŸå§‹å›¾åƒå°ºå¯¸: {img0.shape}")
    
    # é¢„å¤„ç†
    img = letterbox(img0, new_shape=640, stride=32, auto=False)[0]
    img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, HWC to CHW
    img = np.ascontiguousarray(img)
    img = img.astype(np.float32) / 255.0  # å½’ä¸€åŒ–åˆ°[0,1]
    img = jt.array(img)
    if img.ndim == 3:
        img = img.unsqueeze(0)  # æ·»åŠ batchç»´åº¦
    
    print(f"é¢„å¤„ç†åå›¾åƒå°ºå¯¸: {img.shape}")
    
    # æ¨ç†
    print("ğŸ”§ å¼€å§‹æ¨ç†...")
    with jt.no_grad():
        outputs = model(img)
    
    print(f"æ¨¡å‹è¾“å‡ºæ•°é‡: {len(outputs)}")
    for i, output in enumerate(outputs):
        print(f"è¾“å‡º {i}: å½¢çŠ¶={output.shape}, æ•°å€¼èŒƒå›´=[{float(output.min().data):.6f}, {float(output.max().data):.6f}]")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰éé›¶å€¼
        non_zero_count = (output != 0).sum()
        print(f"è¾“å‡º {i}: éé›¶å…ƒç´ æ•°é‡={int(non_zero_count.data)}/{output.numel()}")
        
        # æ£€æŸ¥å‰å‡ ä¸ªå€¼
        if output.numel() > 0:
            flat_output = output.flatten()
            print(f"è¾“å‡º {i}: å‰10ä¸ªå€¼={flat_output[:10].numpy()}")
    
    # æ£€æŸ¥è®­ç»ƒæ¨¡å¼ä¸‹çš„è¾“å‡º
    print("\nğŸ”§ æ£€æŸ¥è®­ç»ƒæ¨¡å¼ä¸‹çš„è¾“å‡º...")
    model.train()
    with jt.no_grad():
        train_outputs = model(img)
    
    print(f"è®­ç»ƒæ¨¡å¼è¾“å‡ºæ•°é‡: {len(train_outputs)}")
    for i, output in enumerate(train_outputs):
        if hasattr(output, 'shape'):
            print(f"è®­ç»ƒè¾“å‡º {i}: å½¢çŠ¶={output.shape}, æ•°å€¼èŒƒå›´=[{float(output.min().data):.6f}, {float(output.max().data):.6f}]")
        else:
            print(f"è®­ç»ƒè¾“å‡º {i}: {type(output)}")
    
    return True

if __name__ == "__main__":
    success = debug_model_output()
    if success:
        print("ğŸ‰ æ¨¡å‹è¾“å‡ºè°ƒè¯•å®Œæˆï¼")
    else:
        print("âŒ æ¨¡å‹è¾“å‡ºè°ƒè¯•å¤±è´¥ï¼")
