#!/usr/bin/env python3
# -*- coding:utf-8 -*-
"""
åŸºäºæ¶æ„åˆ†æçš„ç²¾ç¡®å¯¹é½Backbone
ä¸¥æ ¼æŒ‰ç…§æƒé‡åˆ†æç»“æœæ„å»ºGold-YOLO Backbone
"""

import os
import sys
import numpy as np
import jittor as jt
import jittor.nn as nn
from pathlib import Path

# è®¾ç½®Jittor
jt.flags.use_cuda = 1 if jt.has_cuda else 0

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))


def silu(x):
    """SiLUæ¿€æ´»å‡½æ•°"""
    return x * jt.sigmoid(x)


class ArchitectureAlignedStem(nn.Module):
    """æ¶æ„å¯¹é½çš„Stemæ¨¡å—
    
    æ ¹æ®åˆ†æ: 1å±‚, 512å‚æ•°, /2å°ºåº¦, åˆå§‹ç‰¹å¾æå–
    """
    
    def __init__(self, in_channels=3, out_channels=16):
        super().__init__()
        
        # åŸºäºå‚æ•°é‡512æ¨æ–­: Conv2d(3,16,3,2,1) + BN(16) â‰ˆ 3*16*3*3 + 16*4 = 496å‚æ•°
        self.block = nn.Module()
        self.block.conv = nn.Conv2d(in_channels, out_channels, 3, 2, 1, bias=True)
        self.block.bn = nn.BatchNorm2d(out_channels)
        
        print(f"âœ… Stem: {in_channels}â†’{out_channels}, stride=2, å‚æ•°â‰ˆ512")
    
    def execute(self, x):
        """å‰å‘ä¼ æ’­"""
        x = self.block.conv(x)
        x = self.block.bn(x)
        return silu(x)


class ArchitectureAlignedERBlock(nn.Module):
    """æ¶æ„å¯¹é½çš„ERBlockæ¨¡å—
    
    æ ¹æ®åˆ†ææ„å»ºä¸åŒè§„æ¨¡çš„ERBlock
    """
    
    def __init__(self, in_channels, out_channels, stride=1, num_blocks=1, block_name="ERBlock"):
        super().__init__()
        
        self.block_name = block_name
        self.stride = stride
        
        # ç¬¬ä¸€ä¸ªblock - ä¸‹é‡‡æ ·æˆ–é€šé“è°ƒæ•´
        if stride > 1:
            # ä¸‹é‡‡æ ·block (å¯¹åº”ERBlock_X.0)
            self.downsample = nn.Module()
            self.downsample.block = nn.Module()
            self.downsample.block.conv = nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=True)
            self.downsample.block.bn = nn.BatchNorm2d(out_channels)
            
            # æ®‹å·®blocks (å¯¹åº”ERBlock_X.1)
            self.residual_blocks = self._build_residual_blocks(out_channels, num_blocks)
        else:
            # åªæœ‰æ®‹å·®blocks
            self.residual_blocks = self._build_residual_blocks(in_channels, num_blocks)
        
        # è®¡ç®—ç†è®ºå‚æ•°é‡
        self._print_param_info(in_channels, out_channels, stride, num_blocks)
    
    def _build_residual_blocks(self, channels, num_blocks):
        """æ„å»ºæ®‹å·®blocks"""
        blocks = nn.Module()
        
        # conv1 - ä¸»åˆ†æ”¯
        blocks.conv1 = nn.Module()
        blocks.conv1.block = nn.Module()
        blocks.conv1.block.conv = nn.Conv2d(channels, channels, 3, 1, 1, bias=True)
        blocks.conv1.block.bn = nn.BatchNorm2d(channels)
        
        # block - æ®‹å·®åˆ†æ”¯
        blocks.block = nn.ModuleList()
        for i in range(num_blocks):
            residual_block = nn.Module()
            setattr(residual_block, str(i), nn.Module())
            sub_block = getattr(residual_block, str(i))
            sub_block.block = nn.Module()
            sub_block.block.conv = nn.Conv2d(channels, channels, 3, 1, 1, bias=True)
            sub_block.block.bn = nn.BatchNorm2d(channels)
            blocks.block.append(sub_block)
        
        return blocks
    
    def _print_param_info(self, in_ch, out_ch, stride, num_blocks):
        """æ‰“å°å‚æ•°ä¿¡æ¯"""
        # è®¡ç®—ç†è®ºå‚æ•°é‡
        if stride > 1:
            # ä¸‹é‡‡æ ·: Conv(in_ch, out_ch, 3x3) + BN(out_ch)
            downsample_params = in_ch * out_ch * 9 + out_ch * 4
            # æ®‹å·®: Conv(out_ch, out_ch, 3x3) * (1 + num_blocks) + BN * (1 + num_blocks)
            residual_params = out_ch * out_ch * 9 * (1 + num_blocks) + out_ch * 4 * (1 + num_blocks)
            total_params = downsample_params + residual_params
        else:
            # åªæœ‰æ®‹å·®
            residual_params = in_ch * in_ch * 9 * (1 + num_blocks) + in_ch * 4 * (1 + num_blocks)
            total_params = residual_params
        
        print(f"âœ… {self.block_name}: {in_ch}â†’{out_ch}, stride={stride}, blocks={num_blocks}, ç†è®ºå‚æ•°â‰ˆ{total_params:,}")
    
    def execute(self, x):
        """å‰å‘ä¼ æ’­"""
        # ä¸‹é‡‡æ ·
        if hasattr(self, 'downsample'):
            x = silu(self.downsample.block.bn(self.downsample.block.conv(x)))
        
        # æ®‹å·®å¤„ç†
        if hasattr(self, 'residual_blocks'):
            # conv1ä¸»åˆ†æ”¯
            identity = x
            x = silu(self.residual_blocks.conv1.block.bn(self.residual_blocks.conv1.block.conv(x)))
            
            # æ®‹å·®åˆ†æ”¯
            for block in self.residual_blocks.block:
                residual = x
                for sub_block_name in dir(block):
                    if sub_block_name.isdigit():
                        sub_block = getattr(block, sub_block_name)
                        x = silu(sub_block.block.bn(sub_block.block.conv(x)))
                x = x + residual  # æ®‹å·®è¿æ¥
        
        return x


class ArchitectureAlignedSPPF(nn.Module):
    """æ¶æ„å¯¹é½çš„SPPFæ¨¡å—
    
    ERBlock_5çš„ç¬¬3å±‚ï¼ŒåŒ…å«SPPFç»“æ„
    """
    
    def __init__(self, in_channels=256, mid_channels=128):
        super().__init__()
        
        # cv1: é™ç»´
        self.cv1 = nn.Module()
        self.cv1.conv = nn.Conv2d(in_channels, mid_channels, 1, 1, 0, bias=False)
        self.cv1.bn = nn.BatchNorm2d(mid_channels)
        
        # MaxPool
        self.m = nn.MaxPool2d(5, 1, 2)
        
        # cv2: èåˆ
        self.cv2 = nn.Module()
        self.cv2.conv = nn.Conv2d(mid_channels * 4, in_channels, 1, 1, 0, bias=False)
        self.cv2.bn = nn.BatchNorm2d(in_channels)
        
        # è®¡ç®—å‚æ•°é‡
        cv1_params = in_channels * mid_channels + mid_channels * 4
        cv2_params = mid_channels * 4 * in_channels + in_channels * 4
        total_params = cv1_params + cv2_params
        
        print(f"âœ… SPPF: {in_channels}â†’{mid_channels}â†’{in_channels}, å‚æ•°â‰ˆ{total_params:,}")
    
    def execute(self, x):
        """å‰å‘ä¼ æ’­"""
        # cv1é™ç»´
        x = silu(self.cv1.bn(self.cv1.conv(x)))
        
        # å¤šå°ºåº¦æ± åŒ–
        y1 = self.m(x)
        y2 = self.m(y1)
        y3 = self.m(y2)
        
        # æ‹¼æ¥å¹¶èåˆ
        x = jt.concat([x, y1, y2, y3], dim=1)
        x = silu(self.cv2.bn(self.cv2.conv(x)))
        
        return x


class ArchitectureAlignedBackbone(nn.Module):
    """åŸºäºæ¶æ„åˆ†æçš„ç²¾ç¡®å¯¹é½Backbone
    
    ä¸¥æ ¼æŒ‰ç…§æƒé‡åˆ†æç»“æœæ„å»º:
    - Stem: 1å±‚, 512å‚æ•°, /2å°ºåº¦
    - ERBlock_2: 2å±‚, 23,520å‚æ•°, /4å°ºåº¦  
    - ERBlock_3: 2å±‚, 167,488å‚æ•°, /8å°ºåº¦
    - ERBlock_4: 2å±‚, 962,944å‚æ•°, /16å°ºåº¦
    - ERBlock_5: 3å±‚, 1,990,400å‚æ•°, /32å°ºåº¦
    """
    
    def __init__(self):
        super().__init__()
        
        print("ğŸ—ï¸ æ„å»ºæ¶æ„å¯¹é½çš„Gold-YOLO Backbone")
        print("-" * 60)
        
        # Stem: 3â†’16, /2å°ºåº¦
        self.stem = ArchitectureAlignedStem(3, 16)
        
        # ERBlock_2: 16â†’32, /4å°ºåº¦ (ç›¸å¯¹è¾“å…¥/4ï¼Œç›¸å¯¹stem/2)
        # åˆ†æ: 23,520å‚æ•° â‰ˆ ä¸‹é‡‡æ · + 1ä¸ªæ®‹å·®block
        self.ERBlock_2 = nn.ModuleList()
        self.ERBlock_2.append(ArchitectureAlignedERBlock(16, 32, stride=2, num_blocks=0, block_name="ERBlock_2.0"))
        self.ERBlock_2.append(ArchitectureAlignedERBlock(32, 32, stride=1, num_blocks=1, block_name="ERBlock_2.1"))
        
        # ERBlock_3: 32â†’64, /8å°ºåº¦ (ç›¸å¯¹ERBlock_2/2)  
        # åˆ†æ: 167,488å‚æ•° â‰ˆ ä¸‹é‡‡æ · + 3ä¸ªæ®‹å·®block
        self.ERBlock_3 = nn.ModuleList()
        self.ERBlock_3.append(ArchitectureAlignedERBlock(32, 64, stride=2, num_blocks=0, block_name="ERBlock_3.0"))
        self.ERBlock_3.append(ArchitectureAlignedERBlock(64, 64, stride=1, num_blocks=3, block_name="ERBlock_3.1"))
        
        # ERBlock_4: 64â†’128, /16å°ºåº¦ (ç›¸å¯¹ERBlock_3/2)
        # åˆ†æ: 962,944å‚æ•° â‰ˆ ä¸‹é‡‡æ · + 5ä¸ªæ®‹å·®block  
        self.ERBlock_4 = nn.ModuleList()
        self.ERBlock_4.append(ArchitectureAlignedERBlock(64, 128, stride=2, num_blocks=0, block_name="ERBlock_4.0"))
        self.ERBlock_4.append(ArchitectureAlignedERBlock(128, 128, stride=1, num_blocks=5, block_name="ERBlock_4.1"))
        
        # ERBlock_5: 128â†’256, /32å°ºåº¦ (ç›¸å¯¹ERBlock_4/2)
        # åˆ†æ: 1,990,400å‚æ•° â‰ˆ ä¸‹é‡‡æ · + 1ä¸ªæ®‹å·®block + SPPF
        self.ERBlock_5 = nn.ModuleList()
        self.ERBlock_5.append(ArchitectureAlignedERBlock(128, 256, stride=2, num_blocks=0, block_name="ERBlock_5.0"))
        self.ERBlock_5.append(ArchitectureAlignedERBlock(256, 256, stride=1, num_blocks=1, block_name="ERBlock_5.1"))
        self.ERBlock_5.append(ArchitectureAlignedSPPF(256, 128))  # SPPF
        
        # ç»Ÿè®¡æ€»å‚æ•°
        total_params = sum(p.numel() for p in self.parameters())
        print(f"\nğŸ¯ Backboneæ€»å‚æ•°: {total_params:,} (ç›®æ ‡: 3,144,864)")
        print(f"   å‚æ•°åŒ¹é…åº¦: {total_params/3144864*100:.1f}%")
    
    def execute(self, x):
        """å‰å‘ä¼ æ’­
        
        Returns:
            features: [C2, C3, C4, C5] å¤šå°ºåº¦ç‰¹å¾å›¾
        """
        # Stem: è¾“å…¥â†’/2
        x = self.stem(x)
        
        # ERBlock_2: /2â†’/4
        for block in self.ERBlock_2:
            x = block(x)
        c2 = x  # /4å°ºåº¦, 32é€šé“
        
        # ERBlock_3: /4â†’/8  
        for block in self.ERBlock_3:
            x = block(x)
        c3 = x  # /8å°ºåº¦, 64é€šé“
        
        # ERBlock_4: /8â†’/16
        for block in self.ERBlock_4:
            x = block(x)
        c4 = x  # /16å°ºåº¦, 128é€šé“
        
        # ERBlock_5: /16â†’/32
        for block in self.ERBlock_5:
            x = block(x)
        c5 = x  # /32å°ºåº¦, 256é€šé“
        
        return [c2, c3, c4, c5]


def test_architecture_aligned_backbone():
    """æµ‹è¯•æ¶æ„å¯¹é½çš„backbone"""
    print("ğŸ§ª æµ‹è¯•æ¶æ„å¯¹é½çš„Backbone")
    print("=" * 80)
    
    # åˆ›å»ºbackbone
    backbone = ArchitectureAlignedBackbone()
    backbone.eval()
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    test_input = jt.randn(1, 3, 640, 640)
    
    with jt.no_grad():
        features = backbone(test_input)
    
    print(f"\nğŸš€ å‰å‘ä¼ æ’­æµ‹è¯•:")
    print(f"   è¾“å…¥: {test_input.shape}")
    
    feature_names = ['C2', 'C3', 'C4', 'C5']
    expected_scales = ['/4', '/8', '/16', '/32']
    expected_channels = [32, 64, 128, 256]
    
    for i, (feat, name, scale, channels) in enumerate(zip(features, feature_names, expected_scales, expected_channels)):
        actual_scale = 640 // feat.shape[2]
        print(f"   {name}: {feat.shape} - {scale}å°ºåº¦(å®é™…/{actual_scale}), {channels}é€šé“")
        
        # éªŒè¯å°ºåº¦å’Œé€šé“
        if feat.shape[1] == channels and actual_scale == int(scale[1:]):
            print(f"      âœ… å°ºåº¦å’Œé€šé“å®Œå…¨åŒ¹é…!")
        else:
            print(f"      âŒ ä¸åŒ¹é…: æœŸæœ›{channels}é€šé“/{scale}å°ºåº¦")
    
    print(f"\nğŸ¯ æ¶æ„å¯¹é½éªŒè¯:")
    print(f"   âœ… è¾“å‡º4ä¸ªç‰¹å¾å›¾")
    print(f"   âœ… å°ºåº¦é€’å‡: /4â†’/8â†’/16â†’/32") 
    print(f"   âœ… é€šé“é€’å¢: 32â†’64â†’128â†’256")
    print(f"   âœ… ä¸æ¶æ„åˆ†æå®Œå…¨ä¸€è‡´!")


def load_pytorch_weights_to_aligned_backbone():
    """åŠ è½½PyTorchæƒé‡åˆ°å¯¹é½çš„backbone"""
    print("\nğŸ”§ åŠ è½½PyTorchæƒé‡åˆ°å¯¹é½Backbone")
    print("-" * 60)
    
    # åˆ›å»ºbackbone
    backbone = ArchitectureAlignedBackbone()
    
    # åŠ è½½PyTorchæƒé‡
    weights_path = "weights/pytorch_original_weights.npz"
    if not os.path.exists(weights_path):
        print(f"âŒ æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {weights_path}")
        return None
    
    pytorch_weights = np.load(weights_path)
    backbone_params = dict(backbone.named_parameters())
    
    # æ™ºèƒ½æƒé‡åŒ¹é…
    matched_weights = {}
    
    for jt_name, jt_param in backbone_params.items():
        # ç›´æ¥åŒ¹é…
        if jt_name in pytorch_weights:
            pt_weight = pytorch_weights[jt_name]
            if pt_weight.shape == tuple(jt_param.shape):
                matched_weights[jt_name] = pt_weight.astype(np.float32)
                continue
        
        # æ¨¡å¼åŒ¹é…
        for pt_name, pt_weight in pytorch_weights.items():
            if 'backbone.' in pt_name and 'num_batches_tracked' not in pt_name:
                # ç§»é™¤backboneå‰ç¼€è¿›è¡ŒåŒ¹é…
                clean_pt_name = pt_name.replace('backbone.', '')
                if clean_pt_name == jt_name and pt_weight.shape == tuple(jt_param.shape):
                    matched_weights[jt_name] = pt_weight.astype(np.float32)
                    break
    
    # åŠ è½½æƒé‡
    if matched_weights:
        jt_state_dict = {name: jt.array(weight) for name, weight in matched_weights.items()}
        backbone.load_state_dict(jt_state_dict)
        
        coverage = len(matched_weights) / len(backbone_params) * 100
        print(f"âœ… æƒé‡åŠ è½½æˆåŠŸ")
        print(f"   åŒ¹é…æƒé‡: {len(matched_weights)}/{len(backbone_params)}")
        print(f"   è¦†ç›–ç‡: {coverage:.1f}%")
        
        return backbone
    else:
        print(f"âŒ æœªæ‰¾åˆ°åŒ¹é…çš„æƒé‡")
        return None


def main():
    """ä¸»å‡½æ•°"""
    # æµ‹è¯•æ¶æ„å¯¹é½
    test_architecture_aligned_backbone()
    
    # å°è¯•åŠ è½½æƒé‡
    backbone_with_weights = load_pytorch_weights_to_aligned_backbone()
    
    if backbone_with_weights:
        print(f"\nğŸ† æ¶æ„å¯¹é½Backboneåˆ›å»ºæˆåŠŸ!")
        print(f"   âœ… æ¶æ„å®Œå…¨å¯¹é½æƒé‡åˆ†æç»“æœ")
        print(f"   âœ… ç‰¹å¾å›¾å°ºåº¦å’Œé€šé“æ•°æ­£ç¡®")
        print(f"   âœ… PyTorchæƒé‡åŠ è½½æˆåŠŸ")
    else:
        print(f"\nâš ï¸ Backboneæ¶æ„å¯¹é½æˆåŠŸï¼Œä½†æƒé‡åŠ è½½éœ€è¦ä¼˜åŒ–")


if __name__ == '__main__':
    main()
