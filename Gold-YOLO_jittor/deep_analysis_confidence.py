#!/usr/bin/env python3
"""
æ·±å…¥åˆ†æç½®ä¿¡åº¦ä½çš„åŸå› 
"""

import os
import sys
import cv2
import numpy as np
import jittor as jt

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models.perfect_gold_yolo import create_perfect_gold_yolo_model
from yolov6.data.data_augment import letterbox

def deep_analysis_confidence():
    """æ·±å…¥åˆ†æç½®ä¿¡åº¦é—®é¢˜"""
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                  æ·±å…¥åˆ†æç½®ä¿¡åº¦ä½çš„åŸå›                        â•‘
    â•‘                                                              â•‘
    â•‘  ğŸ” åˆ†ææ¨¡å‹å„å±‚è¾“å‡º                                         â•‘
    â•‘  ğŸ¯ å®šä½é—®é¢˜æ ¹æº                                             â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ”§ åŠ è½½æ¨¡å‹...")
    model = create_perfect_gold_yolo_model('gold_yolo-n', num_classes=20)
    
    # å¯¹æ¯”ï¼šåŠ è½½è‡ªæ£€è®­ç»ƒæƒé‡ vs åˆå§‹æƒé‡
    print("\nğŸ“Š å¯¹æ¯”åˆ†æï¼šåˆå§‹æƒé‡ vs è‡ªæ£€è®­ç»ƒæƒé‡")
    
    # 1. æµ‹è¯•åˆå§‹æƒé‡
    print("\nğŸ” æµ‹è¯•1ï¼šåˆå§‹æƒé‡æ¨¡å‹")
    model.eval()
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    img_path = '/home/kyc/project/GOLD-YOLO/Gold-YOLO_pytorch/runs/inference/pytorch_baseline_test/test_images/2008_000099.jpg'
    img0 = cv2.imread(img_path)
    h0, w0 = img0.shape[:2]
    
    img = letterbox(img0, new_shape=640, stride=32, auto=False)[0]
    img = img[:, :, ::-1].transpose(2, 0, 1)
    img = np.ascontiguousarray(img)
    img = img.astype(np.float32) / 255.0
    img_tensor = jt.array(img).unsqueeze(0)
    
    with jt.no_grad():
        pred_init = model(img_tensor)
    
    # åˆ†æåˆå§‹æƒé‡è¾“å‡º
    pred_init = pred_init[0]  # [8400, 25]
    obj_conf_init = pred_init[:, 4]
    cls_conf_init = pred_init[:, 5:]
    
    print(f"   åˆå§‹æƒé‡ - ç›®æ ‡ç½®ä¿¡åº¦èŒƒå›´: [{float(obj_conf_init.min().numpy()):.6f}, {float(obj_conf_init.max().numpy()):.6f}]")
    print(f"   åˆå§‹æƒé‡ - ç±»åˆ«ç½®ä¿¡åº¦èŒƒå›´: [{float(cls_conf_init.min().numpy()):.6f}, {float(cls_conf_init.max().numpy()):.6f}]")
    
    # 2. æµ‹è¯•è‡ªæ£€è®­ç»ƒæƒé‡
    print("\nğŸ” æµ‹è¯•2ï¼šè‡ªæ£€è®­ç»ƒæƒé‡æ¨¡å‹")
    weights_path = 'simple_self_check_model.pkl'
    if os.path.exists(weights_path):
        model.load_state_dict(jt.load(weights_path))
        print(f"   âœ… åŠ è½½è‡ªæ£€è®­ç»ƒæƒé‡: {weights_path}")
    else:
        print(f"   âŒ æœªæ‰¾åˆ°è‡ªæ£€è®­ç»ƒæƒé‡")
        return False
    
    model.eval()
    
    with jt.no_grad():
        pred_trained = model(img_tensor)
    
    # åˆ†æè®­ç»ƒåè¾“å‡º
    pred_trained = pred_trained[0]  # [8400, 25]
    obj_conf_trained = pred_trained[:, 4]
    cls_conf_trained = pred_trained[:, 5:]
    
    print(f"   è®­ç»ƒå - ç›®æ ‡ç½®ä¿¡åº¦èŒƒå›´: [{float(obj_conf_trained.min().numpy()):.6f}, {float(obj_conf_trained.max().numpy()):.6f}]")
    print(f"   è®­ç»ƒå - ç±»åˆ«ç½®ä¿¡åº¦èŒƒå›´: [{float(cls_conf_trained.min().numpy()):.6f}, {float(cls_conf_trained.max().numpy()):.6f}]")
    
    # 3. åˆ†ææ£€æµ‹å¤´å‚æ•°
    print("\nğŸ” æµ‹è¯•3ï¼šæ£€æµ‹å¤´å‚æ•°åˆ†æ")
    
    # æ£€æŸ¥æ£€æµ‹å¤´çš„æƒé‡
    for name, param in model.named_parameters():
        if 'detect' in name and ('cls_pred' in name or 'reg_pred' in name):
            param_data = param.data
            print(f"   å‚æ•° {name}:")
            print(f"     å½¢çŠ¶: {param_data.shape}")
            min_val = param_data.min()
            max_val = param_data.max()
            mean_val = param_data.mean()
            std_val = param_data.std()

            print(f"     æ•°å€¼èŒƒå›´: [{float(min_val.numpy()):.6f}, {float(max_val.numpy()):.6f}]")
            print(f"     å‡å€¼: {float(mean_val.numpy()):.6f}")
            print(f"     æ ‡å‡†å·®: {float(std_val.numpy()):.6f}")
    
    # 4. åˆ†ææ¿€æ´»å‡½æ•°è¾“å‡º
    print("\nğŸ” æµ‹è¯•4ï¼šæ¿€æ´»å‡½æ•°åˆ†æ")
    
    # æ£€æŸ¥sigmoidæ¿€æ´»å‰åçš„å€¼
    raw_cls_logits = cls_conf_trained  # è¿™äº›åº”è¯¥æ˜¯sigmoidä¹‹å‰çš„logits
    print(f"   ç±»åˆ«logitsèŒƒå›´: [{float(raw_cls_logits.min().numpy()):.6f}, {float(raw_cls_logits.max().numpy()):.6f}]")
    print(f"   ç±»åˆ«logitså‡å€¼: {float(raw_cls_logits.mean().numpy()):.6f}")

    # æ‰‹åŠ¨åº”ç”¨sigmoidçœ‹çœ‹
    manual_sigmoid = jt.sigmoid(raw_cls_logits)
    print(f"   æ‰‹åŠ¨sigmoidåèŒƒå›´: [{float(manual_sigmoid.min().numpy()):.6f}, {float(manual_sigmoid.max().numpy()):.6f}]")
    
    # 5. æ£€æŸ¥è®­ç»ƒç›®æ ‡
    print("\nğŸ” æµ‹è¯•5ï¼šè®­ç»ƒç›®æ ‡åˆ†æ")
    
    # æ£€æŸ¥æˆ‘ä»¬è®­ç»ƒæ—¶ä½¿ç”¨çš„æ ‡ç­¾
    train_target = jt.array([[0, 0.5, 0.5, 0.8, 0.8, 0]], dtype='float32')
    print(f"   è®­ç»ƒç›®æ ‡: {train_target.numpy()}")
    print(f"   ç›®æ ‡ç±»åˆ«: {int(train_target[0, 0].numpy())}")
    print(f"   ç›®æ ‡ä½ç½®: [{float(train_target[0, 1].numpy()):.2f}, {float(train_target[0, 2].numpy()):.2f}]")
    print(f"   ç›®æ ‡å°ºå¯¸: [{float(train_target[0, 3].numpy()):.2f}, {float(train_target[0, 4].numpy()):.2f}]")
    
    # 6. æ£€æŸ¥å¯¹åº”ä½ç½®çš„é¢„æµ‹
    print("\nğŸ” æµ‹è¯•6ï¼šç›®æ ‡ä½ç½®é¢„æµ‹åˆ†æ")
    
    # æ‰¾åˆ°æœ€æ¥è¿‘è®­ç»ƒç›®æ ‡ä½ç½®çš„é¢„æµ‹
    boxes = pred_trained[:, :4]  # [x_center, y_center, width, height]
    target_center = jt.array([0.5, 0.5])  # è®­ç»ƒç›®æ ‡ä¸­å¿ƒ
    
    # è®¡ç®—è·ç¦»
    centers = boxes[:, :2]  # é¢„æµ‹ä¸­å¿ƒç‚¹
    distances = jt.sqrt(((centers - target_center) ** 2).sum(dim=1))
    closest_idx = distances.argmin(dim=0)[0]
    
    print(f"   æœ€æ¥è¿‘ç›®æ ‡ä½ç½®çš„é¢„æµ‹ç´¢å¼•: {int(closest_idx.numpy())}")
    print(f"   è¯¥ä½ç½®çš„ç›®æ ‡ç½®ä¿¡åº¦: {float(obj_conf_trained[closest_idx].numpy()):.6f}")
    print(f"   è¯¥ä½ç½®çš„ç±»åˆ«ç½®ä¿¡åº¦: {cls_conf_trained[closest_idx].numpy()}")
    print(f"   è¯¥ä½ç½®é¢„æµ‹çš„ç±»åˆ«0ç½®ä¿¡åº¦: {float(cls_conf_trained[closest_idx, 0].numpy()):.6f}")
    
    # 7. é—®é¢˜è¯Šæ–­
    print("\nğŸ¯ é—®é¢˜è¯Šæ–­:")
    
    if float(obj_conf_trained.min().numpy()) == float(obj_conf_trained.max().numpy()) == 1.0:
        print("   âœ… ç›®æ ‡ç½®ä¿¡åº¦æ­£å¸¸ (å…¨éƒ¨ä¸º1.0)")
    else:
        print("   âŒ ç›®æ ‡ç½®ä¿¡åº¦å¼‚å¸¸")

    cls_range = float(cls_conf_trained.max().numpy()) - float(cls_conf_trained.min().numpy())
    if cls_range < 0.01:
        print(f"   âŒ ç±»åˆ«ç½®ä¿¡åº¦å˜åŒ–èŒƒå›´å¤ªå° ({cls_range:.6f})")
        print("   ğŸ”§ å¯èƒ½åŸå› ï¼š")
        print("      1. ç±»åˆ«åˆ†ç±»å¤´æƒé‡åˆå§‹åŒ–ä¸å½“")
        print("      2. è®­ç»ƒæ—¶ç±»åˆ«æŸå¤±æƒé‡å¤ªå°")
        print("      3. æ¿€æ´»å‡½æ•°é¥±å’Œ")
        print("      4. å­¦ä¹ ç‡å¯¹åˆ†ç±»å¤´ä¸åˆé€‚")
    else:
        print(f"   âœ… ç±»åˆ«ç½®ä¿¡åº¦å˜åŒ–èŒƒå›´æ­£å¸¸ ({cls_range:.6f})")
    
    # 8. å»ºè®®çš„ä¿®å¤æ–¹æ¡ˆ
    print("\nğŸ’¡ å»ºè®®çš„ä¿®å¤æ–¹æ¡ˆ:")
    print("   1. é‡æ–°åˆå§‹åŒ–åˆ†ç±»å¤´æƒé‡")
    print("   2. å¢åŠ åˆ†ç±»æŸå¤±æƒé‡")
    print("   3. è°ƒæ•´å­¦ä¹ ç‡ç­–ç•¥")
    print("   4. å¢åŠ è®­ç»ƒè½®æ•°")
    print("   5. æ£€æŸ¥æ ‡ç­¾æ ¼å¼æ˜¯å¦æ­£ç¡®")
    
    return True

def visualize_detection_with_analysis():
    """å¯è§†åŒ–æ£€æµ‹ç»“æœå¹¶åˆ†æ"""
    print("\nğŸ¨ åˆ›å»ºè¯¦ç»†çš„æ£€æµ‹ç»“æœå¯è§†åŒ–...")
    
    # åŠ è½½æ¨¡å‹å’Œæƒé‡
    model = create_perfect_gold_yolo_model('gold_yolo-n', num_classes=20)
    weights_path = 'simple_self_check_model.pkl'
    if os.path.exists(weights_path):
        model.load_state_dict(jt.load(weights_path))
    
    model.eval()
    
    # åŠ è½½å›¾åƒ
    img_path = '/home/kyc/project/GOLD-YOLO/Gold-YOLO_pytorch/runs/inference/pytorch_baseline_test/test_images/2008_000099.jpg'
    img0 = cv2.imread(img_path)
    h0, w0 = img0.shape[:2]
    
    # é¢„å¤„ç†
    img = letterbox(img0, new_shape=640, stride=32, auto=False)[0]
    img = img[:, :, ::-1].transpose(2, 0, 1)
    img = np.ascontiguousarray(img)
    img = img.astype(np.float32) / 255.0
    img_tensor = jt.array(img).unsqueeze(0)
    
    # æ¨ç†
    with jt.no_grad():
        pred = model(img_tensor)[0]  # [8400, 25]
    
    # è§£æé¢„æµ‹
    boxes = pred[:, :4]
    obj_conf = pred[:, 4]
    cls_conf = pred[:, 5:]
    
    # é€‰æ‹©å‰10ä¸ªæ£€æµ‹è¿›è¡Œå¯è§†åŒ–
    num_show = 10
    
    # åˆ›å»ºå¯è§†åŒ–å›¾åƒ
    img_vis = img0.copy()
    
    # ç»˜åˆ¶æ£€æµ‹ç»“æœ
    colors = [(255,0,0), (0,255,0), (0,0,255), (255,255,0), (255,0,255), 
              (0,255,255), (128,0,128), (255,165,0), (0,128,128), (128,128,0)]
    
    for i in range(num_show):
        # è·å–é¢„æµ‹
        box = boxes[i].numpy()
        obj_c = float(obj_conf[i].data)
        cls_c = cls_conf[i].numpy()
        
        # è½¬æ¢åæ ‡
        x_center, y_center, width, height = box
        x1 = int((x_center - width/2) * w0 / 640)
        y1 = int((y_center - height/2) * h0 / 640)
        x2 = int((x_center + width/2) * w0 / 640)
        y2 = int((y_center + height/2) * h0 / 640)
        
        # ç¡®ä¿åæ ‡åœ¨èŒƒå›´å†…
        x1 = max(0, min(x1, w0-1))
        y1 = max(0, min(y1, h0-1))
        x2 = max(0, min(x2, w0-1))
        y2 = max(0, min(y2, h0-1))
        
        # è·å–æœ€é«˜ç±»åˆ«
        max_cls_idx = np.argmax(cls_c)
        max_cls_conf = cls_c[max_cls_idx]
        final_conf = obj_c * max_cls_conf
        
        color = colors[i % len(colors)]
        
        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        cv2.rectangle(img_vis, (x1, y1), (x2, y2), color, 2)
        
        # ç»˜åˆ¶è¯¦ç»†æ ‡ç­¾
        label = f'Det{i+1}: C{max_cls_idx}'
        label2 = f'Obj:{obj_c:.4f} Cls:{max_cls_conf:.4f}'
        label3 = f'Final:{final_conf:.6f}'
        
        # ç»˜åˆ¶å¤šè¡Œæ ‡ç­¾
        cv2.putText(img_vis, label, (x1, y1-25), cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
        cv2.putText(img_vis, label2, (x1, y1-15), cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)
        cv2.putText(img_vis, label3, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)
        
        print(f"æ£€æµ‹{i+1}: ä½ç½®=({x1},{y1},{x2},{y2}), ç›®æ ‡ç½®ä¿¡åº¦={obj_c:.6f}, ç±»åˆ«{max_cls_idx}ç½®ä¿¡åº¦={max_cls_conf:.6f}, æœ€ç»ˆ={final_conf:.6f}")
    
    # ä¿å­˜å¯è§†åŒ–ç»“æœ
    result_path = 'detailed_detection_analysis.jpg'
    cv2.imwrite(result_path, img_vis)
    print(f"\nğŸ“¸ è¯¦ç»†æ£€æµ‹åˆ†æå›¾å·²ä¿å­˜: {result_path}")
    
    return True

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹æ·±å…¥åˆ†æç½®ä¿¡åº¦é—®é¢˜...")
    
    # æ·±å…¥åˆ†æ
    success1 = deep_analysis_confidence()
    
    # å¯è§†åŒ–åˆ†æ
    success2 = visualize_detection_with_analysis()
    
    if success1 and success2:
        print("\nğŸ‰ æ·±å…¥åˆ†æå®Œæˆï¼")
        print("ğŸ“‹ åˆ†æç»“æœæ€»ç»“ï¼š")
        print("   - ç›®æ ‡æ£€æµ‹åŠŸèƒ½æ­£å¸¸")
        print("   - ç±»åˆ«åˆ†ç±»ç½®ä¿¡åº¦è¿‡ä½")
        print("   - éœ€è¦é‡æ–°è®­ç»ƒåˆ†ç±»å¤´æˆ–è°ƒæ•´è®­ç»ƒç­–ç•¥")
    else:
        print("\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼")
