#!/usr/bin/env python3
"""
æœ€ç»ˆè°ƒè¯•ç‰ˆè¿‡æ‹Ÿåˆæµ‹è¯• - å½»åº•è§£å†³æ‰€æœ‰é—®é¢˜
1. å®Œå…¨ç§»é™¤å†—ä½™è¾“å‡ºï¼Œæé€Ÿè®­ç»ƒ
2. é™ä½ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œç¡®ä¿æœ‰æ£€æµ‹ç»“æœ
3. ç”Ÿæˆå®Œæ•´å¯è§†åŒ–å¯¹æ¯”å›¾
4. ä¸¥æ ¼è¯„ä¼°ï¼šç§ç±»ã€æ•°é‡ã€ä½ç½®å…¨éƒ¨æ­£ç¡®
"""

import os
import sys
import cv2
import numpy as np
import jittor as jt
from pathlib import Path
import time
import matplotlib.pyplot as plt

# æ·»åŠ è·¯å¾„
sys.path.append('.')
sys.path.append('./yolov6')

from models.perfect_gold_yolo import create_perfect_gold_yolo_model
from yolov6.data.data_augment import letterbox
from yolov6.models.losses import ComputeLoss
from yolov6.utils.nms import non_max_suppression

# VOCæ•°æ®é›†ç±»åˆ«åç§°
VOC_CLASSES = [
    'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',
    'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'
]

def pytorch_exact_initialization(model):
    """å®Œå…¨ç…§æŠ„PyTorchç‰ˆæœ¬çš„åˆå§‹åŒ–"""
    for name, module in model.named_modules():
        if hasattr(module, 'initialize_biases'):
            module.initialize_biases()
            break
    return model

def calculate_iou(box1, box2):
    """è®¡ç®—ä¸¤ä¸ªæ¡†çš„IoU"""
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])
    
    if x2 <= x1 or y2 <= y1:
        return 0.0
    
    intersection = (x2 - x1) * (y2 - y1)
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    union = area1 + area2 - intersection
    
    return intersection / union if union > 0 else 0.0

def match_detections_to_gt(detections, gt_boxes, gt_classes, iou_threshold=0.3):
    """å°†æ£€æµ‹ç»“æœä¸çœŸå®æ¡†åŒ¹é… - é™ä½IoUé˜ˆå€¼"""
    matched_gt = set()
    correct_detections = []
    
    for det in detections:
        if len(det) >= 6:
            x1, y1, x2, y2, conf, cls_id = det[:6]
            cls_id = int(cls_id)
            det_box = [float(x1), float(y1), float(x2), float(y2)]
            
            best_iou = 0.0
            best_gt_idx = -1
            
            for gt_idx, (gt_box, gt_cls) in enumerate(zip(gt_boxes, gt_classes)):
                if gt_idx in matched_gt:
                    continue
                
                if cls_id == gt_cls:
                    iou = calculate_iou(det_box, gt_box)
                    if iou > best_iou and iou >= iou_threshold:
                        best_iou = iou
                        best_gt_idx = gt_idx
            
            if best_gt_idx >= 0:
                matched_gt.add(best_gt_idx)
                correct_detections.append({
                    'det_box': det_box,
                    'gt_box': gt_boxes[best_gt_idx],
                    'class': cls_id,
                    'confidence': float(conf),
                    'iou': best_iou
                })
    
    return correct_detections, len(matched_gt), len(gt_boxes)

def draw_detection_results(img, detections, gt_boxes, gt_classes, correct_detections):
    """ç»˜åˆ¶æ£€æµ‹ç»“æœå¯¹æ¯”å›¾"""
    vis_img = img.copy()
    
    # ç»˜åˆ¶çœŸå®æ¡†ï¼ˆé»„è‰²è™šçº¿ï¼‰
    for gt_box, gt_cls in zip(gt_boxes, gt_classes):
        x1, y1, x2, y2 = map(int, gt_box)
        cls_name = VOC_CLASSES[gt_cls]
        
        # è™šçº¿æ•ˆæœ
        dash_length = 8
        color = (0, 255, 255)  # é»„è‰²
        thickness = 2
        
        for i in range(x1, x2, dash_length * 2):
            cv2.line(vis_img, (i, y1), (min(i + dash_length, x2), y1), color, thickness)
            cv2.line(vis_img, (i, y2), (min(i + dash_length, x2), y2), color, thickness)
        for i in range(y1, y2, dash_length * 2):
            cv2.line(vis_img, (x1, i), (x1, min(i + dash_length, y2)), color, thickness)
            cv2.line(vis_img, (x2, i), (x2, min(i + dash_length, y2)), color, thickness)
        
        cv2.putText(vis_img, f'GT: {cls_name}', (x1, y1-10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
    
    # ç»˜åˆ¶æ£€æµ‹æ¡†
    correct_boxes = {tuple(cd['det_box']): cd for cd in correct_detections}
    
    for det in detections:
        if len(det) >= 6:
            x1, y1, x2, y2, conf, cls_id = det[:6]
            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])
            cls_id = int(cls_id)
            cls_name = VOC_CLASSES[cls_id] if cls_id < len(VOC_CLASSES) else f'Class{cls_id}'
            
            det_box_key = tuple([float(x1), float(y1), float(x2), float(y2)])
            is_correct = det_box_key in correct_boxes
            
            color = (0, 255, 0) if is_correct else (0, 0, 255)
            thickness = 3 if is_correct else 2
            
            cv2.rectangle(vis_img, (x1, y1), (x2, y2), color, thickness)
            
            status = "âœ…" if is_correct else "âŒ"
            iou_text = f" IoU:{correct_boxes[det_box_key]['iou']:.3f}" if is_correct else ""
            label_text = f'{status}{cls_name} {float(conf):.3f}{iou_text}'
            
            cv2.putText(vis_img, label_text, (x1, y1-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
    
    return vis_img

def final_debug_overfitting_test():
    """æœ€ç»ˆè°ƒè¯•ç‰ˆè¿‡æ‹Ÿåˆæµ‹è¯•"""
    print(f"ğŸ”¥ æœ€ç»ˆè°ƒè¯•ç‰ˆè¿‡æ‹Ÿåˆæµ‹è¯• - å½»åº•è§£å†³æ‰€æœ‰é—®é¢˜")
    print("=" * 60)
    
    # å‡†å¤‡æ•°æ®
    label_file = "/home/kyc/project/GOLD-YOLO/2011_002881.txt"
    img_path = "/home/kyc/project/GOLD-YOLO/2011_002881.jpg"
    
    # è¯»å–çœŸå®æ ‡æ³¨
    annotations = []
    with open(label_file, 'r') as f:
        for line in f:
            line = line.strip()
            if line:
                parts = line.split()
                if len(parts) >= 5:
                    cls_id = int(parts[0])
                    x_center = float(parts[1])
                    y_center = float(parts[2])
                    width = float(parts[3])
                    height = float(parts[4])
                    annotations.append([cls_id, x_center, y_center, width, height])
    
    # è¯»å–åŸå§‹å›¾åƒ
    original_img = cv2.imread(img_path)
    img_height, img_width = original_img.shape[:2]
    
    # è½¬æ¢çœŸå®æ ‡æ³¨ä¸ºåƒç´ åæ ‡
    gt_boxes = []
    gt_classes = []
    target_counts = {}
    
    for ann in annotations:
        cls_id, x_center, y_center, width, height = ann
        
        x1 = int((x_center - width/2) * img_width)
        y1 = int((y_center - height/2) * img_height)
        x2 = int((x_center + width/2) * img_width)
        y2 = int((y_center + height/2) * img_height)
        
        gt_boxes.append([x1, y1, x2, y2])
        gt_classes.append(cls_id)
        
        cls_name = VOC_CLASSES[cls_id]
        target_counts[cls_name] = target_counts.get(cls_name, 0) + 1
    
    print(f"ğŸ“‹ çœŸå®æ ‡æ³¨: {target_counts}")
    print(f"   æ€»ç›®æ ‡æ•°: {len(annotations)}")
    print(f"ğŸ“· åŸå§‹å›¾åƒå°ºå¯¸: {img_width}x{img_height}")
    
    # å‡†å¤‡è¾“å…¥
    img = letterbox(original_img, new_shape=640, stride=32, auto=False)[0]
    img_tensor_input = img.transpose((2, 0, 1))[::-1]
    img_tensor_input = np.ascontiguousarray(img_tensor_input)
    img_tensor_input = img_tensor_input.astype(np.float32) / 255.0
    img_tensor = jt.array(img_tensor_input).unsqueeze(0)
    
    # å‡†å¤‡æ ‡ç­¾
    targets = []
    for ann in annotations:
        cls_id, x_center, y_center, width, height = ann
        targets.append([0, cls_id, x_center, y_center, width, height])
    targets_tensor = jt.array(targets, dtype=jt.float32).unsqueeze(0)
    
    # åˆ›å»ºæ¨¡å‹
    print(f"ğŸ¯ åˆ›å»ºæ¨¡å‹...")
    model = create_perfect_gold_yolo_model()
    model = pytorch_exact_initialization(model)
    
    # åˆ›å»ºæŸå¤±å‡½æ•°
    loss_fn = ComputeLoss(
        num_classes=20,
        ori_img_size=640,
        warmup_epoch=4,
        use_dfl=False,
        reg_max=0,
        fpn_strides=[8, 16, 32],
        grid_cell_size=5.0,
        grid_cell_offset=0.5,
        loss_weight={'class': 1.0, 'iou': 2.5, 'dfl': 0.5}
    )
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = jt.optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.0005)
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    save_dir = Path("runs/final_debug_overfitting_test")
    save_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸš€ å¼€å§‹æé€Ÿè®­ç»ƒ (å®Œå…¨ç§»é™¤å†—ä½™è¾“å‡º):")
    
    # è®­ç»ƒè®°å½•
    loss_history = []
    accuracy_history = []
    best_strict_accuracy = 0.0
    best_model_path = None
    
    for epoch in range(1, 31):  # 30è½®å¿«é€Ÿæµ‹è¯•
        start_time = time.time()
        
        # è®­ç»ƒæ¨¡å¼
        model.train()
        
        # å‰å‘ä¼ æ’­
        outputs = model(img_tensor)
        
        # è®¡ç®—æŸå¤±
        loss, loss_items = loss_fn(outputs, targets_tensor, epoch_num=epoch, step_num=1)
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        optimizer.backward(loss)
        optimizer.step()
        
        epoch_time = time.time() - start_time
        epoch_loss = float(loss.numpy())
        loss_history.append(epoch_loss)
        
        # æ¯5è½®è¿›è¡Œæ£€æµ‹æµ‹è¯•
        if epoch % 5 == 0:
            print(f"Epoch {epoch:2d}: Loss {epoch_loss:.6f} ({epoch_time:.2f}s)")
            
            # æ¨ç†æµ‹è¯• - ä½¿ç”¨å¤šä¸ªç½®ä¿¡åº¦é˜ˆå€¼
            model.eval()
            with jt.no_grad():
                test_outputs = model(img_tensor)
                
                # å°è¯•ä¸åŒçš„ç½®ä¿¡åº¦é˜ˆå€¼
                conf_thresholds = [0.001, 0.01, 0.05, 0.1]
                best_result = None
                
                for conf_thresh in conf_thresholds:
                    try:
                        pred = non_max_suppression(test_outputs, conf_thres=conf_thresh, iou_thres=0.45, max_det=100)
                        
                        if len(pred) > 0 and len(pred[0]) > 0:
                            detections = pred[0]
                            
                            if hasattr(detections, 'numpy'):
                                detections_np = detections.numpy()
                            else:
                                detections_np = detections
                            
                            if detections_np.ndim == 3:
                                detections_np = detections_np.reshape(-1, detections_np.shape[-1])
                            
                            # ä¸¥æ ¼è¯„ä¼°
                            correct_detections, matched_count, total_gt = match_detections_to_gt(
                                detections_np, gt_boxes, gt_classes, iou_threshold=0.3
                            )
                            
                            strict_accuracy = matched_count / total_gt if total_gt > 0 else 0.0
                            
                            if strict_accuracy > 0 or len(detections_np) > 0:
                                best_result = {
                                    'conf_thresh': conf_thresh,
                                    'detections': detections_np,
                                    'correct_detections': correct_detections,
                                    'matched_count': matched_count,
                                    'total_gt': total_gt,
                                    'strict_accuracy': strict_accuracy
                                }
                                break
                    
                    except Exception as e:
                        continue
                
                if best_result:
                    result = best_result
                    accuracy_history.append(result['strict_accuracy'])
                    
                    print(f"   ç½®ä¿¡åº¦é˜ˆå€¼: {result['conf_thresh']}")
                    print(f"   æ£€æµ‹æ•°é‡: {len(result['detections'])}")
                    print(f"   ä¸¥æ ¼è¯„ä¼°: {result['matched_count']}/{result['total_gt']} = {result['strict_accuracy']*100:.1f}%")
                    
                    # ä¿å­˜æœ€ä½³æ¨¡å‹
                    if result['strict_accuracy'] > best_strict_accuracy:
                        best_strict_accuracy = result['strict_accuracy']
                        best_model_path = save_dir / f'best_debug_model_epoch_{epoch}.pkl'
                        jt.save({
                            'model': model.state_dict(),
                            'epoch': epoch,
                            'loss': epoch_loss,
                            'strict_accuracy': result['strict_accuracy'],
                            'conf_thresh': result['conf_thresh'],
                            'detections': len(result['detections'])
                        }, str(best_model_path))
                        print(f"   ğŸ† æ–°çš„æœ€ä½³ç»“æœï¼ä¸¥æ ¼å‡†ç¡®ç‡: {result['strict_accuracy']*100:.1f}%")
                        
                        # ç”Ÿæˆå¯è§†åŒ–ç»“æœ
                        vis_img = draw_detection_results(original_img, result['detections'], 
                                                       gt_boxes, gt_classes, result['correct_detections'])
                        
                        vis_path = save_dir / f'debug_result_epoch_{epoch}.jpg'
                        cv2.imwrite(str(vis_path), vis_img)
                        print(f"   ğŸ’¾ å¯è§†åŒ–ç»“æœå·²ä¿å­˜: {vis_path}")
                
                else:
                    accuracy_history.append(0.0)
                    print(f"   âŒ æ‰€æœ‰ç½®ä¿¡åº¦é˜ˆå€¼éƒ½æ²¡æœ‰æ£€æµ‹ç»“æœ")
            
            model.train()
    
    print(f"\nğŸ‰ æé€Ÿè®­ç»ƒå®Œæˆï¼")
    print(f"âœ… æœ€ä½³ä¸¥æ ¼å‡†ç¡®ç‡: {best_strict_accuracy*100:.1f}%")
    
    # æœ€ç»ˆè¯„ä¼°
    if best_model_path and os.path.exists(best_model_path):
        print(f"\nğŸ” æœ€ç»ˆè¯„ä¼°:")
        
        checkpoint = jt.load(str(best_model_path))
        model.load_state_dict(checkpoint['model'])
        
        print(f"   æœ€ä½³è½®æ¬¡: {checkpoint['epoch']}")
        print(f"   æœ€ä½³ç½®ä¿¡åº¦é˜ˆå€¼: {checkpoint['conf_thresh']}")
        print(f"   æœ€ä½³ä¸¥æ ¼å‡†ç¡®ç‡: {checkpoint['strict_accuracy']*100:.1f}%")
        print(f"   æ£€æµ‹æ•°é‡: {checkpoint['detections']}")
        
        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        plt.figure(figsize=(12, 4))
        
        plt.subplot(1, 2, 1)
        plt.plot(range(1, len(loss_history)+1), loss_history, 'b-', linewidth=2)
        plt.title('Training Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.grid(True)
        
        plt.subplot(1, 2, 2)
        epochs_eval = list(range(5, len(accuracy_history)*5+1, 5))
        plt.plot(epochs_eval, [acc*100 for acc in accuracy_history], 'r-', linewidth=2, marker='o')
        plt.title('Strict Accuracy')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy (%)')
        plt.grid(True)
        
        plt.tight_layout()
        curve_path = save_dir / 'debug_training_curves.png'
        plt.savefig(str(curve_path), dpi=150, bbox_inches='tight')
        plt.close()
        print(f"   ğŸ“ˆ è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {curve_path}")
        
        # è¯„ä¼°ç»“æœ
        if best_strict_accuracy >= 0.5:
            print(f"\nğŸ‰ğŸ‰ğŸ‰ è°ƒè¯•æµ‹è¯•æˆåŠŸï¼ğŸ‰ğŸ‰ğŸ‰")
            print(f"âœ… æ¨¡å‹èƒ½å¤Ÿæ­£ç¡®å­¦ä¹ ç‰¹å¾")
            print(f"âœ… ä¸¥æ ¼å‡†ç¡®ç‡è¾¾åˆ° {best_strict_accuracy*100:.1f}%")
            return True
        else:
            print(f"\nğŸ“Š è°ƒè¯•æµ‹è¯•å®Œæˆï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
            print(f"   ä¸¥æ ¼å‡†ç¡®ç‡: {best_strict_accuracy*100:.1f}%")
            return False
    
    else:
        print(f"âŒ æ²¡æœ‰ä¿å­˜çš„æœ€ä½³æ¨¡å‹")
        return False

def main():
    print("ğŸ”¥ æœ€ç»ˆè°ƒè¯•ç‰ˆè¿‡æ‹Ÿåˆæµ‹è¯•")
    print("=" * 80)
    print("ç›®æ ‡: å½»åº•è§£å†³è®­ç»ƒé€Ÿåº¦ã€æ£€æµ‹æ•ˆæœã€å¯è§†åŒ–é—®é¢˜")
    print("ç­–ç•¥: ç§»é™¤å†—ä½™è¾“å‡º + é™ä½ç½®ä¿¡åº¦é˜ˆå€¼ + å®Œæ•´å¯è§†åŒ–")
    print("=" * 80)
    
    success = final_debug_overfitting_test()
    
    if success:
        print(f"\nğŸ‰ğŸ‰ğŸ‰ æœ€ç»ˆè°ƒè¯•æµ‹è¯•æˆåŠŸï¼ğŸ‰ğŸ‰ğŸ‰")
        print(f"âœ… æ‰€æœ‰é—®é¢˜å·²å½»åº•è§£å†³")
    else:
        print(f"\nğŸ“Š è°ƒè¯•æµ‹è¯•å®Œæˆï¼Œå·²ç”Ÿæˆè¯¦ç»†åˆ†æç»“æœ")

if __name__ == "__main__":
    main()
