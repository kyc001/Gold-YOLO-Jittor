#!/usr/bin/env python3
"""
è°ƒè¯•æ¨ç†åæ ‡é—®é¢˜
åˆ†æä¸ºä»€ä¹ˆé¢„æµ‹æ¡†åæ ‡å¼‚å¸¸
"""

import os
import sys
import cv2
import numpy as np
import jittor as jt
from pathlib import Path
import time
import math

# æ·»åŠ è·¯å¾„
sys.path.append('.')
sys.path.append('./yolov6')

from models.perfect_gold_yolo import create_perfect_gold_yolo_model
from yolov6.data.data_augment import letterbox
from yolov6.models.pytorch_aligned_losses import ComputeLoss

def debug_inference_coordinates():
    """è°ƒè¯•æ¨ç†åæ ‡é—®é¢˜"""
    print(f"ğŸ” è°ƒè¯•æ¨ç†åæ ‡é—®é¢˜")
    print("=" * 80)
    
    # å‡†å¤‡æ•°æ®
    img_path = "/home/kyc/project/GOLD-YOLO/2008_001420.jpg"
    original_img = cv2.imread(img_path)
    img_height, img_width = original_img.shape[:2]
    
    # é¢„å¤„ç†å›¾åƒ
    img_size = 640
    img = letterbox(original_img, new_shape=img_size, stride=32, auto=False)[0]
    img_tensor_input = img.transpose((2, 0, 1))[::-1]
    img_tensor_input = np.ascontiguousarray(img_tensor_input)
    img_tensor_input = img_tensor_input.astype(np.float32) / 255.0
    img_tensor = jt.array(img_tensor_input).unsqueeze(0)
    
    print(f"ğŸ“Š æ•°æ®å‡†å¤‡:")
    print(f"   åŸå§‹å›¾åƒå°ºå¯¸: {img_width}x{img_height}")
    print(f"   é¢„å¤„ç†åå°ºå¯¸: {img.shape}")
    print(f"   è¾“å…¥å¼ é‡: {img_tensor.shape}")
    
    # åˆ›å»ºæ¨¡å‹
    model = create_perfect_gold_yolo_model()
    
    # å…ˆè®­ç»ƒå‡ è½®è®©æ¨¡å‹æœ‰åˆç†çš„è¾“å‡º
    print(f"\nğŸ”§ å¿«é€Ÿè®­ç»ƒå‡ è½®:")
    model.train()
    
    # å‡†å¤‡æ ‡ç­¾
    targets = [[0, 11, 0.814, 0.400, 0.111, 0.208]]  # ä¸€ä¸ªdogç›®æ ‡
    targets_tensor = jt.array(targets, dtype=jt.float32).unsqueeze(0)
    
    loss_fn = ComputeLoss(
        num_classes=20,
        ori_img_size=img_size,
        warmup_epoch=0,
        use_dfl=False,
        reg_max=0,
        fpn_strides=[8, 16, 32],
        grid_cell_size=5.0,
        grid_cell_offset=0.5,
        loss_weight={'class': 1.0, 'iou': 2.5, 'dfl': 0.5}
    )
    
    optimizer = jt.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)
    
    for epoch in range(10):
        outputs = model(img_tensor)
        loss, loss_items = loss_fn(outputs, targets_tensor, epoch_num=epoch, step_num=epoch)
        optimizer.zero_grad()
        optimizer.backward(loss)
        optimizer.step()
        
        if epoch % 5 == 0:
            print(f"   è½®æ¬¡ {epoch}: æŸå¤±={float(loss):.6f}")
    
    # åˆ‡æ¢åˆ°æ¨ç†æ¨¡å¼
    print(f"\nğŸ” åˆ‡æ¢åˆ°æ¨ç†æ¨¡å¼:")
    model.eval()
    
    with jt.no_grad():
        # æ¨ç†
        outputs = model(img_tensor)
        
        print(f"   æ¨ç†è¾“å‡ºå½¢çŠ¶: {outputs.shape}")
        print(f"   è¾“å‡ºèŒƒå›´: [{float(outputs.min()):.6f}, {float(outputs.max()):.6f}]")
        
        # åˆ†æè¾“å‡ºçš„å„ä¸ªéƒ¨åˆ†
        batch_size, num_anchors, num_features = outputs.shape
        print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
        print(f"   anchoræ•°é‡: {num_anchors}")
        print(f"   ç‰¹å¾æ•°é‡: {num_features}")
        
        # åˆ†è§£è¾“å‡º
        pred_bboxes = outputs[..., :4]      # [1, 8400, 4] åæ ‡
        pred_obj = outputs[..., 4:5]        # [1, 8400, 1] objectness
        pred_cls = outputs[..., 5:]         # [1, 8400, 20] ç±»åˆ«
        
        print(f"\nğŸ“Š è¾“å‡ºåˆ†æ:")
        print(f"   é¢„æµ‹æ¡†: {pred_bboxes.shape}, èŒƒå›´=[{float(pred_bboxes.min()):.2f}, {float(pred_bboxes.max()):.2f}]")
        print(f"   objectness: {pred_obj.shape}, èŒƒå›´=[{float(pred_obj.min()):.6f}, {float(pred_obj.max()):.6f}]")
        print(f"   ç±»åˆ«åˆ†æ•°: {pred_cls.shape}, èŒƒå›´=[{float(pred_cls.min()):.6f}, {float(pred_cls.max()):.6f}]")
        
        # æ£€æŸ¥åæ ‡æ ¼å¼
        print(f"\nğŸ” åæ ‡æ ¼å¼åˆ†æ:")
        sample_boxes = pred_bboxes[0, :10]  # å‰10ä¸ªæ¡†
        for i, box in enumerate(sample_boxes):
            x, y, w, h = box
            print(f"   æ¡†{i+1}: x={float(x):.2f}, y={float(y):.2f}, w={float(w):.2f}, h={float(h):.2f}")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯xywhæ ¼å¼è¿˜æ˜¯xyxyæ ¼å¼
        print(f"\nğŸ” åæ ‡æ ¼å¼åˆ¤æ–­:")
        if float(pred_bboxes.max()) > img_size * 2:
            print(f"   âŒ åæ ‡å€¼è¿‡å¤§ï¼Œå¯èƒ½æœ‰ç¼©æ”¾é—®é¢˜")
        elif float(pred_bboxes.min()) < -img_size:
            print(f"   âŒ åæ ‡å€¼è¿‡å°ï¼Œå¯èƒ½æœ‰åç§»é—®é¢˜")
        else:
            print(f"   âœ… åæ ‡å€¼åœ¨åˆç†èŒƒå›´å†…")
        
        # æ£€æŸ¥objectnesså’Œç±»åˆ«åˆ†æ•°
        print(f"\nğŸ” ç½®ä¿¡åº¦åˆ†æ:")
        max_obj = float(pred_obj.max())
        max_cls = float(pred_cls.max())
        print(f"   æœ€å¤§objectness: {max_obj:.6f}")
        print(f"   æœ€å¤§ç±»åˆ«åˆ†æ•°: {max_cls:.6f}")
        
        # è®¡ç®—æ€»ç½®ä¿¡åº¦
        total_conf = pred_obj * pred_cls.max(dim=-1, keepdim=True)[0]
        max_total_conf = float(total_conf.max())
        print(f"   æœ€å¤§æ€»ç½®ä¿¡åº¦: {max_total_conf:.6f}")
        
        # æ‰¾åˆ°é«˜ç½®ä¿¡åº¦çš„é¢„æµ‹
        high_conf_mask = total_conf.squeeze(-1) > 0.1
        high_conf_indices = jt.where(high_conf_mask)
        
        if len(high_conf_indices[1]) > 0:
            print(f"\nğŸ¯ é«˜ç½®ä¿¡åº¦é¢„æµ‹ (>0.1):")
            for i in range(min(5, len(high_conf_indices[1]))):
                idx = high_conf_indices[1][i]
                box = pred_bboxes[0, idx]
                obj = pred_obj[0, idx, 0]
                cls_scores = pred_cls[0, idx]
                max_cls_idx = jt.argmax(cls_scores)[0]
                max_cls_score = cls_scores[max_cls_idx]
                
                x, y, w, h = box
                print(f"   é¢„æµ‹{i+1}: åæ ‡=({float(x):.1f},{float(y):.1f},{float(w):.1f},{float(h):.1f}), obj={float(obj):.3f}, cls={int(max_cls_idx)}({float(max_cls_score):.3f})")
        else:
            print(f"\nâŒ æ²¡æœ‰é«˜ç½®ä¿¡åº¦é¢„æµ‹")
        
        # æ£€æŸ¥åæ ‡æ˜¯å¦éœ€è¦è½¬æ¢
        print(f"\nğŸ”§ åæ ‡è½¬æ¢æµ‹è¯•:")
        
        # å‡è®¾æ˜¯xywhæ ¼å¼ï¼Œè½¬æ¢ä¸ºxyxy
        x_center, y_center, width, height = pred_bboxes[0, 0]
        x1 = float(x_center - width / 2)
        y1 = float(y_center - height / 2)
        x2 = float(x_center + width / 2)
        y2 = float(y_center + height / 2)
        
        print(f"   ç¬¬ä¸€ä¸ªæ¡† xywh->xyxy: ({x1:.1f},{y1:.1f}) -> ({x2:.1f},{y2:.1f})")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç¼©æ”¾åˆ°åŸå§‹å›¾åƒ
        scale_x = img_width / img_size
        scale_y = img_height / img_size
        
        x1_scaled = x1 * scale_x
        y1_scaled = y1 * scale_y
        x2_scaled = x2 * scale_x
        y2_scaled = y2 * scale_y
        
        print(f"   ç¼©æ”¾åˆ°åŸå§‹å›¾åƒ: ({x1_scaled:.1f},{y1_scaled:.1f}) -> ({x2_scaled:.1f},{y2_scaled:.1f})")
        print(f"   ç¼©æ”¾å› å­: x={scale_x:.3f}, y={scale_y:.3f}")
        
        if 0 <= x1_scaled <= img_width and 0 <= y1_scaled <= img_height and 0 <= x2_scaled <= img_width and 0 <= y2_scaled <= img_height:
            print(f"   âœ… ç¼©æ”¾ååæ ‡åœ¨å›¾åƒèŒƒå›´å†…")
        else:
            print(f"   âŒ ç¼©æ”¾ååæ ‡ä»ç„¶è¶…å‡ºå›¾åƒèŒƒå›´")
        
        return outputs

def main():
    print("ğŸ” è°ƒè¯•æ¨ç†åæ ‡é—®é¢˜")
    print("=" * 80)
    
    try:
        outputs = debug_inference_coordinates()
        
        print(f"\nğŸ“Š è°ƒè¯•æ€»ç»“:")
        print(f"   è¾“å‡ºå½¢çŠ¶: {outputs.shape}")
        print(f"   è¾“å‡ºèŒƒå›´: [{float(outputs.min()):.2f}, {float(outputs.max()):.2f}]")
        
    except Exception as e:
        print(f"\nâŒ è°ƒè¯•å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
